[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 0.0001,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2474950674851635,
        "time": 14.152631759643555,
        "additional_info": {
            "duration": 14.133777141571045,
            "num_run": 2,
            "train_loss": 1.214036255838255,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005897913068713326,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015283020493786284,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 1.4677592009332837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009994383306256792,
            "feature_preprocessor:select_percentile_classification:percentile": 83.71076102633408,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.346405029296875,
        "additional_info": {
            "duration": 0.3355398178100586,
            "num_run": 3,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017335374469244055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21446023234155723,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 393,
            "classifier:CustomMLPClassifier:tol": 0.00020669606778637786,
            "feature_preprocessor:select_rates_classification:alpha": 0.37074326113847605,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.24734783172607422,
        "additional_info": {
            "duration": 0.23162007331848145,
            "num_run": 4,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001265432263937216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025210486300051585,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 1.3134515968729273e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.886128143254935,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.31714510917663574,
        "additional_info": {
            "duration": 0.3060002326965332,
            "num_run": 5,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.476537348642138e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6094187968363136,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.000623601061960284,
            "feature_preprocessor:select_rates_classification:alpha": 0.37277199716070397,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.9019508361816406,
        "additional_info": {
            "duration": 0.891826868057251,
            "num_run": 6,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.150721995132133e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010880231565364893,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0032008478454880612,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034494424153546144,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8627567984926874,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.259129727137432,
        "time": 0.826138973236084,
        "additional_info": {
            "duration": 0.8146970272064209,
            "num_run": 7,
            "train_loss": 1.1787841369818874,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.1977691813522454e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.44966367306334676,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.005806128069380193,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008876578344611543,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 93,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27320045729587017,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.26935386657714844,
        "additional_info": {
            "duration": 0.2507169246673584,
            "num_run": 8,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03859643951467421,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07212176876171598,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.003501543999506037,
            "feature_preprocessor:select_percentile_classification:percentile": 48.494598649907545,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.248587692258814,
        "time": 0.6848468780517578,
        "additional_info": {
            "duration": 0.6723771095275879,
            "num_run": 9,
            "train_loss": 1.1791141443719886,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.024396726173774e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000792752159797921,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.008568517736793516,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4481637321671371,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2504989108643505,
        "time": 0.2899010181427002,
        "additional_info": {
            "duration": 0.2770817279815674,
            "num_run": 10,
            "train_loss": 1.2332225648226165,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04534421007358139,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4293992218467536,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 1.1576354108101876e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022736229145807908,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4696837096943476,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 2.206824779510498,
        "additional_info": {
            "duration": 2.192810297012329,
            "num_run": 11,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.190162741326012e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.051563839312456394,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 363,
            "classifier:CustomMLPClassifier:tol": 4.3673072866513476e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2674328453592296,
        "time": 0.7734019756317139,
        "additional_info": {
            "duration": 0.763728141784668,
            "num_run": 12,
            "train_loss": 1.2055089298035075,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3540613852681343e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007020317984370575,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 4.963733159642449e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3549262182156768,
            "feature_preprocessor:select_percentile_classification:percentile": 29.50564901623699,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.4954209327697754,
        "additional_info": {
            "duration": 0.4803330898284912,
            "num_run": 13,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.1904652038167188e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14547666221998873,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 250,
            "classifier:CustomMLPClassifier:tol": 0.0018741921611895498,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004783330131787969,
            "feature_preprocessor:select_percentile_classification:percentile": 39.19279299354127,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2458565977042424,
        "time": 0.8702950477600098,
        "additional_info": {
            "duration": 0.8577718734741211,
            "num_run": 14,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012558700444440325,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004566038365612244,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 412,
            "classifier:CustomMLPClassifier:tol": 0.0002690505476795295,
            "feature_preprocessor:select_rates_classification:alpha": 0.27958793650725733,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.348236083984375,
        "additional_info": {
            "duration": 0.3382861614227295,
            "num_run": 15,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004529404207303219,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3286435034285036,
            "classifier:CustomMLPClassifier:max_iter": 241,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 1.2003474193840605e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017601424341716212,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1275,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4044304895742429,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.268015120558756,
        "time": 1.463243007659912,
        "additional_info": {
            "duration": 1.45051908493042,
            "num_run": 16,
            "train_loss": 1.1779061743867525,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2471563595009652e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.040802395340469234,
            "classifier:CustomMLPClassifier:max_iter": 368,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 2.96190105467316e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8510201724092987,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3730888366699219,
        "additional_info": {
            "duration": 0.36175084114074707,
            "num_run": 17,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008757870236502908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025210486300051585,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 1.3035540989712393e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_percentile_classification:percentile": 50.0,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.48270487785339355,
        "additional_info": {
            "duration": 0.4615950584411621,
            "num_run": 18,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011247489853798529,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.29775183981059283,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 350,
            "classifier:CustomMLPClassifier:tol": 1.7984748714608828e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1256058140500073,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 920,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2938783129163548,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.43090200424194336,
        "additional_info": {
            "duration": 0.4164612293243408,
            "num_run": 19,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07938590978658329,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003820085895659359,
            "classifier:CustomMLPClassifier:max_iter": 392,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.004730882699538629,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008049962284980616,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5505321650681011,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222673202467494,
        "time": 0.42221522331237793,
        "additional_info": {
            "duration": 0.40503501892089844,
            "num_run": 20,
            "train_loss": 1.2373984418909296,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0014660584400787088,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022448664668604418,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.00016587810585277324,
            "feature_preprocessor:select_rates_classification:alpha": 0.48553680774472563,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2390058421668737,
        "time": 9.264899015426636,
        "additional_info": {
            "duration": 9.252666711807251,
            "num_run": 21,
            "train_loss": 1.0499090289964736,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011962304756318251,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27314929186832093,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.002367678169354958,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006999046958137659,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5537129916763176,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 1.1945080757141113,
        "additional_info": {
            "duration": 1.1785612106323242,
            "num_run": 22,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7114069159181107e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15951870298448778,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.43890267327215676,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1309521198272705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.238957369532558e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010662292033276136,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.0001006856202596087,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032523410809078574,
            "feature_preprocessor:select_percentile_classification:percentile": 77.35209353785427,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2474768958087903,
        "time": 5.120142936706543,
        "additional_info": {
            "duration": 5.1103081703186035,
            "num_run": 24,
            "train_loss": 1.0228604981247966,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.341779913308504e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011869586426206818,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.00011349992020375841,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17511295750117292,
            "feature_preprocessor:select_rates_classification:alpha": 0.013457542283623615,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.207689003387401,
        "time": 4.112287282943726,
        "additional_info": {
            "duration": 4.100620985031128,
            "num_run": 25,
            "train_loss": 1.1652439667098922,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.824096971131191e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025038120213221435,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.001350777272458087,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4445875095712063,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2403804969922234,
        "time": 0.4631929397583008,
        "additional_info": {
            "duration": 0.4463071823120117,
            "num_run": 26,
            "train_loss": 1.1542446641543118,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0526723996377998e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002802691297599802,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 2.634289992649762e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.04291428338756169,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5545761585235596,
        "additional_info": {
            "duration": 0.5386559963226318,
            "num_run": 27,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006406964628520832,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020684682003233607,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 0.0011378287529698054,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005621166423265596,
            "feature_preprocessor:select_rates_classification:alpha": 0.42599982424148175,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2279493278998994,
        "time": 1.168734073638916,
        "additional_info": {
            "duration": 1.156947135925293,
            "num_run": 28,
            "train_loss": 1.1710190805525391,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0007868127629653095,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003925855652102181,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 1.708156613750426e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02065504617158127,
            "feature_preprocessor:select_rates_classification:alpha": 0.43714775287188873,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2482096958321527,
        "time": 2.9192140102386475,
        "additional_info": {
            "duration": 2.903402090072632,
            "num_run": 29,
            "train_loss": 1.144007399718085,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010352011790538048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00025985620950269936,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.0003570884780307026,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026648821843625943,
            "feature_preprocessor:select_rates_classification:alpha": 0.4669959948394841,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.7549488544464111,
        "additional_info": {
            "duration": 0.7421026229858398,
            "num_run": 30,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003923567849330057,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3114078649971819,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.002597745823306526,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007864775359774428,
            "feature_preprocessor:select_rates_classification:alpha": 0.48362898138321936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2651203506575621,
        "time": 1.3323631286621094,
        "additional_info": {
            "duration": 1.3200500011444092,
            "num_run": 31,
            "train_loss": 1.061568960819824,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.007400115768645e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008741762138625734,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 250,
            "classifier:CustomMLPClassifier:tol": 1.0833780108427403e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00093737357707281,
            "feature_preprocessor:select_percentile_classification:percentile": 57.938627487371534,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2364658758623812,
        "time": 8.825950860977173,
        "additional_info": {
            "duration": 8.809104681015015,
            "num_run": 32,
            "train_loss": 1.039086064342058,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00992357429323932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001372641142881417,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.0004792352651812377,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1534,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 10.929982772423124,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2511579591638464,
        "time": 0.34987688064575195,
        "additional_info": {
            "duration": 0.334536075592041,
            "num_run": 33,
            "train_loss": 1.2385706883009207,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7114069159181107e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31844017200918934,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4563217903756445,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.222673202467494,
        "time": 0.4674980640411377,
        "additional_info": {
            "duration": 0.4547429084777832,
            "num_run": 34,
            "train_loss": 1.226361674810559,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002182969125155583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4961930220156904,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 0.0048840610857295375,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.10161444831666677,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2851622676955445,
        "time": 0.6979660987854004,
        "additional_info": {
            "duration": 0.6858730316162109,
            "num_run": 35,
            "train_loss": 1.067856074806214,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003526133523866417,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012601450864713822,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.0001268641286184638,
            "feature_preprocessor:select_percentile_classification:percentile": 42.85968834949168,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3031010627746582,
        "additional_info": {
            "duration": 0.289654016494751,
            "num_run": 36,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.560705488459092e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09789342644177167,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.46948629930699104,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.544107844094213,
        "time": 0.5170638561248779,
        "additional_info": {
            "duration": 0.5049328804016113,
            "num_run": 37,
            "train_loss": 1.544258233216406,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7114069159181107e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7951452909667874,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4825923876137776,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.5087440013885498,
        "additional_info": {
            "duration": 0.49455809593200684,
            "num_run": 38,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7114069159181107e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2376067998689838,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 9.301647174396487e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4606196003132588,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12563467025756836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005347957859405093,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007980403299966151,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.00279326490961662,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025196771120868284,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.15040995688533976,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2453876560562063,
        "time": 0.414945125579834,
        "additional_info": {
            "duration": 0.4024507999420166,
            "num_run": 40,
            "train_loss": 1.1905894430077018,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.382327568964079e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012919537096922005,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.005170701431289671,
            "feature_preprocessor:select_rates_classification:alpha": 0.45457600052354086,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1225430965423584,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.382327568964079e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012919537096922005,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.004069947767637376,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010127797111138372,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1209,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4571219052270441,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2324875887356008,
        "time": 0.8509900569915771,
        "additional_info": {
            "duration": 0.8399491310119629,
            "num_run": 42,
            "train_loss": 1.157803262818168,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.111387000311437e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026626904060753024,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.005167151513882791,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000516126734250631,
            "feature_preprocessor:select_rates_classification:alpha": 0.26019900341603863,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1228179931640625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5323017864636567e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010841976692770264,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.00010560263662101244,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18758160600908763,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7902428450576573,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21087692976357236,
            "feature_preprocessor:select_rates_classification:alpha": 0.3027264914783485,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2519696189041718,
        "time": 0.9948689937591553,
        "additional_info": {
            "duration": 0.9796121120452881,
            "num_run": 44,
            "train_loss": 1.1738340661156532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.382327568964079e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023241453061766871,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.005429224969154488,
            "feature_preprocessor:select_rates_classification:alpha": 0.4395807957745439,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09590673446655273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.808906714365336e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013527373445211774,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.005429224969154488,
            "feature_preprocessor:select_rates_classification:alpha": 0.4395807957745439,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12332391738891602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.023424259728047e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013527373445211774,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 0.0051225487284249594,
            "feature_preprocessor:select_rates_classification:alpha": 0.4715700047205474,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09536981582641602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.6876489175063897e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016904386678284004,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 0.0053786108828869,
            "feature_preprocessor:select_rates_classification:alpha": 0.4016369348399807,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12200498580932617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.297997843874404e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14435894218228496,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 0.006950246595684434,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7420917155657712,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26175605804073165,
            "feature_preprocessor:select_rates_classification:alpha": 0.4658862203898184,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2537495059608648,
        "time": 0.9730370044708252,
        "additional_info": {
            "duration": 0.8975811004638672,
            "num_run": 49,
            "train_loss": 1.0695287801689484,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.278130904728146e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010664474450869248,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.008613585137327306,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012193741615622016,
            "feature_preprocessor:select_rates_classification:alpha": 0.48191812342711565,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12292098999023438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.695949293009544e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008144603366248209,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 256,
            "classifier:CustomMLPClassifier:tol": 1.0979169564333802e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49026490546020857,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.41139698028564453,
        "additional_info": {
            "duration": 0.3981821537017822,
            "num_run": 51,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0228340781246376,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023642040060881872,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.00010083133441611109,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 929,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4184019259372086,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2405351516302914,
        "time": 3.2144789695739746,
        "additional_info": {
            "duration": 3.2021639347076416,
            "num_run": 52,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.468082535128228e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0037057265051565844,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.005656429773874844,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.26608928645514346,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12366199493408203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09926624663462477,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05054036820245677,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.004971508567669584,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9421905744706863,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09685266416708527,
            "feature_preprocessor:select_rates_classification:alpha": 0.4177854036045421,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2587699458068986,
        "time": 0.8153560161590576,
        "additional_info": {
            "duration": 0.8047659397125244,
            "num_run": 54,
            "train_loss": 1.1872568024483676,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0761120073689165e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015740431121886926,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.005078137649214456,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011200801137323834,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.122528076171875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.8515581324405e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004143030625915384,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 273,
            "classifier:CustomMLPClassifier:tol": 0.008272808097226692,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001690072288758605,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8113567362886186,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2511862599869028,
        "time": 0.4457416534423828,
        "additional_info": {
            "duration": 0.41706180572509766,
            "num_run": 56,
            "train_loss": 1.2208493691096571,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.472861292595684e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022832671992052258,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.004565460498247609,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019672333493630352,
            "feature_preprocessor:select_rates_classification:alpha": 0.1169075586585903,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09570097923278809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.0906889358496762e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.048523599112889435,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.004299882569804431,
            "feature_preprocessor:select_rates_classification:alpha": 0.38492701150057124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12842488288879395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00012701612212949928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012089507820481522,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 8.34687312395274e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2771904651101715,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9721848733995728,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19728005733819323,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6413079765258571,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2413638746088609,
        "time": 1.6747829914093018,
        "additional_info": {
            "duration": 1.6599149703979492,
            "num_run": 59,
            "train_loss": 1.1887282440652358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.015150377264202862,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021788995686840246,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 0.0049988172320576466,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015136352478379847,
            "feature_preprocessor:select_rates_classification:alpha": 0.272935846089522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12287521362304688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4741331401225497e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5435006631288838,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 1.0180126306188592e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008275378012427732,
            "feature_preprocessor:select_percentile_classification:percentile": 3.290908666392939,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.3393349773395014,
        "time": 0.308427095413208,
        "additional_info": {
            "duration": 0.28897714614868164,
            "num_run": 61,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018134461597821898,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18638807427188966,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 0.009938763141620911,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015496134276612675,
            "feature_preprocessor:select_rates_classification:alpha": 0.41597447471331717,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.20868611335754395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.140906047522969e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005922590191400162,
            "classifier:CustomMLPClassifier:max_iter": 243,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 1.8379335976308065e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03565230281735214,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13296103477478027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0312909861893183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2959912940099999,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.004972641468702272,
            "feature_preprocessor:select_rates_classification:alpha": 0.08095666575280505,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15735888481140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.500281531019389e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001876556746020186,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.0032869880515661344,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4715700047205474,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12365603446960449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.198116571260688e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9048759510821778,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.0007948112534481998,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07084552023701818,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.312367357762645,
        "time": 0.3881409168243408,
        "additional_info": {
            "duration": 0.3615753650665283,
            "num_run": 66,
            "train_loss": 1.2606555321666164,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.034561912663829124,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14064434673093254,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 2.9236382623206694e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 11.890079087371392,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2528387716299647,
        "time": 0.4637949466705322,
        "additional_info": {
            "duration": 0.44689202308654785,
            "num_run": 67,
            "train_loss": 1.2131699369472766,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0446446232108248e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012210968006486184,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.004352093757524828,
            "feature_preprocessor:select_rates_classification:alpha": 0.48380363144845395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1261739730834961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003755894137693151,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07917196228522808,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 1.977464014658394e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1323418941693925,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9958275253073422,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16074217717983488,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5215814613090958,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2086906395199215,
        "time": 0.3587839603424072,
        "additional_info": {
            "duration": 0.34012579917907715,
            "num_run": 69,
            "train_loss": 1.200136677451795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011357663234237217,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003121649730559807,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.0013102402237022224,
            "feature_preprocessor:select_rates_classification:alpha": 0.11752518629194682,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.220815477292457,
        "time": 0.7290480136871338,
        "additional_info": {
            "duration": 0.7105982303619385,
            "num_run": 70,
            "train_loss": 1.1624256817314136,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.5663152433684054e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35450977221565133,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.0032403574552703853,
            "feature_preprocessor:select_rates_classification:alpha": 0.20254615132191092,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13040685653686523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.610895221023065e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22350400180402094,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 4.5808839472391204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003089272228647806,
            "feature_preprocessor:select_rates_classification:alpha": 0.4778388884146397,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09596896171569824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05672908062904203,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00281992630662491,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.009749887964530982,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.48547989853776435,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7667108067924467,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.027305014856836604,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7423264148573939,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.257664083670952,
        "time": 0.2894589900970459,
        "additional_info": {
            "duration": 0.27738499641418457,
            "num_run": 73,
            "train_loss": 1.2217213428531126,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.019044455465090458,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5354518241801016,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.005195015082149645,
            "feature_preprocessor:select_rates_classification:alpha": 0.48018804523233827,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.544107844094213,
        "time": 0.2226848602294922,
        "additional_info": {
            "duration": 0.20623993873596191,
            "num_run": 74,
            "train_loss": 1.544258233216406,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0079933878679648e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8394584348281091,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 2.537126519634338e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03548452881415495,
            "feature_preprocessor:select_rates_classification:alpha": 0.2089950624816425,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09824395179748535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0012785090322652336,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002631949110560406,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 7.923459369165192e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002409001680744266,
            "feature_preprocessor:select_rates_classification:alpha": 0.4767581329637051,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16291117668151855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.094176761201192e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011801889380295718,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 0.0006357074251965302,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 59,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 66.3595708966235,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.279171731014924,
        "time": 0.6067531108856201,
        "additional_info": {
            "duration": 0.5923299789428711,
            "num_run": 77,
            "train_loss": 1.011848425403082,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009235443848668782,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002226398058997969,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 3.7712754917642776e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013016946813563529,
            "feature_preprocessor:select_rates_classification:alpha": 0.06431603638980382,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1348259449005127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.252776665026559e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020545725627603333,
            "classifier:CustomMLPClassifier:max_iter": 269,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.0020862309425441743,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031018496212619835,
            "feature_preprocessor:select_rates_classification:alpha": 0.07106681222936072,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.23051118850708008,
        "additional_info": {
            "duration": 0.21277403831481934,
            "num_run": 79,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00020247034379310296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023947532336136452,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 6.508867234976143e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004784571012802104,
            "feature_preprocessor:select_percentile_classification:percentile": 50.65693987823111,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.39758801460266113,
        "additional_info": {
            "duration": 0.3868138790130615,
            "num_run": 80,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.524440852407909e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005417795707814299,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.001790518352727794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30459413567938026,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6120816415903996,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2603314688088305,
        "time": 0.4846069812774658,
        "additional_info": {
            "duration": 0.4607219696044922,
            "num_run": 81,
            "train_loss": 1.1776977463249094,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.935658995402572e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07838822266007063,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 257,
            "classifier:CustomMLPClassifier:tol": 0.00028677566399796573,
            "feature_preprocessor:select_rates_classification:alpha": 0.4039965321887539,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1022179126739502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.6256258514552847e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7315699676422074,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.47415944482367806,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2598989573530501,
        "time": 0.32266688346862793,
        "additional_info": {
            "duration": 0.3005638122558594,
            "num_run": 83,
            "train_loss": 1.1834169706241546,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.507336264036467e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10726054670470245,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 98,
            "classifier:CustomMLPClassifier:tol": 0.0015300747511771077,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008561510057678023,
            "feature_preprocessor:select_rates_classification:alpha": 0.44392881309424986,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12433314323425293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.389659883085155e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01038852712928243,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.0058432904053723565,
            "feature_preprocessor:select_rates_classification:alpha": 0.0686538882849087,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0993340015411377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0051017135991791385,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00999985326570176,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 0.00019643983405702605,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43952178815351944,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8312554247690194,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3323671817779541,
        "additional_info": {
            "duration": 0.31571006774902344,
            "num_run": 86,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.668205175130929e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4289975628383616,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 3.896634509576241e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.40714760541286177,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13257694244384766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007299447577707799,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024446984735602733,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.0017389242396376298,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038341399255986855,
            "feature_preprocessor:select_rates_classification:alpha": 0.13393776861376092,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10262393951416016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005205110308257504,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04819156883039105,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.00021633979291859202,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 188,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 22.633338449723905,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2350679847873167,
        "time": 0.5019361972808838,
        "additional_info": {
            "duration": 0.4769930839538574,
            "num_run": 89,
            "train_loss": 1.1908472597868567,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.018640911046999793,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013202407188959506,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 3.99814047873906e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1859153797393251,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2618697555610476,
        "time": 1.6119959354400635,
        "additional_info": {
            "duration": 1.5932891368865967,
            "num_run": 90,
            "train_loss": 1.187379325754878,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001008471038399744,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001869767157671802,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 0.008666432688992105,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007768622219389242,
            "feature_preprocessor:select_rates_classification:alpha": 0.35459333115481523,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0966188907623291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00029409720369568136,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006940288944113616,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.0005580281136124216,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001349227148925382,
            "feature_preprocessor:select_rates_classification:alpha": 0.021008683972218656,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12490677833557129,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.024378522828608962,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003201061954052406,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 5.1162220478636076e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013668835316740192,
            "feature_preprocessor:select_percentile_classification:percentile": 75.59783036066878,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2813119888305664,
        "additional_info": {
            "duration": 0.2584981918334961,
            "num_run": 93,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006789007599139024,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006069618486712134,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 0.0005567586749531636,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014059183480896933,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2790238965312115,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.220010925322712,
        "time": 0.29977893829345703,
        "additional_info": {
            "duration": 0.2810091972351074,
            "num_run": 94,
            "train_loss": 1.182629392172532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01793129381359631,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2828461008225747,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.0009321385886917462,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012344540308091857,
            "feature_preprocessor:select_percentile_classification:percentile": 37.57251116898629,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.272107632576381,
        "time": 0.3596920967102051,
        "additional_info": {
            "duration": 0.3375532627105713,
            "num_run": 95,
            "train_loss": 1.16454139803767,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.062269065411662e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004348305547475465,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 7.089209900415328e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 896,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 42.14296551408823,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2311766433269442,
        "time": 1.163658857345581,
        "additional_info": {
            "duration": 1.135486125946045,
            "num_run": 96,
            "train_loss": 1.144038594902831,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5932665365418048e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04557795440667987,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 0.00013612112668937254,
            "feature_preprocessor:select_rates_classification:alpha": 0.18763154026935322,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10175085067749023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.046515173195995727,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04617340217664428,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.0005149036759712221,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010827499831237378,
            "feature_preprocessor:select_percentile_classification:percentile": 20.77586569961019,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3355519771575928,
        "additional_info": {
            "duration": 0.3201889991760254,
            "num_run": 98,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.7328564770322803e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0044587736633991655,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 2.504797546989137e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022481302476452298,
            "feature_preprocessor:select_percentile_classification:percentile": 14.837301124415973,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2528387716299647,
        "time": 0.224456787109375,
        "additional_info": {
            "duration": 0.21367192268371582,
            "num_run": 99,
            "train_loss": 1.2131699369472766,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.536352769177545e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5635503428493601,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.002130317021718084,
            "feature_preprocessor:select_rates_classification:alpha": 0.3968348115029958,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12381410598754883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009554808454619054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.680561464221297,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.0022646567244337824,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4978507340466919,
            "feature_preprocessor:select_percentile_classification:percentile": 89.13396114022486,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2945663571589665,
        "time": 0.4336872100830078,
        "additional_info": {
            "duration": 0.4095919132232666,
            "num_run": 101,
            "train_loss": 1.077586147977562,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.5955018431469475e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09868849902289963,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.0005948877109094314,
            "feature_preprocessor:select_rates_classification:alpha": 0.013496691505056325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12767696380615234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010790588543291188,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029600929043583538,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 185,
            "classifier:CustomMLPClassifier:tol": 1.05845125217427e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003369433378214549,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8016161013566084,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2525022699689012,
        "time": 0.33328890800476074,
        "additional_info": {
            "duration": 0.31340718269348145,
            "num_run": 103,
            "train_loss": 1.2088480711889318,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006388911744030426,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7944729881886776,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 1.1584796670381575e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006401924979534646,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 151,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8420029418810064,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2604092635074193,
        "time": 0.36830806732177734,
        "additional_info": {
            "duration": 0.3510768413543701,
            "num_run": 104,
            "train_loss": 1.1931960495112925,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00018224077754553806,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5565968672193551,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 5.5080977855325936e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2386953017841331,
            "feature_preprocessor:select_rates_classification:alpha": 0.09134701381201484,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12526488304138184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.616107452041503e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020434037745132127,
            "classifier:CustomMLPClassifier:max_iter": 266,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 0.0016820613432552308,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.37640075880856705,
            "feature_preprocessor:select_rates_classification:alpha": 0.19994757294502935,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12342095375061035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08856471575738539,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017540429889086637,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 5.1274686102357075e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000294651861119395,
            "feature_preprocessor:select_rates_classification:alpha": 0.013621751890576694,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.240158046542985,
        "time": 0.42365002632141113,
        "additional_info": {
            "duration": 0.40842270851135254,
            "num_run": 107,
            "train_loss": 1.190193465344379,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.815722213929424e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06643689357397113,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 259,
            "classifier:CustomMLPClassifier:tol": 0.0006198406101315688,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9045111388453677,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23789694682071055,
            "feature_preprocessor:select_percentile_classification:percentile": 34.03459105365437,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2490383753909673,
        "time": 0.3628370761871338,
        "additional_info": {
            "duration": 0.3518202304840088,
            "num_run": 108,
            "train_loss": 1.0780686448837846,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1977871379714594e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01840680298201856,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 4.394508908198879e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06019686448592587,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09787297248840332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.781868550876322e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5133366664797095,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 1.4187545144763029e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.42768235810405114,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.27060604095458984,
        "additional_info": {
            "duration": 0.2493879795074463,
            "num_run": 110,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012280702309800419,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09780396726688258,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 2.0637609893042342e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.012448596138154494,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1239008903503418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.802298965177013e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04544568333912144,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 0.00046303484468718573,
            "feature_preprocessor:select_rates_classification:alpha": 0.265166358598269,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10387110710144043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.2618906292878797e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8171286082577737,
            "classifier:CustomMLPClassifier:max_iter": 152,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 0.006629697164141229,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12475055967198885,
            "feature_preprocessor:select_rates_classification:alpha": 0.01598043294056787,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.2756998538970947,
        "additional_info": {
            "duration": 0.2647280693054199,
            "num_run": 113,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006243742121548578,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34747189261448863,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.004067699585579543,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003288528782377234,
            "feature_preprocessor:select_rates_classification:alpha": 0.3542324458173639,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12407898902893066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000355822700312519,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5462005992764009,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 0.0005223579895706979,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7003535681879177,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24848643421053127,
            "feature_preprocessor:select_rates_classification:alpha": 0.4917611952442679,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.36518335342407227,
        "additional_info": {
            "duration": 0.3529088497161865,
            "num_run": 115,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.87484696583781e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1510020882256647,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 2.0543456585826493e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1626100646105408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12960100173950195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00012827896315657436,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04068442649175846,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 1.684338513003935e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 19.67084109987706,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2500218398471148,
        "time": 0.37862682342529297,
        "additional_info": {
            "duration": 0.3489189147949219,
            "num_run": 117,
            "train_loss": 1.1528612022415239,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00026850701887830525,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05536416893420651,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.00745934439070208,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003721555628058811,
            "feature_preprocessor:select_rates_classification:alpha": 0.18572776266421537,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.216341990891823,
        "time": 0.2572650909423828,
        "additional_info": {
            "duration": 0.24513506889343262,
            "num_run": 118,
            "train_loss": 1.123051219913022,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010919066633626885,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0857057900969575,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 0.0017091771845632808,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004710693669341426,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1070,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.04015471364544084,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2958590440517403,
        "time": 0.37067389488220215,
        "additional_info": {
            "duration": 0.3542649745941162,
            "num_run": 119,
            "train_loss": 1.1294114194862908,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021479175725478878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18461130893254893,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.00046878172263510175,
            "feature_preprocessor:select_rates_classification:alpha": 0.013496691505056325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12398505210876465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004059426354586919,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05383004739574169,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 2.3477317652773916e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 71.11055588025691,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231194901842827,
        "time": 0.45452380180358887,
        "additional_info": {
            "duration": 0.43782806396484375,
            "num_run": 121,
            "train_loss": 1.0057991937137356,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00019855049922678394,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008634530662954269,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.004035904661196373,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015352434957872196,
            "feature_preprocessor:select_percentile_classification:percentile": 33.66748966342355,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.246916922099869,
        "time": 0.303617000579834,
        "additional_info": {
            "duration": 0.2774379253387451,
            "num_run": 122,
            "train_loss": 1.196382367381393,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005735923687500467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5517415437021799,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.00556349244267134,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1519652754251856,
            "feature_preprocessor:select_percentile_classification:percentile": 63.35937871307329,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2832137275583975,
        "time": 0.5192890167236328,
        "additional_info": {
            "duration": 0.5045812129974365,
            "num_run": 123,
            "train_loss": 1.0115983874274712,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.010829312457927641,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2103222815865972,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 1.6150711860674506e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21095373122449204,
            "feature_preprocessor:select_percentile_classification:percentile": 18.696734173831423,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2559538619436483,
        "time": 0.25413990020751953,
        "additional_info": {
            "duration": 0.2412121295928955,
            "num_run": 124,
            "train_loss": 1.1999300393418169,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02695376753866968,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007640361558921304,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 182,
            "classifier:CustomMLPClassifier:tol": 0.008611112623714869,
            "feature_preprocessor:select_rates_classification:alpha": 0.19755702902725883,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.2613711357116699,
        "additional_info": {
            "duration": 0.24934077262878418,
            "num_run": 125,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.973743482167676e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8348642410658051,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 0.0005561571693509892,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10552165504677985,
            "feature_preprocessor:select_rates_classification:alpha": 0.4470174609727579,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.25547099113464355,
        "additional_info": {
            "duration": 0.23771309852600098,
            "num_run": 126,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.857336812114243e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07613332241153382,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.0006309681834289492,
            "feature_preprocessor:select_rates_classification:alpha": 0.03984603148650633,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.24220991134643555,
        "additional_info": {
            "duration": 0.22620272636413574,
            "num_run": 127,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.5954720704682674e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4400513449996869,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.002590251792225422,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48926620506659824,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2495528981990782,
        "time": 0.7903599739074707,
        "additional_info": {
            "duration": 0.7797260284423828,
            "num_run": 128,
            "train_loss": 1.1432807511747742,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00399298528606468,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013905668630961098,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 0.00225659244477471,
            "feature_preprocessor:select_rates_classification:alpha": 0.1488418111280261,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.415421724319458,
        "additional_info": {
            "duration": 0.3937411308288574,
            "num_run": 129,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00012844356743979123,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8587063108598072,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 0.00048509243024968886,
            "feature_preprocessor:select_percentile_classification:percentile": 17.60864179754778,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2418308598991683,
        "time": 0.5753798484802246,
        "additional_info": {
            "duration": 0.5637421607971191,
            "num_run": 130,
            "train_loss": 1.1859557633918218,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6668031878206592e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06360054231375223,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 127,
            "classifier:CustomMLPClassifier:tol": 0.00034807681585062475,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03464800916506191,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20581125574533443,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2645422052722677,
        "time": 0.4456369876861572,
        "additional_info": {
            "duration": 0.43268489837646484,
            "num_run": 131,
            "train_loss": 1.1184192812466873,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.077686805332703e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4539463878481458,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 0.0008253501228896324,
            "feature_preprocessor:select_rates_classification:alpha": 0.19394836773244678,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.28264498710632324,
        "additional_info": {
            "duration": 0.2709488868713379,
            "num_run": 132,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000522524947606326,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7994596744628153,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.0021352932205894355,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 151,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4696056222324854,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.34389305114746094,
        "additional_info": {
            "duration": 0.32679176330566406,
            "num_run": 133,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0018748432553079343,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002498488854896659,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 5.263373689352799e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3709744500195208,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2389785629424366,
        "time": 1.5573017597198486,
        "additional_info": {
            "duration": 1.5319440364837646,
            "num_run": 134,
            "train_loss": 1.1282833699132255,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01619445877678236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004242174574749904,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.0007088242083781098,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008542414159696164,
            "feature_preprocessor:select_rates_classification:alpha": 0.22659415079676,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10238790512084961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.79192428359793e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0040600990455272445,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 8.303449374778764e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013199075266882997,
            "feature_preprocessor:select_rates_classification:alpha": 0.14031727004693084,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1262531280517578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.28873540676349e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5123841079976509,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.00033355739900037235,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025261527362089377,
            "feature_preprocessor:select_rates_classification:alpha": 0.4742592859303185,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2252365352809658,
        "time": 0.25051069259643555,
        "additional_info": {
            "duration": 0.23423480987548828,
            "num_run": 137,
            "train_loss": 1.1962355327177485,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010428591838017742,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0296889901536321,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.0005094467936957571,
            "feature_preprocessor:select_percentile_classification:percentile": 46.51433012029249,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.263089799168084,
        "time": 0.3295128345489502,
        "additional_info": {
            "duration": 0.29723501205444336,
            "num_run": 138,
            "train_loss": 1.1729792884156747,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.108444676414504e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.042407432737307564,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.00047801930017759875,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004984210536951151,
            "feature_preprocessor:select_percentile_classification:percentile": 83.80216763931605,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2829771484075083,
        "time": 0.32787203788757324,
        "additional_info": {
            "duration": 0.3106119632720947,
            "num_run": 139,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019182623498252935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005544846312019563,
            "classifier:CustomMLPClassifier:max_iter": 398,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.0009574634335331593,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.885098951858506,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21583572576762045,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.954866567440525,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2559934003515172,
        "time": 0.47644686698913574,
        "additional_info": {
            "duration": 0.46240687370300293,
            "num_run": 140,
            "train_loss": 1.1941608118376925,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0687192033533816,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003531740919681322,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.00011292850260553673,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17454555415786144,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7656647680494405,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.01678573235130874,
            "feature_preprocessor:select_percentile_classification:percentile": 92.60664631672324,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2208529290833323,
        "time": 0.6029810905456543,
        "additional_info": {
            "duration": 0.5794620513916016,
            "num_run": 141,
            "train_loss": 1.1725026778479744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9383555127645265e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004845184745721548,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 1.4123106633368891e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25141514351941724,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 111,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8772275463067547,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.23629296270843,
        "time": 0.8105289936065674,
        "additional_info": {
            "duration": 0.7973809242248535,
            "num_run": 142,
            "train_loss": 1.202762220948408,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00022511658067364814,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001232864989244194,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 0.00026256500095745106,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1392157653019924,
            "feature_preprocessor:select_percentile_classification:percentile": 85.40455710326549,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.25358983016921,
        "time": 1.1969990730285645,
        "additional_info": {
            "duration": 1.185196876525879,
            "num_run": 143,
            "train_loss": 1.1864267191070448,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.5215077142046176e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00045431558324448516,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 0.00029937293848262853,
            "feature_preprocessor:select_percentile_classification:percentile": 73.66818327346064,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.3061985969543457,
        "additional_info": {
            "duration": 0.28464794158935547,
            "num_run": 144,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0713230541966319,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009740544347907722,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.00021793165493856685,
            "feature_preprocessor:select_percentile_classification:percentile": 21.489190357671507,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2654933259306365,
        "time": 0.33466196060180664,
        "additional_info": {
            "duration": 0.31280517578125,
            "num_run": 145,
            "train_loss": 1.2295464832171596,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007133718445496048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13562960659781345,
            "classifier:CustomMLPClassifier:max_iter": 266,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 0.0006909533774616198,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003435096949793843,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 626,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 14.460003159985213,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2579976073756676,
        "time": 0.49029111862182617,
        "additional_info": {
            "duration": 0.47222399711608887,
            "num_run": 146,
            "train_loss": 1.2305428237298275,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.406727962914475e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005502361924648463,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 0.0008815689924155011,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7701444638443627,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04561896135907095,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5083748430918199,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2612916535955083,
        "time": 0.40107202529907227,
        "additional_info": {
            "duration": 0.3773519992828369,
            "num_run": 147,
            "train_loss": 1.1997778303140605,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7946752534188466e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5727341806883868,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 0.00023556792774318396,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8182105793264084,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10939273111247563,
            "feature_preprocessor:select_rates_classification:alpha": 0.12797294700101644,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.241204198817206,
        "time": 0.22446012496948242,
        "additional_info": {
            "duration": 0.20613312721252441,
            "num_run": 148,
            "train_loss": 1.2292744893215273,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002845937813867605,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017692801466329348,
            "classifier:CustomMLPClassifier:max_iter": 260,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.00045815266061824563,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015533898140603864,
            "feature_preprocessor:select_rates_classification:alpha": 0.49216416901574656,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1282329559326172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0453653786498561e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09901989098003562,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 351,
            "classifier:CustomMLPClassifier:tol": 0.005534830581160477,
            "feature_preprocessor:select_percentile_classification:percentile": 88.02794433049961,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2849569320678711,
        "additional_info": {
            "duration": 0.26746487617492676,
            "num_run": 150,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2510367783771022e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9634285220093852,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 0.009423202572245841,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009991566222962574,
            "feature_preprocessor:select_rates_classification:alpha": 0.484812265370199,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.544107844094213,
        "time": 0.25188302993774414,
        "additional_info": {
            "duration": 0.2278001308441162,
            "num_run": 151,
            "train_loss": 1.544258233216406,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00048154275304659026,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9175772606715992,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 2.3238202651446446e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000551982264211399,
            "feature_preprocessor:select_rates_classification:alpha": 0.18852482855255612,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09756112098693848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.716846968615297e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9972717820424638,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.002590251792225422,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1016,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4655378521228892,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.27933406829833984,
        "additional_info": {
            "duration": 0.26186299324035645,
            "num_run": 153,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.019947941937715912,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001789495542819479,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.0002688303784802554,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002922142680614139,
            "feature_preprocessor:select_rates_classification:alpha": 0.4974807352352167,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10151290893554688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.356247642710271e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8839994372828003,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.008811730481661643,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010615767273833398,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.97861315335639,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2447771234533782,
        "time": 0.43938279151916504,
        "additional_info": {
            "duration": 0.4175560474395752,
            "num_run": 155,
            "train_loss": 1.2025672755449057,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03213395468878592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00047252589707716657,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 0.0003706258204172507,
            "feature_preprocessor:select_rates_classification:alpha": 0.023744580230962434,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12880611419677734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.028811458470144304,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9968962513987087,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 1.1369735958782173e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02212764862226548,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9108415914401975,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09496905589525008,
            "feature_preprocessor:select_rates_classification:alpha": 0.16086976143106504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.3430494060909557,
        "time": 0.22988605499267578,
        "additional_info": {
            "duration": 0.21561074256896973,
            "num_run": 157,
            "train_loss": 1.3335574853490084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00046420422472286116,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002983693474558449,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 4.9122328369864674e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8889904053665045,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.265106308795421,
        "time": 1.0130360126495361,
        "additional_info": {
            "duration": 0.9940259456634521,
            "num_run": 158,
            "train_loss": 1.1898642549255711,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0599014682659118e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2324799516334292,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.00555445167501861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1634,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 48.82186580367314,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2639186089861634,
        "time": 0.3816561698913574,
        "additional_info": {
            "duration": 0.35950589179992676,
            "num_run": 159,
            "train_loss": 1.218091070061238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009862298953463534,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04275758537246873,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.0008609908772344251,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.050562619735770156,
            "feature_preprocessor:select_rates_classification:alpha": 0.09570877567335014,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12975287437438965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.014401089304258404,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014135672805901897,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 167,
            "classifier:CustomMLPClassifier:tol": 0.00013655494988685507,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010539510044364033,
            "feature_preprocessor:select_rates_classification:alpha": 0.19758181673720498,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3144528865814209,
        "additional_info": {
            "duration": 0.3013598918914795,
            "num_run": 161,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02161627799622286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7716238436517284,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.006828535735877745,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016042642867714698,
            "feature_preprocessor:select_rates_classification:alpha": 0.3957398144475482,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12668323516845703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03642034018870879,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035800744290818407,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.007852131546652897,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.23838324826018664,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2592389308746899,
        "time": 0.35358285903930664,
        "additional_info": {
            "duration": 0.32329583168029785,
            "num_run": 163,
            "train_loss": 1.1718803590786078,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.4416979444194844e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021192331522445416,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 0.00017696593590208192,
            "feature_preprocessor:select_rates_classification:alpha": 0.44669336560812734,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13431620597839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.019514413754367577,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016305043870337897,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.0006007035847577206,
            "feature_preprocessor:select_rates_classification:alpha": 0.4872504660470439,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.26531100273132324,
        "additional_info": {
            "duration": 0.2521970272064209,
            "num_run": 165,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00019200718155075596,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8322161150018091,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.006483420390252153,
            "feature_preprocessor:select_rates_classification:alpha": 0.2546413572269813,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15900015830993652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011114865219583937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016686506400490923,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.0017493735704828437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003324430338497419,
            "feature_preprocessor:select_rates_classification:alpha": 0.19040741738965306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09794831275939941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.593965986922667e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1463287100752062,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 1.1023840629028353e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9791218619010673,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03419130390224963,
            "feature_preprocessor:select_rates_classification:alpha": 0.02065410288892483,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.36607813835144043,
        "additional_info": {
            "duration": 0.3485686779022217,
            "num_run": 168,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.010949359863427986,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12505324551806843,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.0011201042823598454,
            "feature_preprocessor:select_rates_classification:alpha": 0.3333848604634503,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10248827934265137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002849675804826954,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019216841136874873,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.005768931755244509,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013447628037342493,
            "feature_preprocessor:select_rates_classification:alpha": 0.015510080872885235,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12314820289611816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.077313941171335e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.039077383050962575,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 0.007532673704892546,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00031997600453198576,
            "feature_preprocessor:select_rates_classification:alpha": 0.280201793968159,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1250770092010498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.2406286668363826e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.050294698452302236,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.0005183689198396581,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01192166155693923,
            "feature_preprocessor:select_percentile_classification:percentile": 4.636816451523522,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.18363499641418457,
        "additional_info": {
            "duration": 0.16928386688232422,
            "num_run": 172,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002191030706160618,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014945325940118564,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 4.731360850463681e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.10003664799480483,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1257326602935791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00792312786317677,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03071702384599385,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0017297540485289266,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002706492353236932,
            "feature_preprocessor:select_rates_classification:alpha": 0.4877802787473961,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12716078758239746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019861017117465,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5478763079415024,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.0007052362948322972,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21624281777938614,
            "feature_preprocessor:select_rates_classification:alpha": 0.4864559450409917,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2386641890929586,
        "time": 0.2347550392150879,
        "additional_info": {
            "duration": 0.22271490097045898,
            "num_run": 175,
            "train_loss": 1.2257684762771905,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0020159916350552935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001787544541520572,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 5.9810598555303e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023106005284511487,
            "feature_preprocessor:select_rates_classification:alpha": 0.08794025145074641,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12445688247680664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.9139706627023402e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016563996941072287,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 1.2818135012837419e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.21411289512326892,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.232911079482827,
        "time": 0.4960649013519287,
        "additional_info": {
            "duration": 0.4790527820587158,
            "num_run": 177,
            "train_loss": 1.1468336949861535,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009836740634863522,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001587665350129046,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 6.60847943039091e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010211198409549543,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8684763691721276,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.006689114815525222,
            "feature_preprocessor:select_percentile_classification:percentile": 89.95084200865328,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2663353731110116,
        "time": 0.9162499904632568,
        "additional_info": {
            "duration": 0.9011750221252441,
            "num_run": 178,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.470681264295124e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026872601422538205,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.004715859078011628,
            "feature_preprocessor:select_rates_classification:alpha": 0.06642027860331687,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12867307662963867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4086210042555889e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011068771220284323,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 0.0003292269283362887,
            "feature_preprocessor:select_rates_classification:alpha": 0.4035611723663658,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13639092445373535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1119130035953713e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05883357183951316,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 0.0015636676479340997,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03684926615934678,
            "feature_preprocessor:select_rates_classification:alpha": 0.3326255027698023,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.33269619941711426,
        "additional_info": {
            "duration": 0.3189890384674072,
            "num_run": 181,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0969509994436055e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010663279955156636,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.0051225487284249594,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7356727063431923,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2712069835333059,
            "feature_preprocessor:select_rates_classification:alpha": 0.4801885706682373,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2341724007566865,
        "time": 0.27495408058166504,
        "additional_info": {
            "duration": 0.254669189453125,
            "num_run": 182,
            "train_loss": 1.2293714232934492,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00014474289570578835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4597771563325016,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.002608939632301858,
            "feature_preprocessor:select_rates_classification:alpha": 0.4758625430282574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09863591194152832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.824072580863091e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012672617602564303,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.008027324567934422,
            "feature_preprocessor:select_rates_classification:alpha": 0.19582496752766762,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1252140998840332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0889658780418269,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005279825199353347,
            "classifier:CustomMLPClassifier:max_iter": 109,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 1.1563803967347998e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007285243515909401,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9768465733228042,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08630439260126603,
            "feature_preprocessor:select_percentile_classification:percentile": 12.091365525994618,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2317365736161106,
        "time": 0.29550719261169434,
        "additional_info": {
            "duration": 0.2748119831085205,
            "num_run": 185,
            "train_loss": 1.2230283707613376,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00017899793648582676,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10380382317146124,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 4.5808839472391204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 905,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4768857081964814,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2432791796088747,
        "time": 0.43291401863098145,
        "additional_info": {
            "duration": 0.41658496856689453,
            "num_run": 186,
            "train_loss": 1.0625456473387456,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.1703047917888756e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8551656777921417,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 5.8226572986187124e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19585659598383368,
            "feature_preprocessor:select_rates_classification:alpha": 0.23815610926353367,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09783601760864258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.7982351834743454e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0030037625137170273,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 59,
            "classifier:CustomMLPClassifier:tol": 0.004235492759982511,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001176779272758612,
            "feature_preprocessor:select_percentile_classification:percentile": 8.502661191603737,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.2372138500213623,
        "additional_info": {
            "duration": 0.21966218948364258,
            "num_run": 188,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017125709716469789,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00223562580038445,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 392,
            "classifier:CustomMLPClassifier:tol": 0.0002798704115087668,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16056982877928136,
            "feature_preprocessor:select_rates_classification:alpha": 0.29905324803942346,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10336494445800781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.560705488459092e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10940197849223524,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 4.339394495359343e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49745704420292247,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.2599358558654785,
        "additional_info": {
            "duration": 0.23817086219787598,
            "num_run": 190,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0033835902324646284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004388450720431388,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.00023061215571297482,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016137091443313895,
            "feature_preprocessor:select_rates_classification:alpha": 0.1805200901431894,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1237189769744873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03214034987487975,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.40929974093280186,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 5.1655613278224515e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09185666286323697,
            "feature_preprocessor:select_rates_classification:alpha": 0.45696246181569944,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.098358154296875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00015064778648480866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5732533011433991,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 381,
            "classifier:CustomMLPClassifier:tol": 0.004639661213641785,
            "feature_preprocessor:select_rates_classification:alpha": 0.18477031614171457,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.28927111625671387,
        "additional_info": {
            "duration": 0.2677121162414551,
            "num_run": 193,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4607574805963824e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012934188990823473,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.0006966352638060495,
            "feature_preprocessor:select_rates_classification:alpha": 0.1153963107449858,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.2832181453704834,
        "additional_info": {
            "duration": 0.27150797843933105,
            "num_run": 194,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008499094883829611,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1336062665805855,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 313,
            "classifier:CustomMLPClassifier:tol": 0.0001261796265191977,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9957676576765211,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08015519588407749,
            "feature_preprocessor:select_rates_classification:alpha": 0.37228999262729134,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.27619194984436035,
        "additional_info": {
            "duration": 0.2624976634979248,
            "num_run": 195,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.055209082326169e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014094972812097107,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.00015130292173796115,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.181236344085895,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9988199868996971,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.14764332770489125,
            "feature_preprocessor:select_rates_classification:alpha": 0.0103485573863111,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2216311365877501,
        "time": 0.3635730743408203,
        "additional_info": {
            "duration": 0.34821581840515137,
            "num_run": 196,
            "train_loss": 1.2218019267551705,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.486056884236712e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029941553922744296,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.00427501752424557,
            "feature_preprocessor:select_rates_classification:alpha": 0.2991328482447572,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12970376014709473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000853536883798622,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029943251402561977,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 185,
            "classifier:CustomMLPClassifier:tol": 0.0013841227593488273,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7276545839458063,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2570677666092849,
        "time": 0.3934133052825928,
        "additional_info": {
            "duration": 0.37670397758483887,
            "num_run": 198,
            "train_loss": 1.2027182555975275,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010340239000916865,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21553492812931083,
            "classifier:CustomMLPClassifier:max_iter": 357,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.007360502462590967,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23235530540467936,
            "feature_preprocessor:select_percentile_classification:percentile": 10.711191983626481,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2451349050064278,
        "time": 0.2470090389251709,
        "additional_info": {
            "duration": 0.23652219772338867,
            "num_run": 199,
            "train_loss": 1.229676121837327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06375463745502327,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.39875422779787834,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00011549000222021162,
            "feature_preprocessor:select_percentile_classification:percentile": 22.789069761824056,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.23158597946166992,
        "additional_info": {
            "duration": 0.21641898155212402,
            "num_run": 200,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0027621739568657352,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046081627898465787,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.005045683690677366,
            "feature_preprocessor:select_rates_classification:alpha": 0.2559893005934169,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1294081211090088,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0024334663675531624,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4654920325932834,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 1.6165693461328198e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1452,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7731358817229493,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2806017922087476,
        "time": 0.40833401679992676,
        "additional_info": {
            "duration": 0.3961648941040039,
            "num_run": 202,
            "train_loss": 1.1645494083272596,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00141717189209717,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007164384596527473,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.00026657339692291146,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011099014840428251,
            "feature_preprocessor:select_rates_classification:alpha": 0.08740430004566249,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12396740913391113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005898806757059531,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09329396062348065,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 3.621905507674466e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.363439355371,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1241610050201416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4762585108821473e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025701341143934613,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 0.0012553498860268292,
            "feature_preprocessor:select_rates_classification:alpha": 0.28877232010187365,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09765887260437012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.7771810358981836e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9580053370719089,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 175,
            "classifier:CustomMLPClassifier:tol": 5.65584945785682e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009742349039408975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1342,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.44247908423218485,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.3276491165161133,
        "additional_info": {
            "duration": 0.3054389953613281,
            "num_run": 206,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0021993722006022906,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004927855321430168,
            "classifier:CustomMLPClassifier:max_iter": 481,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 4.667464631318572e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01809471395040149,
            "feature_preprocessor:select_rates_classification:alpha": 0.3097786923152878,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.23624751180762,
        "time": 0.7271299362182617,
        "additional_info": {
            "duration": 0.7136228084564209,
            "num_run": 207,
            "train_loss": 1.171592625092161,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05400725066442495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8951790214476346,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 2.8066634493130547e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4718769005174555,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10218214988708496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.138774520911323e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000301999965557263,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.0007259776483126823,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005954993777139305,
            "feature_preprocessor:select_rates_classification:alpha": 0.21279148403760814,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13054680824279785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007125920767915169,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02734138187071959,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 9.099208554264384e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004576897107652537,
            "feature_preprocessor:select_rates_classification:alpha": 0.2443000262240326,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1240999698638916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.120814760449291e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006060424809104468,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 6.744319374657618e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2584969139968616,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10451984405517578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.1359839151097055e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008869365449371166,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 2.4350855549607917e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025154217897406235,
            "feature_preprocessor:select_rates_classification:alpha": 0.16246914466963458,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09791207313537598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00039805519659609636,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00629872976094333,
            "classifier:CustomMLPClassifier:max_iter": 109,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.001993391795544388,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11170128902913735,
            "feature_preprocessor:select_rates_classification:alpha": 0.2885737566028879,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1313788890838623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005249751457431408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001170581704555663,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0006909705268715862,
            "feature_preprocessor:select_rates_classification:alpha": 0.4616475905947055,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09644007682800293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.940208644623843e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22095121830764394,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 9.35637602797772e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015388718897614207,
            "feature_preprocessor:select_percentile_classification:percentile": 18.676696935137347,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2773549556732178,
        "additional_info": {
            "duration": 0.25517916679382324,
            "num_run": 215,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4609288817762624e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00247508675312853,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 1.6914796325427648e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11594702072993522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12329626083374023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004263198304163233,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.329323056139454,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 0.00020251926865003526,
            "feature_preprocessor:select_rates_classification:alpha": 0.02786945093415425,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5763208866119385,
        "additional_info": {
            "duration": 0.5612270832061768,
            "num_run": 217,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.07740033011212e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03981175562809039,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.00904604475950466,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07343907983746334,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2579147046839823,
        "time": 0.7857937812805176,
        "additional_info": {
            "duration": 0.771165132522583,
            "num_run": 218,
            "train_loss": 1.04132604490437,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012133393688212585,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07676479299506563,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 3.733948747984262e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8506476939903926,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2425656162802596,
        "time": 0.4380829334259033,
        "additional_info": {
            "duration": 0.4253368377685547,
            "num_run": 219,
            "train_loss": 1.0708036644056578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.024203185789425583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08041854383454408,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 9.876673223555849e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.02470765051274787,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09656596183776855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05032776922929074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001579117431243439,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 0.0011907610683885744,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05006468892512977,
            "feature_preprocessor:select_rates_classification:alpha": 0.34242597915742007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10640311241149902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.28873540676349e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9821012639291771,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 4.3884572689311055e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005722596256686823,
            "feature_preprocessor:select_rates_classification:alpha": 0.4716403115999732,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2691390241118108,
        "time": 0.2451009750366211,
        "additional_info": {
            "duration": 0.23339176177978516,
            "num_run": 222,
            "train_loss": 1.2062540033654299,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.218208018496169e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19033087340107227,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 364,
            "classifier:CustomMLPClassifier:tol": 0.0001102155221262659,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09426022620660589,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8317615616672717,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2515511493105325,
        "time": 0.44786524772644043,
        "additional_info": {
            "duration": 0.42456507682800293,
            "num_run": 223,
            "train_loss": 1.1917614579316473,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003034167209614272,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010291340908065563,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 211,
            "classifier:CustomMLPClassifier:tol": 3.802292563849469e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016804043051294824,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4698173353582764,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.34260988235473633,
        "additional_info": {
            "duration": 0.32892513275146484,
            "num_run": 224,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004228850041398055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004003324035384527,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.0014264464701033788,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012107023405901028,
            "feature_preprocessor:select_rates_classification:alpha": 0.49534688645244934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12405610084533691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00019225500809756958,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.416587389873045,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 4.3765976606133154e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4464041241726796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2452916028417345,
        "time": 0.4185667037963867,
        "additional_info": {
            "duration": 0.40364718437194824,
            "num_run": 226,
            "train_loss": 1.2064362276051173,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.537240810254734e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.848098064297979,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 0.00012762377399724623,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012099691458898967,
            "feature_preprocessor:select_rates_classification:alpha": 0.44793047441404965,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0992279052734375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006333214511757206,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007628131577609522,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 7.038068344734047e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.43657283968101723,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12791204452514648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.857250658682777e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016896301115745032,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 335,
            "classifier:CustomMLPClassifier:tol": 5.207552275612238e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.13155287359565196,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12432003021240234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06295132505010351,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.997551394807095,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 2.5851889484019633e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000140494219582111,
            "feature_preprocessor:select_rates_classification:alpha": 0.027347145587382306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12643694877624512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.82976634296681e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019339192405036917,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 0.0002476110330413378,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002472129749436908,
            "feature_preprocessor:select_rates_classification:alpha": 0.45284874401507963,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.36613011360168457,
        "additional_info": {
            "duration": 0.34551310539245605,
            "num_run": 231,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3214262179642567e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020258802913280076,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 1.3900507425717771e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13815208690408973,
            "feature_preprocessor:select_percentile_classification:percentile": 65.96898689423995,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2265929315904325,
        "time": 0.30225515365600586,
        "additional_info": {
            "duration": 0.28491806983947754,
            "num_run": 232,
            "train_loss": 1.1856697213526008,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000266316522130703,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002869807979982,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 0.0007126519988473241,
            "feature_preprocessor:select_rates_classification:alpha": 0.2120021522324822,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13090896606445312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02338821317431185,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10420870278211374,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 1.660660021698691e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01695172321398373,
            "feature_preprocessor:select_percentile_classification:percentile": 9.309147266381876,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2427606572457963,
        "time": 0.32131314277648926,
        "additional_info": {
            "duration": 0.3098022937774658,
            "num_run": 234,
            "train_loss": 1.240364456508985,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7380673645301582e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008432565003274734,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 4.519081618396949e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.0645157199151615,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10367417335510254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002257896141759253,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9782746181074966,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 0.009119228060188642,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 157,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.41787164439751234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2400680360807192,
        "time": 0.4981110095977783,
        "additional_info": {
            "duration": 0.480787992477417,
            "num_run": 236,
            "train_loss": 1.2420562013778982,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.8452920938650626e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7395575084510209,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.004335367587623273,
            "feature_preprocessor:select_rates_classification:alpha": 0.28425336906030735,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.29720306396484375,
        "additional_info": {
            "duration": 0.27332019805908203,
            "num_run": 237,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011751948235718505,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006368762313841435,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.00035429472166676954,
            "feature_preprocessor:select_percentile_classification:percentile": 24.546111761177617,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.31362009048461914,
        "additional_info": {
            "duration": 0.298022985458374,
            "num_run": 238,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004721364239756484,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24496281571869002,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.005638581982637387,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007238333085731278,
            "feature_preprocessor:select_percentile_classification:percentile": 92.55533185381907,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.41930603981018066,
        "additional_info": {
            "duration": 0.39442920684814453,
            "num_run": 239,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006016072595724455,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12540069112323723,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 250,
            "classifier:CustomMLPClassifier:tol": 0.00010629832603543348,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013739087081843881,
            "feature_preprocessor:select_rates_classification:alpha": 0.39731285746118306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13124990463256836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.497371992190807e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.168745672239603,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 0.0005817595088189682,
            "feature_preprocessor:select_rates_classification:alpha": 0.020447411357569827,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12441277503967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.7113394734915828e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016016961831060814,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0008231137374015039,
            "feature_preprocessor:select_percentile_classification:percentile": 54.04090631370644,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.31145524978637695,
        "additional_info": {
            "duration": 0.298846960067749,
            "num_run": 242,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008639067892253202,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007556165135508723,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.0007760616370765646,
            "feature_preprocessor:select_rates_classification:alpha": 0.30633564696897836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09801506996154785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.468864626731953e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003162820802979165,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.0011013973257233583,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000360823121577377,
            "feature_preprocessor:select_rates_classification:alpha": 0.17839220091535765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10031986236572266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.740192232706111e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019469118313039748,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 3.0051854179276014e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010451240979173625,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9140160024985237,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21788914862167394,
            "feature_preprocessor:select_rates_classification:alpha": 0.16867522619267236,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2221183801714242,
        "time": 1.462406873703003,
        "additional_info": {
            "duration": 1.4364540576934814,
            "num_run": 245,
            "train_loss": 1.132103930745214,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013057626663423992,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001917183135141749,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 2.1261070755439487e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 49.63128127172513,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2285223652920971,
        "time": 1.1629798412322998,
        "additional_info": {
            "duration": 1.150801181793213,
            "num_run": 246,
            "train_loss": 1.2282906874889483,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0893591334186826e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003794873168343954,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.0012717919956036776,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14264863696114274,
            "feature_preprocessor:select_percentile_classification:percentile": 9.774814051356458,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2333749565575216,
        "time": 0.3211700916290283,
        "additional_info": {
            "duration": 0.3080260753631592,
            "num_run": 247,
            "train_loss": 1.2187008991528354,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0604382305742599e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9051323052905238,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 0.00014550465816985306,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03408652622958758,
            "feature_preprocessor:select_rates_classification:alpha": 0.4861587344493988,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.3028221130371094,
        "additional_info": {
            "duration": 0.2805061340332031,
            "num_run": 248,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025884197716302453,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1382878831804891,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0010500223175773685,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012520102933399486,
            "feature_preprocessor:select_percentile_classification:percentile": 88.91610391231609,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.4636521339416504,
        "additional_info": {
            "duration": 0.4435720443725586,
            "num_run": 249,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005838780055567471,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020849251676067254,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.00015091022985089364,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015266689837365946,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8259397618224519,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2658888515994745,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27375231402812916,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2702822077793678,
        "time": 0.8077178001403809,
        "additional_info": {
            "duration": 0.794497013092041,
            "num_run": 250,
            "train_loss": 1.1261459781753127,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02311006213820138,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5565987784652686,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 2.316871675914156e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7264140628865225,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_rates_classification:alpha": 0.4793805271834825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2209559598091198,
        "time": 0.2995901107788086,
        "additional_info": {
            "duration": 0.2854752540588379,
            "num_run": 251,
            "train_loss": 1.2085867725106862,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006363153138314282,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08232174852996015,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0005340473954706137,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0549783603285897,
            "feature_preprocessor:select_rates_classification:alpha": 0.35651661378159283,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0978250503540039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.575677496062885e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011483294542110948,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.00038898712034977163,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010479498681397312,
            "feature_preprocessor:select_rates_classification:alpha": 0.041035439797764015,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13112592697143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04410363870933279,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09323830466715027,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.004803090277665739,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003296921146540173,
            "feature_preprocessor:select_percentile_classification:percentile": 83.68928087706267,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.3919060230255127,
        "additional_info": {
            "duration": 0.3776240348815918,
            "num_run": 254,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01735513294818531,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020786677694016045,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 3.2381162367756366e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3564883063646971,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09764218330383301,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00016218232048315602,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011821341048730502,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 1.3298377465155614e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2374968845058336,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.2903628349304199,
        "additional_info": {
            "duration": 0.2723720073699951,
            "num_run": 256,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.020734966248598132,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9343397417667137,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 1.980628955618963e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.027347145587382306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10980892181396484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.059354815458519e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8322161150018091,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.006483420390252153,
            "feature_preprocessor:select_rates_classification:alpha": 0.3023594240018523,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12468886375427246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.137797079274348e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009269952478709936,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.0007500723595869134,
            "feature_preprocessor:select_rates_classification:alpha": 0.01316651665313741,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1017918586730957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7525841026060547e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9966356755082696,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 4.403536494426972e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008637096077238032,
            "feature_preprocessor:select_rates_classification:alpha": 0.44951130079377233,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12810015678405762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.554904089599259e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02321795473897283,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 4.189467539734755e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.28960956506732394,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12920117378234863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017756047038409721,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001745074541892883,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 1.74484239509297e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45102537114637453,
            "feature_preprocessor:select_rates_classification:alpha": 0.1968553531430199,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13297605514526367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006114314558619921,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020041813982340183,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.0012441682319016677,
            "feature_preprocessor:select_rates_classification:alpha": 0.299525464212793,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12930989265441895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002939942605567634,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05919405689441784,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 254,
            "classifier:CustomMLPClassifier:tol": 0.0020782145758839513,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.33664579812578393,
            "feature_preprocessor:select_rates_classification:alpha": 0.10601199827843782,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12515711784362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008882598194344572,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001415471467622853,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.00020548726277064798,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01727584305098353,
            "feature_preprocessor:select_percentile_classification:percentile": 64.49221996142197,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2578824911454682,
        "time": 0.3439619541168213,
        "additional_info": {
            "duration": 0.3267381191253662,
            "num_run": 265,
            "train_loss": 1.180145259973132,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.7549778180835954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.046317615065201864,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 3.496164842846594e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 10.302057321701316,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.3122875632865723,
        "time": 0.5737779140472412,
        "additional_info": {
            "duration": 0.551044225692749,
            "num_run": 266,
            "train_loss": 1.2692617011538765,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011077703524632084,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020928501924104945,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 240,
            "classifier:CustomMLPClassifier:tol": 0.00027015472941160424,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17923311063626823,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2267020484881808,
        "time": 0.7849569320678711,
        "additional_info": {
            "duration": 0.7682898044586182,
            "num_run": 267,
            "train_loss": 1.1949481588032698,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03302905053279808,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014921707609813546,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 1.753678076748929e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.32831705991158194,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2436714349964513,
        "time": 2.4499289989471436,
        "additional_info": {
            "duration": 2.4329988956451416,
            "num_run": 268,
            "train_loss": 1.1693591453559393,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00888825077227281,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023029430654970978,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 0.0012580205279159311,
            "feature_preprocessor:select_rates_classification:alpha": 0.10539607345633212,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12491202354431152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.05755254245583408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014208957653885463,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 0.0004287809004380858,
            "feature_preprocessor:select_percentile_classification:percentile": 48.32884780372731,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.4469871520996094,
        "additional_info": {
            "duration": 0.43424510955810547,
            "num_run": 270,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01608549648049121,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014440762841004284,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 3.3390135774427966e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018797458034282507,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1445,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7807961681787169,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2472130374334642,
        "time": 3.2263081073760986,
        "additional_info": {
            "duration": 3.207134962081909,
            "num_run": 271,
            "train_loss": 1.023153655477675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014829469548001411,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13714734861785513,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 4.5703362023306846e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9514100623455656,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24439997722675197,
            "feature_preprocessor:select_rates_classification:alpha": 0.3611481439305579,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2264837278531746,
        "time": 0.3442811965942383,
        "additional_info": {
            "duration": 0.3286929130554199,
            "num_run": 272,
            "train_loss": 1.1873359258892453,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.273999441589187e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08273866447450508,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 4.5808839472391204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4768857081964814,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2310350957919076,
        "time": 0.3427300453186035,
        "additional_info": {
            "duration": 0.3216238021850586,
            "num_run": 273,
            "train_loss": 1.2222720364967807,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0038448505407697666,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5603934864973508,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 2.750308417701877e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.16444903979567982,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.246077299118042,
        "additional_info": {
            "duration": 0.23107194900512695,
            "num_run": 274,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05081224641566875,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21646956168476816,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 9.856654698377726e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.331841892910314,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 457,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 22.130238292391578,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.236706324308973,
        "time": 0.37621307373046875,
        "additional_info": {
            "duration": 0.35672712326049805,
            "num_run": 275,
            "train_loss": 1.1957972816507711,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001569625694227255,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024115763072555005,
            "classifier:CustomMLPClassifier:max_iter": 392,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 1.3239929293254544e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023731012537834452,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2857224566893679,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.259489508467965,
        "time": 1.0176200866699219,
        "additional_info": {
            "duration": 0.9992308616638184,
            "num_run": 276,
            "train_loss": 1.0736178039951594,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07426564322096857,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000376022801836308,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 1.7637364236124833e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023176571415063022,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21460232539499413,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.232801875745569,
        "time": 0.858863115310669,
        "additional_info": {
            "duration": 0.8455331325531006,
            "num_run": 277,
            "train_loss": 1.1294304589924695,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021479175725478878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.49807244393171224,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.0003024664346438723,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010520993133068786,
            "feature_preprocessor:select_rates_classification:alpha": 0.010468189601413583,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13028883934020996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0394593423333572,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9659746276466369,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 7.858673489656356e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1987,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9150941836538847,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2686437814182019,
        "time": 0.44293808937072754,
        "additional_info": {
            "duration": 0.4255530834197998,
            "num_run": 279,
            "train_loss": 1.2858078040104692,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007095192089340736,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0032721272148131513,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.0037836368067505595,
            "feature_preprocessor:select_rates_classification:alpha": 0.12598204646344885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12955689430236816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09527327752612183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.997551394807095,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 7.249120444604048e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000140494219582111,
            "feature_preprocessor:select_rates_classification:alpha": 0.02693378098671282,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.2982821464538574,
        "additional_info": {
            "duration": 0.27520012855529785,
            "num_run": 281,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04191545192966636,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14250253737249524,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 0.0007616206340161957,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1264,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 51.7509492795282,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.351187957626776,
        "time": 0.4289400577545166,
        "additional_info": {
            "duration": 0.4101450443267822,
            "num_run": 282,
            "train_loss": 1.1897655800041038,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001081956863519561,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0042829334129634725,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 0.00020738763296534728,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000122667171833763,
            "feature_preprocessor:select_rates_classification:alpha": 0.2146842633296422,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.24320387840270996,
        "additional_info": {
            "duration": 0.22667503356933594,
            "num_run": 283,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002712979471843978,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000191112280520305,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.0006974758828108521,
            "feature_preprocessor:select_rates_classification:alpha": 0.3950467345378597,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12346792221069336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006583441220928236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012519174051865413,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 8.409819782009041e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032120509533773345,
            "feature_preprocessor:select_rates_classification:alpha": 0.06919705243231894,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2440261517536428,
        "time": 0.32224178314208984,
        "additional_info": {
            "duration": 0.30174803733825684,
            "num_run": 285,
            "train_loss": 1.2466764963400765,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.654167473355721e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9730723459784645,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 3.34239654770731e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009710309432324985,
            "feature_preprocessor:select_rates_classification:alpha": 0.4680926972040969,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.3113333778323457,
        "time": 0.27376484870910645,
        "additional_info": {
            "duration": 0.25899291038513184,
            "num_run": 286,
            "train_loss": 1.2538427528944167,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004565496293744513,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10720347423273778,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 2.3377598294740505e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009790533049320784,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 474,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2686035546998614,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2755077743178669,
        "time": 0.4727938175201416,
        "additional_info": {
            "duration": 0.4588007926940918,
            "num_run": 287,
            "train_loss": 1.1118069197467406,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.555781400078711e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024552644797401577,
            "classifier:CustomMLPClassifier:max_iter": 461,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 0.0001496034721226662,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27852218238697607,
            "feature_preprocessor:select_rates_classification:alpha": 0.21545203034173124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09732508659362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.26861274866427e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3021791729128538,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 0.0010990773226103462,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2137698878628031,
            "feature_preprocessor:select_rates_classification:alpha": 0.33690177674265254,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1251220703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018134461597821898,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09497105944364194,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 246,
            "classifier:CustomMLPClassifier:tol": 0.009761035035719954,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 977,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.41597447471331717,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.244437556996457,
        "time": 0.46993398666381836,
        "additional_info": {
            "duration": 0.4553110599517822,
            "num_run": 290,
            "train_loss": 1.1531103942435217,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0045509193856971275,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4392507828047694,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.005274682539378488,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42281926100359934,
            "feature_preprocessor:select_rates_classification:alpha": 0.06818396947815468,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1247861385345459,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025689511389662023,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007095375623229308,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 126,
            "classifier:CustomMLPClassifier:tol": 0.000551038467725666,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002927911350034555,
            "feature_preprocessor:select_rates_classification:alpha": 0.1037592501974042,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12400984764099121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010846051140657219,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08414242496235201,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 1.9492267991077083e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07968943455048823,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1292099952697754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.953447885156651e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28202253054881143,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 0.0001554261288164516,
            "feature_preprocessor:select_rates_classification:alpha": 0.3177236476856252,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12458395957946777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04824063419229205,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.86333382381826,
            "classifier:CustomMLPClassifier:max_iter": 426,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 2.091188427682118e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3432730000976894,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09892988204956055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.696783974661984e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006734238736580373,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.0005621171185110886,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12862392380855234,
            "feature_preprocessor:select_percentile_classification:percentile": 61.68192728564077,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2429386783928438,
        "time": 0.9128351211547852,
        "additional_info": {
            "duration": 0.8992338180541992,
            "num_run": 296,
            "train_loss": 1.0242831655119202,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00014181211624464805,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.40219023529787007,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.00023240472198225875,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7454644902134332,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19547802306949197,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49700785648532386,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2197673686605073,
        "time": 0.3077051639556885,
        "additional_info": {
            "duration": 0.2866249084472656,
            "num_run": 297,
            "train_loss": 1.1951738364194266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.245165291175976e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5193878094635574,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.002803747970096579,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6699002794611101,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.31643128395080566,
        "additional_info": {
            "duration": 0.3023989200592041,
            "num_run": 298,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08585603073778844,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0032261138681202828,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 0.00039614494082798016,
            "feature_preprocessor:select_rates_classification:alpha": 0.40871951379810184,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5114502906799316,
        "additional_info": {
            "duration": 0.49033498764038086,
            "num_run": 299,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.421617033650687e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005921722966608941,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.004769773093539885,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16820799163555786,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1554,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1119244340812312,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2108253301733156,
        "time": 0.28568196296691895,
        "additional_info": {
            "duration": 0.27220797538757324,
            "num_run": 300,
            "train_loss": 1.1945634418425817,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.90819927507654e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5238018538208884,
            "classifier:CustomMLPClassifier:max_iter": 277,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.0069175147253301575,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015368478282018873,
            "feature_preprocessor:select_percentile_classification:percentile": 54.52103352852108,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.544107844094213,
        "time": 0.3409237861633301,
        "additional_info": {
            "duration": 0.31757307052612305,
            "num_run": 301,
            "train_loss": 1.544258233216406,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000296459926737833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001440344671959531,
            "classifier:CustomMLPClassifier:max_iter": 461,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.0003245541005411413,
            "feature_preprocessor:select_rates_classification:alpha": 0.3531878149219795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12451481819152832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01594940279906264,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002091406450299441,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.00317425676011736,
            "feature_preprocessor:select_rates_classification:alpha": 0.25497589248545993,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.21657299995422363,
        "additional_info": {
            "duration": 0.20507192611694336,
            "num_run": 303,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00069367446638502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031307542859456794,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.002629073274271129,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008498968537002057,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9977214548391846,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.00520314867019085,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3475914481264516,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2579734363668433,
        "time": 0.3596000671386719,
        "additional_info": {
            "duration": 0.3405461311340332,
            "num_run": 304,
            "train_loss": 1.1905894430077018,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04621433181658208,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5112204125119626,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 175,
            "classifier:CustomMLPClassifier:tol": 0.009761617653297052,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1832,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.34647700608057413,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2777192814909855,
        "time": 0.3564186096191406,
        "additional_info": {
            "duration": 0.3416738510131836,
            "num_run": 305,
            "train_loss": 1.221704146809636,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.595685098153112e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17071471519487094,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 2.337497567855582e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3041276118549498,
            "feature_preprocessor:select_rates_classification:alpha": 0.12818199690174198,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12932300567626953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010349864271467284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00025302329290793896,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 4.4379745561644e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.058855677267807924,
            "feature_preprocessor:select_rates_classification:alpha": 0.11707188143043051,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2097781997202302,
        "time": 0.684762716293335,
        "additional_info": {
            "duration": 0.6651649475097656,
            "num_run": 307,
            "train_loss": 1.2000581684984848,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.256988826769837e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5616849176668373,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 1.0468093450249858e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2954910921014962,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1252143383026123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0017284588944287698,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20133630246669565,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.0010282635807136319,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9535113447158678,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2526952677371992,
        "time": 0.5153460502624512,
        "additional_info": {
            "duration": 0.48196911811828613,
            "num_run": 309,
            "train_loss": 1.1874890298929341,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.1672933749844804e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7991821366317732,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 6.334467919413245e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015559523221256932,
            "feature_preprocessor:select_rates_classification:alpha": 0.012853912584228711,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09855175018310547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009535048917264893,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9978999015021389,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 4.3765976606133154e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007870872733155794,
            "feature_preprocessor:select_rates_classification:alpha": 0.4991412394229272,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2552150625878349,
        "time": 0.3544800281524658,
        "additional_info": {
            "duration": 0.337573766708374,
            "num_run": 311,
            "train_loss": 1.170304253688593,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00106518902062397,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005354018130446106,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 0.0063476528872463385,
            "feature_preprocessor:select_rates_classification:alpha": 0.21917105270909826,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12378430366516113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001342096477352012,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7678311203408031,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.0006952033355598732,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005334330147139957,
            "feature_preprocessor:select_rates_classification:alpha": 0.1951746759103363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1038200855255127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000347926753940827,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.351267785385416,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.00012834271529569308,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008100645128628309,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8681291228199247,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.2644691467285156,
        "additional_info": {
            "duration": 0.24593210220336914,
            "num_run": 314,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.673297671162943e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008898351100869808,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.00035531548831678396,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9224729577084336,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2350639418125944,
        "time": 0.5860061645507812,
        "additional_info": {
            "duration": 0.5658578872680664,
            "num_run": 315,
            "train_loss": 1.1949971645190598,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0292634517161658,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009469044699025308,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 0.0048679074217825545,
            "feature_preprocessor:select_rates_classification:alpha": 0.12627780369341454,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09629487991333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.081972852490272,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003188608439520418,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 0.0012192279715032641,
            "feature_preprocessor:select_percentile_classification:percentile": 61.53475244240418,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2170020173701832,
        "time": 0.4140002727508545,
        "additional_info": {
            "duration": 0.39339113235473633,
            "num_run": 317,
            "train_loss": 1.2008076679377495,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02063064263474575,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05457554510960533,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 5.461458180247543e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7061967195861462,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.14974302113848956,
            "feature_preprocessor:select_percentile_classification:percentile": 44.82888951680495,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2401621329374621,
        "time": 0.3268470764160156,
        "additional_info": {
            "duration": 0.30715084075927734,
            "num_run": 318,
            "train_loss": 1.068967159821848,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04801171629053148,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3521942582745105,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.0010585946239190618,
            "feature_preprocessor:select_rates_classification:alpha": 0.31794143001946934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1314101219177246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4185201586668308e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005711513831433078,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 98,
            "classifier:CustomMLPClassifier:tol": 1.2592866071465772e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5650226176656314,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2511913245602444,
        "time": 0.4497060775756836,
        "additional_info": {
            "duration": 0.4352860450744629,
            "num_run": 320,
            "train_loss": 1.2016262100880726,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006497773747043583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.046239677064552696,
            "classifier:CustomMLPClassifier:max_iter": 255,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00030692672261968095,
            "feature_preprocessor:select_percentile_classification:percentile": 24.385062365670947,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2560843021531374,
        "time": 0.22707509994506836,
        "additional_info": {
            "duration": 0.2104949951171875,
            "num_run": 321,
            "train_loss": 1.222913060773124,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016923685528413765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019397857824899736,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 2.722264320022363e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0065798126077162514,
            "feature_preprocessor:select_percentile_classification:percentile": 69.16491491471618,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2551591396331787,
        "additional_info": {
            "duration": 0.24022316932678223,
            "num_run": 322,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5523010871677553e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02511527783832199,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 4.843766412236177e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1979,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 82.84362686239739,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2246401747995435,
        "time": 0.6090271472930908,
        "additional_info": {
            "duration": 0.59505295753479,
            "num_run": 323,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006981147063467669,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001606405026183247,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 0.00012191010040078818,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20643742724015374,
            "feature_preprocessor:select_rates_classification:alpha": 0.4992202820953309,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09702610969543457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.598760768599647e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4597771563325016,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.002608939632301858,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48638515304179775,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1302802562713623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.7398492657878436e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7686037192600024,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.002608939632301858,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48638515304179775,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10212397575378418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.1842298202811034e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5475830965082628,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.0002564674414101004,
            "feature_preprocessor:select_percentile_classification:percentile": 96.35458723324602,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.302113395687932,
        "time": 0.3866112232208252,
        "additional_info": {
            "duration": 0.36821603775024414,
            "num_run": 327,
            "train_loss": 1.246902405442279,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007999245239691586,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009620249755431678,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 0.0002736064831079755,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025978765858675045,
            "feature_preprocessor:select_rates_classification:alpha": 0.3403106671024567,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0967867374420166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.031212195219696284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0061392309086350265,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 1.0825028459415926e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.33741722032129196,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09685707092285156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.171569724189227e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11413335263936798,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 112,
            "classifier:CustomMLPClassifier:tol": 0.00022483040577078676,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11898977778204581,
            "feature_preprocessor:select_rates_classification:alpha": 0.2879955087434038,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09650397300720215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.013845689020596089,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023423012469275987,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.006831725408778431,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002861696758800077,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8268577286922675,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13604939795434576,
            "feature_preprocessor:select_rates_classification:alpha": 0.2234603054620356,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2239841478761506,
        "time": 0.2582998275756836,
        "additional_info": {
            "duration": 0.2446279525756836,
            "num_run": 331,
            "train_loss": 1.253336122606268,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09034949895546726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013486053482351408,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.0005242110325042116,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6294442732067514,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2284819789646286,
        "time": 0.8297560214996338,
        "additional_info": {
            "duration": 0.8077847957611084,
            "num_run": 332,
            "train_loss": 1.1906391122133788,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009400820722711006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27449490881812183,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 2.4604671774940336e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4854589724099579,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09650492668151855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07788340045098167,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017497080019587004,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 9.618135453525556e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07110921838933795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1501162052154541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004743015279006777,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024231229482093875,
            "classifier:CustomMLPClassifier:max_iter": 124,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 1.1193019189239408e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07387471916963048,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1172,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 40.36731994695874,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2424424141006156,
        "time": 0.5718839168548584,
        "additional_info": {
            "duration": 0.5621140003204346,
            "num_run": 335,
            "train_loss": 1.225341485912848,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08989718367826449,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008976488037711765,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 2.4977858181286056e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025921586308387635,
            "feature_preprocessor:select_percentile_classification:percentile": 47.97730760026668,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2277946732618312,
        "time": 0.9272940158843994,
        "additional_info": {
            "duration": 0.9030468463897705,
            "num_run": 336,
            "train_loss": 1.0830002907314071,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.853748881159152e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027364475161283045,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 5.985418023847658e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008397853071630927,
            "feature_preprocessor:select_rates_classification:alpha": 0.2902422031353706,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.7884798049926758,
        "additional_info": {
            "duration": 0.7726919651031494,
            "num_run": 337,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6925233512500966e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.43661382838981927,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 5.4145649924421035e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010566169522064947,
            "feature_preprocessor:select_rates_classification:alpha": 0.025960116974539905,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2596653561585092,
        "time": 0.28526902198791504,
        "additional_info": {
            "duration": 0.271744966506958,
            "num_run": 338,
            "train_loss": 1.1703174068562494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8617625229598663e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15500621799443062,
            "classifier:CustomMLPClassifier:max_iter": 266,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.00044266224538581786,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4186270508469766,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.25212693214416504,
        "additional_info": {
            "duration": 0.235090970993042,
            "num_run": 339,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.45625511540057e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005830230362774847,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.008893372709915064,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4414619253491816,
            "feature_preprocessor:select_rates_classification:alpha": 0.25869829085650387,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.2089850902557373,
        "additional_info": {
            "duration": 0.19795918464660645,
            "num_run": 340,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7031667998355967e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005054886660813419,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.001153636271162148,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1176,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 62.61351402008452,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2240347501898121,
        "time": 0.7432210445404053,
        "additional_info": {
            "duration": 0.7276849746704102,
            "num_run": 341,
            "train_loss": 1.11339484681612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4593482829860052e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.29505102276516787,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 9.072434996815424e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003830529229146167,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.42842259172449704,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.5543880462646484,
        "additional_info": {
            "duration": 0.5354058742523193,
            "num_run": 342,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.033745576707136536,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006516229274181616,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 1.1086975428137297e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.04309653970520596,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09893012046813965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.673903738100539e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.044312254099507724,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 0.004862053251955683,
            "feature_preprocessor:select_rates_classification:alpha": 0.45176054167503854,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12479305267333984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00023977145792034423,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003693971026416625,
            "classifier:CustomMLPClassifier:max_iter": 398,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.00013082047334432814,
            "feature_preprocessor:select_rates_classification:alpha": 0.10745210332007447,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15964698791503906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.654167473355721e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5446637549598787,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 2.0392388644296196e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010517417608657102,
            "feature_preprocessor:select_rates_classification:alpha": 0.4680926972040969,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.320649413191231,
        "time": 0.25701093673706055,
        "additional_info": {
            "duration": 0.24158096313476562,
            "num_run": 346,
            "train_loss": 1.2441733781453348,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.023966569849038544,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016242256375544218,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.0005635667400567487,
            "feature_preprocessor:select_rates_classification:alpha": 0.09022005423447403,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13336181640625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010404005839036836,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03554847286198804,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.00014417254627344009,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001126617616790471,
            "feature_preprocessor:select_rates_classification:alpha": 0.1268593294739691,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.2678501605987549,
        "additional_info": {
            "duration": 0.2545938491821289,
            "num_run": 348,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001780978577183421,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001675999658967893,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 5.9810598555303e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.08794025145074641,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1296379566192627,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006533087498254103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10794019471356285,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 1.0510684175126873e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001754650959333407,
            "feature_preprocessor:select_rates_classification:alpha": 0.19284764039280577,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09627604484558105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012203546007028946,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002251580276804129,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.00021743569020180544,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010154039026182239,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7900058307281814,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05708131641619939,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6192234462838274,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.288453335959037,
        "time": 0.983353853225708,
        "additional_info": {
            "duration": 0.9114527702331543,
            "num_run": 351,
            "train_loss": 1.1533583082680654,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00035247978634245995,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19126984053170298,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 1.3620210919073272e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.29695067660832947,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0968019962310791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4422107316421596e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36751577768617505,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.0012040825820957902,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026806137606301744,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 354,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1747806935716781,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.270609732151632,
        "time": 0.61263108253479,
        "additional_info": {
            "duration": 0.6013891696929932,
            "num_run": 353,
            "train_loss": 1.0767251009375387,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.630463239174463e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9837868757040608,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.0006913869120593275,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001690272483390667,
            "feature_preprocessor:select_percentile_classification:percentile": 57.67609235333353,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.28101181983947754,
        "additional_info": {
            "duration": 0.270733118057251,
            "num_run": 354,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0013284822908133282,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.251347251677219,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 2.0172167075276458e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.21609255290255364,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1282668113708496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000736020937766703,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6064679689489136,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 0.0006265792707386866,
            "feature_preprocessor:select_rates_classification:alpha": 0.1390974335432594,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.2884089946746826,
        "additional_info": {
            "duration": 0.27796101570129395,
            "num_run": 356,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6637545671519002e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003342102162140758,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 2.5902073071412298e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006891638768051318,
            "feature_preprocessor:select_percentile_classification:percentile": 8.635520628203032,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2568332306556342,
        "time": 0.3078160285949707,
        "additional_info": {
            "duration": 0.29630112648010254,
            "num_run": 357,
            "train_loss": 1.2307934761930055,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0026467268820055223,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011468662362089424,
            "classifier:CustomMLPClassifier:max_iter": 359,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 0.00023924190558122506,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03626323868684346,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17881902586251874,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.25393199920654297,
        "additional_info": {
            "duration": 0.23914885520935059,
            "num_run": 358,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00018769719091887637,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005416323414720738,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 6.810148708422879e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019626681526988725,
            "feature_preprocessor:select_percentile_classification:percentile": 98.75091779102534,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.24994993209838867,
        "additional_info": {
            "duration": 0.22850918769836426,
            "num_run": 359,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.014610690435819845,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4334771919957651,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.009624548749042103,
            "feature_preprocessor:select_rates_classification:alpha": 0.0788679523495815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12372684478759766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.880678075465043e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007512998240454217,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.00010763249441951806,
            "feature_preprocessor:select_rates_classification:alpha": 0.3640046691220471,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09606122970581055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05400725066442495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8951790214476346,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 4.2983651403155786e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.49444559919149683,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09649300575256348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021313237605941515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9863257865974135,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.0006759913928649301,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27687757430907683,
            "feature_preprocessor:select_rates_classification:alpha": 0.4335396750335875,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12885308265686035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.046199182187569e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04153013536345012,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 2.3508539798095406e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39530318450187046,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12356376647949219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.16961493263626e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6271712778283959,
            "classifier:CustomMLPClassifier:max_iter": 229,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.00045983600567412364,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3625473285880102,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2590528671979526,
        "time": 0.283322811126709,
        "additional_info": {
            "duration": 0.2669870853424072,
            "num_run": 365,
            "train_loss": 1.2321474348682733,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00019839102327824792,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0075110509493239355,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 0.00011045374319516057,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 375,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.09980844752231433,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2325098033866964,
        "time": 0.7528328895568848,
        "additional_info": {
            "duration": 0.7383320331573486,
            "num_run": 366,
            "train_loss": 1.204488509419751,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03164047776921125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016141792229585346,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.002401548743062573,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1257495471398908,
            "feature_preprocessor:select_rates_classification:alpha": 0.08021657824490641,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.26047492027282715,
        "additional_info": {
            "duration": 0.2489171028137207,
            "num_run": 367,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.660109039323119e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010861448267847296,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 0.0006521789639473264,
            "feature_preprocessor:select_rates_classification:alpha": 0.30111914603604173,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2416913989811251,
        "time": 0.49208712577819824,
        "additional_info": {
            "duration": 0.4772961139678955,
            "num_run": 368,
            "train_loss": 1.1820254984217768,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0007899773740683702,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021088960148928208,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.00032420961697186525,
            "feature_preprocessor:select_rates_classification:alpha": 0.3256222050937157,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12915897369384766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.129489482698114e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17570307296903837,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.004611100818283838,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1760132904239213,
            "feature_preprocessor:select_rates_classification:alpha": 0.4787401302930321,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09715914726257324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001448116566855747,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002026253015033981,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 7.13354447731699e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.09644388980551093,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.47880005836486816,
        "additional_info": {
            "duration": 0.4579508304595947,
            "num_run": 371,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00020027803120605748,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.410867218782256,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 1.1694117823255215e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03680647460157649,
            "feature_preprocessor:select_rates_classification:alpha": 0.3964876633972057,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1284618377685547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006131873949884725,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007978450651702102,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.001958482454185021,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.08786331284693338,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2323966000944708,
        "time": 0.25617003440856934,
        "additional_info": {
            "duration": 0.24130773544311523,
            "num_run": 373,
            "train_loss": 1.1942215102599587,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00682852874791415,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015129033762910677,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 0.0010387618074784437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011179569006502553,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.407961206142869,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2440949257436773,
        "time": 0.29646801948547363,
        "additional_info": {
            "duration": 0.27702808380126953,
            "num_run": 374,
            "train_loss": 1.1922811878766149,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04312821018790593,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06638143301496588,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 1.1675900744455085e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00044272156092223475,
            "feature_preprocessor:select_rates_classification:alpha": 0.2193695004948087,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1011800765991211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2510367783771022e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.522251324974431,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.007369082193127455,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03561700869497035,
            "feature_preprocessor:select_rates_classification:alpha": 0.4834430989178564,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.17189764976501465,
        "additional_info": {
            "duration": 0.16100406646728516,
            "num_run": 376,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0014515399338375287,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001143291823934883,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 0.0002205223344603151,
            "feature_preprocessor:select_percentile_classification:percentile": 64.54794944319359,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.32389402389526367,
        "additional_info": {
            "duration": 0.31334710121154785,
            "num_run": 377,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.4352082922465588e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003676770126559978,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 5.603661964489353e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030549756938781374,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1434,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.11193950270957845,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.234576828488185,
        "time": 0.453350305557251,
        "additional_info": {
            "duration": 0.4379618167877197,
            "num_run": 378,
            "train_loss": 1.0855403124742091,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2584753008330934e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7871321942484018,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.00015368478176376385,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014880727820734664,
            "feature_preprocessor:select_rates_classification:alpha": 0.036863106925739075,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12308406829833984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.686302121495457e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47217437498732484,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.0001108833216102819,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002851024518511577,
            "feature_preprocessor:select_rates_classification:alpha": 0.45658448607063296,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.21480703353881836,
        "additional_info": {
            "duration": 0.19904112815856934,
            "num_run": 380,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.478363454438258e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4964625308705362,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 8.155058932607448e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.15012414190973186,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10159993171691895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2574096895996943e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06908097544171618,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 1.136795153481821e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019020078721131688,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1276,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 55.481224565049864,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2658531941006794,
        "time": 0.3684811592102051,
        "additional_info": {
            "duration": 0.3540458679199219,
            "num_run": 382,
            "train_loss": 1.14658931186302,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0531088605101593,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.529377695891229,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 0.009925918823437789,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00940470515127346,
            "feature_preprocessor:select_rates_classification:alpha": 0.3130744324154649,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.3196073038917324,
        "time": 0.2932569980621338,
        "additional_info": {
            "duration": 0.28233790397644043,
            "num_run": 383,
            "train_loss": 1.3036409512908562,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0023767452617384295,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08813826764000568,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 4.01256176725558e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14083805729033227,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2466854075223217,
        "time": 0.3289148807525635,
        "additional_info": {
            "duration": 0.3156242370605469,
            "num_run": 384,
            "train_loss": 1.1940621369162254,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.04830115727464319,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007721232112517983,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 1.85230667681531e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15687247700080495,
            "feature_preprocessor:select_rates_classification:alpha": 0.23364208200101097,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12684106826782227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02019439684541457,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5433280548642998,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.004972641468702272,
            "feature_preprocessor:select_rates_classification:alpha": 0.05608536461631545,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.2946591377258301,
        "additional_info": {
            "duration": 0.27855420112609863,
            "num_run": 386,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0643192938107616,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015279273200902761,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 3.145821188308408e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3778945921323355,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12389707565307617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06729909053306407,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000147946736848014,
            "classifier:CustomMLPClassifier:max_iter": 481,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.0003272832506041444,
            "feature_preprocessor:select_rates_classification:alpha": 0.022957333197900637,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0960838794708252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.015461609337354515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008543279715378924,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.001259584002610433,
            "feature_preprocessor:select_rates_classification:alpha": 0.30761618506369437,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09633302688598633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02683092303720365,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5287569250972282,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.00184174737564308,
            "feature_preprocessor:select_rates_classification:alpha": 0.46660027065828436,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.290151341922664,
        "time": 0.27004384994506836,
        "additional_info": {
            "duration": 0.2571909427642822,
            "num_run": 390,
            "train_loss": 1.1430541785826849,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008659392447319374,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009096258975064761,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.0017953597690851173,
            "feature_preprocessor:select_rates_classification:alpha": 0.23703292915377996,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1289370059967041,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0027878053271437313,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004058949453201514,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 6.429277103327278e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1712,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8807036187125936,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2423787046839225,
        "time": 0.4442780017852783,
        "additional_info": {
            "duration": 0.4261288642883301,
            "num_run": 392,
            "train_loss": 1.2054532717461512,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0377758373742348e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008895118451833245,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.0023438027368299116,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10990493238412714,
            "feature_preprocessor:select_percentile_classification:percentile": 35.78340907374498,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2359826752534295,
        "time": 0.25135374069213867,
        "additional_info": {
            "duration": 0.23981904983520508,
            "num_run": 393,
            "train_loss": 1.1630408361848033,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011093786797644029,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001204359755283869,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 235,
            "classifier:CustomMLPClassifier:tol": 1.5806686761068004e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004632159398522273,
            "feature_preprocessor:select_rates_classification:alpha": 0.49365757616747047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10114097595214844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1004148001109249e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03593302054279655,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.00023742412574957703,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11026551820539109,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1097,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.19674422213432463,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.236652830878473,
        "time": 0.3847348690032959,
        "additional_info": {
            "duration": 0.360044002532959,
            "num_run": 395,
            "train_loss": 1.2139566204229666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.541762729179605e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020822140651001746,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 1.817788588063041e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3789479426069428,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3802969455718994,
        "additional_info": {
            "duration": 0.3647608757019043,
            "num_run": 396,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1485995356723868e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011529599879375676,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 8.973121506284793e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011610042002141961,
            "feature_preprocessor:select_rates_classification:alpha": 0.48838621538987553,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09619998931884766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.764166798327954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000805410290672538,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 0.00013195130169908837,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.017089054416197236,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2333295490764664,
        "time": 0.5110719203948975,
        "additional_info": {
            "duration": 0.49974489212036133,
            "num_run": 398,
            "train_loss": 1.1876058983469673,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.4800025003665215e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6285321494346017,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.0016701234234977773,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010965655895926911,
            "feature_preprocessor:select_percentile_classification:percentile": 92.27874828542397,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.26775312423706055,
        "additional_info": {
            "duration": 0.2525928020477295,
            "num_run": 399,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06597264635295239,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9383993398356923,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.0049916926791599555,
            "feature_preprocessor:select_rates_classification:alpha": 0.4602278849780929,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12764215469360352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006029759342926968,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005582775852974851,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 0.0013596288235021925,
            "feature_preprocessor:select_percentile_classification:percentile": 81.59454633677535,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.21595406532287598,
        "additional_info": {
            "duration": 0.20164203643798828,
            "num_run": 401,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0018354948744461856,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002338135862567252,
            "classifier:CustomMLPClassifier:max_iter": 193,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 4.902169241845272e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0778144305950314,
            "feature_preprocessor:select_percentile_classification:percentile": 81.82767812131978,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2337803190481296,
        "time": 0.7623400688171387,
        "additional_info": {
            "duration": 0.7468960285186768,
            "num_run": 402,
            "train_loss": 1.0380662584458689,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08685535929709842,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008037516528534577,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 4.918483279735017e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005334066850319004,
            "feature_preprocessor:select_rates_classification:alpha": 0.3326599340083982,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12455010414123535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004063626757036059,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023280436672311403,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.009651799746694997,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023878505218682716,
            "feature_preprocessor:select_rates_classification:alpha": 0.14909085564196148,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.19671010971069336,
        "additional_info": {
            "duration": 0.18422341346740723,
            "num_run": 404,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00020861419748575237,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06829935821201055,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.0004068375426496949,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026040681552776158,
            "feature_preprocessor:select_percentile_classification:percentile": 19.79942774467616,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2513570431041052,
        "time": 0.5741617679595947,
        "additional_info": {
            "duration": 0.5417001247406006,
            "num_run": 405,
            "train_loss": 1.1563990204496561,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.576876666269888e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0057852679943808435,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 1.4765301427375502e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6772076477550596,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3208489418029785,
        "additional_info": {
            "duration": 0.2907388210296631,
            "num_run": 406,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006042078813292627,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022067977337962674,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 337,
            "classifier:CustomMLPClassifier:tol": 0.009761317595953618,
            "feature_preprocessor:select_rates_classification:alpha": 0.3934662720978647,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12758302688598633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.355807063691195e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011991749103297331,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.0003993954640134182,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02708947798848921,
            "feature_preprocessor:select_rates_classification:alpha": 0.32358581100976314,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13151907920837402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.478363454438258e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4964625308705362,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 5.9968069413533704e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1583108189864312,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09761881828308105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.087094820764543e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010197694815683839,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.00029634623370687266,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9968311982946401,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12545071243720304,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.22678080894301067,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2312402659041275,
        "time": 0.4582631587982178,
        "additional_info": {
            "duration": 0.4378390312194824,
            "num_run": 410,
            "train_loss": 1.192775377489314,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.58564932911221e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04022829869452575,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.00012228179610465257,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000348210641420794,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.512926048161589,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.34410715103149414,
        "additional_info": {
            "duration": 0.3256049156188965,
            "num_run": 411,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.309301281045893e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04302304478405604,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.00020721786029737673,
            "feature_preprocessor:select_percentile_classification:percentile": 73.98130002639674,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225942056079891,
        "time": 0.41745686531066895,
        "additional_info": {
            "duration": 0.391157865524292,
            "num_run": 412,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016870294552276375,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003059270502759621,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 112,
            "classifier:CustomMLPClassifier:tol": 3.6944301109570746e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016967008200542084,
            "feature_preprocessor:select_rates_classification:alpha": 0.03657304204779497,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.19095182418823242,
        "additional_info": {
            "duration": 0.17653465270996094,
            "num_run": 413,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.11798532844849e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018621109921092477,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 0.0003423261889468403,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030739997967505444,
            "feature_preprocessor:select_rates_classification:alpha": 0.09493941318969726,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09705090522766113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07281349521325746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028245497836553663,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 1.3095849605100657e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8391731815408194,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2512367754610545,
        "time": 0.571073055267334,
        "additional_info": {
            "duration": 0.5566818714141846,
            "num_run": 415,
            "train_loss": 1.2200917568676457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009359806958671292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9103954208094063,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 163,
            "classifier:CustomMLPClassifier:tol": 0.0011058835263239005,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04170949166419815,
            "feature_preprocessor:select_rates_classification:alpha": 0.3625779229646579,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10306930541992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9600601536292094e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005478148034401814,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 0.00018996985805591035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010014512419360981,
            "feature_preprocessor:select_rates_classification:alpha": 0.10670911290469166,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12396717071533203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7666965345089417e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004735565445438734,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.003482533269578037,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005453494270762448,
            "feature_preprocessor:select_rates_classification:alpha": 0.25211419242341865,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2474768958087903,
        "time": 0.19363999366760254,
        "additional_info": {
            "duration": 0.167219877243042,
            "num_run": 418,
            "train_loss": 1.1685956467754053,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.198560775671417e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24640249356892188,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 3.0166036882105662e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4762787443308309,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.2815859317779541,
        "additional_info": {
            "duration": 0.2686119079589844,
            "num_run": 419,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.5448436364207086e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09731883149656938,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 8.349337310635608e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.21792099411989074,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1267838478088379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003745933885894758,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.48460787841626085,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 1.6425825336169802e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021264425374803875,
            "feature_preprocessor:select_rates_classification:alpha": 0.14965668233802865,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10258197784423828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.0644805164078776e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00496950960369795,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0016787004502376226,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9271560980223325,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05372809168717702,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.006288868029533212,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2317092509719185,
        "time": 0.3567826747894287,
        "additional_info": {
            "duration": 0.34435486793518066,
            "num_run": 422,
            "train_loss": 1.1903209800134795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003887786071366532,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1592622287875951,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 0.0016881466220303348,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2993166503191408,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2327877904636733,
        "time": 0.34023094177246094,
        "additional_info": {
            "duration": 0.32410216331481934,
            "num_run": 423,
            "train_loss": 1.2043859205953522,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.378049752038017e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07128595679200424,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 0.0014183285569002552,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038514170912175245,
            "feature_preprocessor:select_rates_classification:alpha": 0.2674453668961557,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09747576713562012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.507336264036467e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06374984242570642,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.0015300747511771077,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010353466623356962,
            "feature_preprocessor:select_rates_classification:alpha": 0.44392881309424986,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09818601608276367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.454553989784719e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002736796147497146,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 6.211173546914175e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1461094546764048,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09937620162963867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.025650540165932892,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10122866835078057,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.00229478047855678,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0027636473147017037,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7777523540744871,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3181440830230713,
        "additional_info": {
            "duration": 0.2989771366119385,
            "num_run": 427,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.594635254832143e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0649757188249349,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 2.0390421553992224e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04882498304516074,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1709,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 46.647690659381865,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2493022771860482,
        "time": 0.32418131828308105,
        "additional_info": {
            "duration": 0.3023710250854492,
            "num_run": 428,
            "train_loss": 1.1890207869305467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4570862963096543e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02268287148228718,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.00045560937066329324,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9276209410279986,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2770418023110957,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.506303987745591,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.247744710319329,
        "time": 0.3041849136352539,
        "additional_info": {
            "duration": 0.2850797176361084,
            "num_run": 429,
            "train_loss": 1.2061002848741738,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.034694578843282774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002764330589508183,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.00489080286620508,
            "feature_preprocessor:select_rates_classification:alpha": 0.2587605296564365,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.207963228225708,
        "additional_info": {
            "duration": 0.19400310516357422,
            "num_run": 430,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004685094196431396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024306079852100277,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 6.153031784819273e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 39.69065227757984,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2131166752422617,
        "time": 0.44701075553894043,
        "additional_info": {
            "duration": 0.43659281730651855,
            "num_run": 431,
            "train_loss": 1.1697019719144945,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00020228691291846593,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010635052705557001,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 7.947775890701011e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39576793698510676,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09803915023803711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002349772557686061,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018441768842643213,
            "classifier:CustomMLPClassifier:max_iter": 398,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.0029401017116628225,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 441,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.030177642650630845,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.3221900463104248,
        "additional_info": {
            "duration": 0.30704307556152344,
            "num_run": 433,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018134461597821898,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19472622509878612,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 0.009938763141620911,
            "feature_preprocessor:select_rates_classification:alpha": 0.3770664980591985,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12591290473937988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0020097729649062807,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011635174542292271,
            "classifier:CustomMLPClassifier:max_iter": 274,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 0.0009855517495794503,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005590815442000351,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1307,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.08084556385015772,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2518604585866688,
        "time": 0.4955759048461914,
        "additional_info": {
            "duration": 0.4781668186187744,
            "num_run": 435,
            "train_loss": 1.160031087701913,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.255077168024805e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.043584629133106186,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 359,
            "classifier:CustomMLPClassifier:tol": 0.001481423513688676,
            "feature_preprocessor:select_rates_classification:alpha": 0.2229983632281395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09755110740661621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06732041152831232,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00880528486009117,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 2.5365792361749688e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3641780635747628,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.30303311347961426,
        "additional_info": {
            "duration": 0.29212427139282227,
            "num_run": 437,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.154491329521447e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002296106061610165,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 0.00017704974384116044,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009152891348596994,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8316152087097175,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1990278767192451,
            "feature_preprocessor:select_percentile_classification:percentile": 47.56225402159803,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2458384260278694,
        "time": 0.8559062480926514,
        "additional_info": {
            "duration": 0.8452398777008057,
            "num_run": 438,
            "train_loss": 1.0294535396301994,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0032506892831213057,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9892730895170195,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 58,
            "classifier:CustomMLPClassifier:tol": 0.00014904828512555504,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022318108138023833,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 228,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.28547468940638,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.353532075881958,
        "additional_info": {
            "duration": 0.3352968692779541,
            "num_run": 439,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.125196885586871e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00026048460345593627,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 0.0024784141284141686,
            "feature_preprocessor:select_rates_classification:alpha": 0.32474036866207284,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10236001014709473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.9824273524455867e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011547122709867326,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.0002897531565695765,
            "feature_preprocessor:select_rates_classification:alpha": 0.420520744871554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12751483917236328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.117614454463656e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036314104037969653,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.00011512672784609285,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006615265010921836,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9599798542153779,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2115374148367156,
            "feature_preprocessor:select_rates_classification:alpha": 0.19894249203505776,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.202636306583098,
        "time": 0.529000997543335,
        "additional_info": {
            "duration": 0.5051369667053223,
            "num_run": 442,
            "train_loss": 1.1511980656341985,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013378491401252286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005969310356973264,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.00825286778126383,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006675195886649106,
            "feature_preprocessor:select_rates_classification:alpha": 0.2358418073262591,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13162803649902344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.505127652662694e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3171029516407044,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 235,
            "classifier:CustomMLPClassifier:tol": 0.009546728033556271,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07873915397937321,
            "feature_preprocessor:select_percentile_classification:percentile": 36.23809489595003,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2552328109741211,
        "additional_info": {
            "duration": 0.2407541275024414,
            "num_run": 444,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008639811459546261,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4785704523497217,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.006793525780454256,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011267657727307995,
            "feature_preprocessor:select_percentile_classification:percentile": 58.729345870456584,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.2562429904937744,
        "additional_info": {
            "duration": 0.24495983123779297,
            "num_run": 445,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1442445073312877e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023217258891808035,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 0.001426741333599326,
            "feature_preprocessor:select_percentile_classification:percentile": 39.581947996413675,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.23912787437438965,
        "additional_info": {
            "duration": 0.2294938564300537,
            "num_run": 446,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007763406326725369,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009422781588506827,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.002419664224527875,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002364736625421106,
            "feature_preprocessor:select_rates_classification:alpha": 0.3327559963698848,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2853691577911377,
        "additional_info": {
            "duration": 0.2737770080566406,
            "num_run": 447,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001074098055611566,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001368968510660629,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 4.156313917479239e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.40732078210803924,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09834527969360352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6923160506727808e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7327976012436388,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 2.768545003420689e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 370,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3959307648964257,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.275494493535816,
        "time": 0.32124996185302734,
        "additional_info": {
            "duration": 0.2978041172027588,
            "num_run": 449,
            "train_loss": 1.3172406400123025,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00044913003159130266,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02455433459798329,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 1.9998150911322566e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0051802839102848995,
            "feature_preprocessor:select_percentile_classification:percentile": 93.19054034083807,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2234566482242726,
        "time": 1.5628559589385986,
        "additional_info": {
            "duration": 1.548750877380371,
            "num_run": 450,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03668725000185892,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010067476696528905,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 0.0018095855769403137,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006084564263839233,
            "feature_preprocessor:select_rates_classification:alpha": 0.49668048201307363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10072803497314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09896513810874545,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013674071891974834,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 1.8309350769512435e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00041228877070421374,
            "feature_preprocessor:select_percentile_classification:percentile": 43.76373104937972,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2585060874315726,
        "time": 0.4094102382659912,
        "additional_info": {
            "duration": 0.39681100845336914,
            "num_run": 452,
            "train_loss": 1.2029938339054072,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008177707790656226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00028615428878210207,
            "classifier:CustomMLPClassifier:max_iter": 255,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.0007244871338553996,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006020910920371362,
            "feature_preprocessor:select_rates_classification:alpha": 0.055463896361965054,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2425788102228008,
        "time": 0.3594639301300049,
        "additional_info": {
            "duration": 0.3480410575866699,
            "num_run": 453,
            "train_loss": 1.2040621825452953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000610314077650604,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23538298952873687,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0005666798911433478,
            "feature_preprocessor:select_rates_classification:alpha": 0.2451808253651529,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.133148193359375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00018695142307968896,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009244599704234531,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 1.0279269452349626e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05358581183078803,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.01363518817607956,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2957316252183544,
        "time": 0.49727678298950195,
        "additional_info": {
            "duration": 0.48410487174987793,
            "num_run": 455,
            "train_loss": 1.1179655215749411,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.144375385496751e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017330213426428134,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 0.006801852950947662,
            "feature_preprocessor:select_rates_classification:alpha": 0.16392527172187046,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.23489093780517578,
        "additional_info": {
            "duration": 0.2225170135498047,
            "num_run": 456,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.20130678773393e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.051832730231758876,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.00527985211867447,
            "feature_preprocessor:select_rates_classification:alpha": 0.036046714381100964,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3816032409667969,
        "additional_info": {
            "duration": 0.3667480945587158,
            "num_run": 457,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02515092271908762,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010092144847876453,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 1.0868946398158134e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02049356321444229,
            "feature_preprocessor:select_rates_classification:alpha": 0.12517632433635714,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.234467581331172,
        "time": 2.0898489952087402,
        "additional_info": {
            "duration": 2.0745370388031006,
            "num_run": 458,
            "train_loss": 1.176367253033163,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.480168149432867e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008141844079577317,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.0016643889457715465,
            "feature_preprocessor:select_rates_classification:alpha": 0.02120615094077428,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.26902198791503906,
        "additional_info": {
            "duration": 0.2510209083557129,
            "num_run": 459,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001644358293106335,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5813445580967828,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.0006952033355598732,
            "feature_preprocessor:select_rates_classification:alpha": 0.1951746759103363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12959623336791992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005999063620196916,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4981058206569939,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 6.769011096708125e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008328991078535436,
            "feature_preprocessor:select_rates_classification:alpha": 0.21712204583656436,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10230898857116699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006079794624399165,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018406504385447987,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 378,
            "classifier:CustomMLPClassifier:tol": 0.0008723014881808517,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.067331545133555,
            "feature_preprocessor:select_percentile_classification:percentile": 4.185407279226328,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.32514023780822754,
        "additional_info": {
            "duration": 0.3135838508605957,
            "num_run": 462,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03533232415130614,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021390717551598055,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.0013886302951891735,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017737270656513628,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 23,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 50.94684403918757,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2422695443664193,
        "time": 0.43157482147216797,
        "additional_info": {
            "duration": 0.41506218910217285,
            "num_run": 463,
            "train_loss": 1.0994752804367118,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03276832932226576,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19392098736133712,
            "classifier:CustomMLPClassifier:max_iter": 327,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.0061217858703293245,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8959600852003785,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09326371223719221,
            "feature_preprocessor:select_percentile_classification:percentile": 47.009461565000144,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.24315699902785,
        "time": 0.33026885986328125,
        "additional_info": {
            "duration": 0.3187441825866699,
            "num_run": 464,
            "train_loss": 1.1529929113019213,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.259206300157356e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.30596452039973354,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.003202761627848945,
            "feature_preprocessor:select_rates_classification:alpha": 0.036492067482269186,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.130781888961792,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.2025916513734865e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7058300384817154,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 1.1718686458000942e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013236054722855868,
            "feature_preprocessor:select_rates_classification:alpha": 0.16335625006852925,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2836058092669542,
        "time": 0.40021824836730957,
        "additional_info": {
            "duration": 0.38878393173217773,
            "num_run": 466,
            "train_loss": 1.1598413651470467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.5157365178151745e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12297634665456983,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0008387337743775861,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15224706622515258,
            "feature_preprocessor:select_rates_classification:alpha": 0.12446295594739983,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10177874565124512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.048350981351928e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001450526270632399,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 6.311441249248988e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5070871732203572,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.5825290679931641,
        "additional_info": {
            "duration": 0.5600721836090088,
            "num_run": 468,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006678314890294296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004995214644249308,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 5.630109406276668e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1481,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.518247755108102,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2082671487726953,
        "time": 0.39255595207214355,
        "additional_info": {
            "duration": 0.3588130474090576,
            "num_run": 469,
            "train_loss": 1.1840330200534768,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00874794682810832,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015180014244944284,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.003152424487694606,
            "feature_preprocessor:select_percentile_classification:percentile": 48.66195593129818,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.3262500762939453,
        "additional_info": {
            "duration": 0.30967283248901367,
            "num_run": 470,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.414789270561311e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023389833080865105,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 0.0003311025785134681,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 666,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 12.945561715273108,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2239568686517135,
        "time": 0.3392031192779541,
        "additional_info": {
            "duration": 0.3276488780975342,
            "num_run": 471,
            "train_loss": 1.2294997839361625,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001298955443161148,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009713754542046066,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 7.191223452017479e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1141,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.43430218319797154,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2753026042056468,
        "time": 0.5013089179992676,
        "additional_info": {
            "duration": 0.48809289932250977,
            "num_run": 472,
            "train_loss": 1.0328046052081452,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0027022146907270043,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015437821791404618,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.000393911763198721,
            "feature_preprocessor:select_rates_classification:alpha": 0.278532631673743,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09881377220153809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03193933033367333,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003681601341483909,
            "classifier:CustomMLPClassifier:max_iter": 124,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.0016065096170418036,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017788132841544762,
            "feature_preprocessor:select_rates_classification:alpha": 0.4134297947020808,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09807109832763672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7762090822193038e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9995182286767885,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 1.8329724846491738e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.31836893719777465,
            "feature_preprocessor:select_rates_classification:alpha": 0.19610266459491965,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.320649413191231,
        "time": 0.25336599349975586,
        "additional_info": {
            "duration": 0.22723674774169922,
            "num_run": 475,
            "train_loss": 1.2521748564105466,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019207962762842036,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019269236565500258,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 8.90875046252032e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3074287180082933,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13141489028930664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0027741001020688636,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014933373486271948,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 0.0008482941874437428,
            "feature_preprocessor:select_rates_classification:alpha": 0.3074145570825535,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13353204727172852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00019027743820516663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0413863747523788,
            "classifier:CustomMLPClassifier:max_iter": 277,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.00010123236317909321,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028591032376557496,
            "feature_preprocessor:select_percentile_classification:percentile": 67.25974590544455,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.24978399276733398,
        "additional_info": {
            "duration": 0.23746013641357422,
            "num_run": 478,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0860960758141995e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01009512074508063,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 3.3372315148140885e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22770621098528757,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10224080085754395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02413279309930702,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005415290579577579,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 308,
            "classifier:CustomMLPClassifier:tol": 0.0024193476651153314,
            "feature_preprocessor:select_rates_classification:alpha": 0.01315223307875876,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12569928169250488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.9649899262929837e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014120484917100372,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.0002641001429313127,
            "feature_preprocessor:select_rates_classification:alpha": 0.2547434327024101,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2419369120010586,
        "time": 0.3240039348602295,
        "additional_info": {
            "duration": 0.3117368221282959,
            "num_run": 481,
            "train_loss": 1.2379475235579411,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3260149125507333e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010062918502911525,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.009876744304469314,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.126397672607794,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8824377152602654,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.040294361961477884,
            "feature_preprocessor:select_rates_classification:alpha": 0.2719849354831981,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2552151060075898,
        "time": 0.24932312965393066,
        "additional_info": {
            "duration": 0.23848319053649902,
            "num_run": 482,
            "train_loss": 1.173784445912296,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00021085500905181217,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09717191950272598,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 0.00029282101663247894,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012160869795187936,
            "feature_preprocessor:select_rates_classification:alpha": 0.2351329628820344,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2819077968597412,
        "additional_info": {
            "duration": 0.25017809867858887,
            "num_run": 483,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002535045101329296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06988463915956658,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.00036276790231020117,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01289787365289865,
            "feature_preprocessor:select_rates_classification:alpha": 0.39004573237597423,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12618374824523926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010271911145584103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5732533011433991,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.007881565090848745,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.173386775718952,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.22098898887634277,
        "additional_info": {
            "duration": 0.2062067985534668,
            "num_run": 485,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004441806144978398,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09659822262062731,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 4.59455227412042e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3894497363985994,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13319897651672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002875555230602209,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005016579681463566,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.0002657245050144917,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11074947943648712,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2203870699103202,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2511913245602444,
        "time": 0.4106869697570801,
        "additional_info": {
            "duration": 0.383695125579834,
            "num_run": 487,
            "train_loss": 1.1915063795911267,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.011657719869455784,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16465140302932976,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 437,
            "classifier:CustomMLPClassifier:tol": 0.0007729604806292008,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005056883182321207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1811,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06018508484183793,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2545601006828162,
        "time": 0.564276933670044,
        "additional_info": {
            "duration": 0.54475998878479,
            "num_run": 488,
            "train_loss": 1.1942690555145687,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.0235474209382696e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5318990744979127,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.009798878749509018,
            "feature_preprocessor:select_rates_classification:alpha": 0.06106571336831849,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.27223896980285645,
        "additional_info": {
            "duration": 0.2559800148010254,
            "num_run": 489,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001215730535044028,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021492691092254563,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.003702041761039541,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09907232720918398,
            "feature_preprocessor:select_rates_classification:alpha": 0.07257910602917411,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12475991249084473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03788420832559829,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.338380204152327,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.00047488479959320547,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001453708132810598,
            "feature_preprocessor:select_rates_classification:alpha": 0.2266158663122659,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1312551498413086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00011888919005464172,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007457811689798603,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 0.0010882702062345326,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004260728094627067,
            "feature_preprocessor:select_rates_classification:alpha": 0.2148986852218911,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12614917755126953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01769472035130901,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020751560705159393,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 1.0626264953680015e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 58.88369865540312,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2870979309082031,
        "additional_info": {
            "duration": 0.2590761184692383,
            "num_run": 493,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0006545499878687303,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004170699735046042,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 67,
            "classifier:CustomMLPClassifier:tol": 0.002321690255307034,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08157652124285104,
            "feature_preprocessor:select_rates_classification:alpha": 0.39341644865022507,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13188910484313965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06771281992489973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07420788274749511,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 0.00032456635418707147,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00048559366434216617,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3664543570004103,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.39536476135253906,
        "additional_info": {
            "duration": 0.37621307373046875,
            "num_run": 495,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007689484612278752,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9932731281204957,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.006809889155350515,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014853995375223175,
            "feature_preprocessor:select_rates_classification:alpha": 0.42327740586473955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12559890747070312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3960202497886801e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0987898507415841,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 382,
            "classifier:CustomMLPClassifier:tol": 0.00505770770669379,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001138774244099209,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 786,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7246964475779727,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1977251138940772,
        "time": 0.48465991020202637,
        "additional_info": {
            "duration": 0.47005510330200195,
            "num_run": 497,
            "train_loss": 1.2136274590064782,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.411418763760511e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036082293140120305,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 0.005370891238229781,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021753821765963462,
            "feature_preprocessor:select_percentile_classification:percentile": 96.96737051769699,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2370258061515476,
        "time": 0.24718785285949707,
        "additional_info": {
            "duration": 0.228989839553833,
            "num_run": 498,
            "train_loss": 1.1705246594537948,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01075788389109799,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1254060807178331,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.00030923790299570227,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0053707541348105604,
            "feature_preprocessor:select_percentile_classification:percentile": 4.556201740568027,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2743489742279053,
        "additional_info": {
            "duration": 0.2569551467895508,
            "num_run": 499,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010076609129613906,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004792087161629544,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 2.568714211373551e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 17.725899344949113,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2385034482829296,
        "time": 0.715756893157959,
        "additional_info": {
            "duration": 0.6982400417327881,
            "num_run": 500,
            "train_loss": 1.2281378149713051,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.6696339947010763e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03010130729335405,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 324,
            "classifier:CustomMLPClassifier:tol": 0.0006775509029398021,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1883,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 66.66835078800189,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.227262065616857,
        "time": 0.7751049995422363,
        "additional_info": {
            "duration": 0.7549431324005127,
            "num_run": 501,
            "train_loss": 1.0229036175020643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011138064345820495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003258198527504987,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 2.6589985483976835e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2629724508028125,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2265019429493025,
        "time": 0.407351016998291,
        "additional_info": {
            "duration": 0.38283610343933105,
            "num_run": 502,
            "train_loss": 1.1892714393937247,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.7710937038156745e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038898241398306627,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.0010320084242284354,
            "feature_preprocessor:select_percentile_classification:percentile": 7.300951181475364,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2589234485870828,
        "time": 0.200181245803833,
        "additional_info": {
            "duration": 0.186859130859375,
            "num_run": 503,
            "train_loss": 1.233851384418073,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09331988880664513,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012084369779432065,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 0.0007623227840722461,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007661993786329455,
            "feature_preprocessor:select_rates_classification:alpha": 0.258836634587143,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12484884262084961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09913055999355973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11649039154663891,
            "classifier:CustomMLPClassifier:max_iter": 350,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 3.304530261252761e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3192864341410225,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09703898429870605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.2740137837567024e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016552585100538145,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.006587875776806917,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8595343788051187,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.4792189598083496,
        "additional_info": {
            "duration": 0.463137149810791,
            "num_run": 506,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.092935327921422e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00895928936375487,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.007601680548778936,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005306317219761428,
            "feature_preprocessor:select_rates_classification:alpha": 0.16382881772711555,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1302049160003662,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011979918161840232,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03217647699420129,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.008168443177932262,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006467621375185337,
            "feature_preprocessor:select_rates_classification:alpha": 0.09968264913979417,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2413638746088609,
        "time": 0.22121500968933105,
        "additional_info": {
            "duration": 0.20786023139953613,
            "num_run": 508,
            "train_loss": 1.1774054839479637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021479175725478878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3855663630880917,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.0004173112382340453,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027339734189050294,
            "feature_preprocessor:select_rates_classification:alpha": 0.010468189601413583,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1260380744934082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011495631236451485,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010460408881585565,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 1.1836707666646845e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002709965539448931,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8183710228305581,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17598681921055712,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21972264308720046,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2322873963572127,
        "time": 0.7407209873199463,
        "additional_info": {
            "duration": 0.7237157821655273,
            "num_run": 510,
            "train_loss": 1.1942102005550046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2959152801791095e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7365379282049885,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.00036526170658420204,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006181898303922516,
            "feature_preprocessor:select_rates_classification:alpha": 0.23053155238081638,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12441086769104004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.8684886848709887e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004134963455471898,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 1.8379167478554284e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02905901661083618,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8533748464087031,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2894159351601167,
            "feature_preprocessor:select_rates_classification:alpha": 0.22958633481519716,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.6276102066040039,
        "additional_info": {
            "duration": 0.6144430637359619,
            "num_run": 512,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004910832361704014,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6585271651175859,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 1.3654502852091774e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008819644074976191,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8229623642668014,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19211532250258193,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.10973008616535784,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2350457267164665,
        "time": 0.4262073040008545,
        "additional_info": {
            "duration": 0.40164995193481445,
            "num_run": 513,
            "train_loss": 1.175451496422553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00031172601824733454,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9408368823290788,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.00028004839681882126,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 718,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11625965489835266,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.279563812723481,
        "time": 0.44481420516967773,
        "additional_info": {
            "duration": 0.42220616340637207,
            "num_run": 514,
            "train_loss": 1.2042931320124075,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003221208923559109,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023082382178578236,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 3.9287018469438495e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3657423400891168,
            "feature_preprocessor:select_rates_classification:alpha": 0.24571793447573456,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12629389762878418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00017389994285748922,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006718537602866503,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 0.0015329295895007181,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022460586967323418,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5684985286108479,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.266740605342355,
        "time": 0.5940310955047607,
        "additional_info": {
            "duration": 0.5684432983398438,
            "num_run": 516,
            "train_loss": 1.0712815039484929,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0443766484887292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014539757793332123,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 112,
            "classifier:CustomMLPClassifier:tol": 0.00015168856379218365,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031087314232421588,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1784,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 58.32935723937334,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2453876560562063,
        "time": 0.285444974899292,
        "additional_info": {
            "duration": 0.2697749137878418,
            "num_run": 517,
            "train_loss": 1.1611180928464582,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008484945934991162,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012654853301416247,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 381,
            "classifier:CustomMLPClassifier:tol": 0.007291057543162082,
            "feature_preprocessor:select_rates_classification:alpha": 0.03831786799600323,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.23349618911743164,
        "additional_info": {
            "duration": 0.21964788436889648,
            "num_run": 518,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0014047364059494407,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008774980108080303,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.0018865932797864872,
            "feature_preprocessor:select_rates_classification:alpha": 0.43675880571964976,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2408494386402595,
        "time": 0.2759521007537842,
        "additional_info": {
            "duration": 0.26184988021850586,
            "num_run": 519,
            "train_loss": 1.1531335791386779,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.674264562614115e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8066870751001113,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.00161728657100968,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9122067482894205,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.36162519454956055,
        "additional_info": {
            "duration": 0.34339404106140137,
            "num_run": 520,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011551624454871697,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005639621875274845,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.0017364657783193107,
            "feature_preprocessor:select_rates_classification:alpha": 0.20911537713793016,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.130584716796875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.118115654904772e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004326364120220197,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 4.1760977609354295e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.02729628013182491,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2533260152136387,
        "time": 0.34795498847961426,
        "additional_info": {
            "duration": 0.3334372043609619,
            "num_run": 522,
            "train_loss": 1.203012027437973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1939280656273128e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4357386995902741,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 2.6487227405181246e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09234112033743543,
            "feature_preprocessor:select_rates_classification:alpha": 0.37900231696882875,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12391996383666992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010556475850723036,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31853247406092133,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 345,
            "classifier:CustomMLPClassifier:tol": 0.0072702738784973,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026354768503486854,
            "feature_preprocessor:select_rates_classification:alpha": 0.44614316028570117,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12557101249694824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.031369013433565456,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014490170223501156,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.004397034214012641,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039632920162948953,
            "feature_preprocessor:select_rates_classification:alpha": 0.4764929073477668,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10065627098083496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.200561387609693e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003398661576909142,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 259,
            "classifier:CustomMLPClassifier:tol": 0.0027123852592988544,
            "feature_preprocessor:select_rates_classification:alpha": 0.1123503217733135,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1248629093170166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012375738877701664,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008612845245939048,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.0019904130911382006,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006381946784674873,
            "feature_preprocessor:select_rates_classification:alpha": 0.18729726423802187,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2948610782623291,
        "additional_info": {
            "duration": 0.2803070545196533,
            "num_run": 527,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.915454020165173e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001724231655812181,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.0012735818181952982,
            "feature_preprocessor:select_rates_classification:alpha": 0.4190102254815602,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12748289108276367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.036401453503101935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9170366325230692,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.00033521780474064756,
            "feature_preprocessor:select_rates_classification:alpha": 0.4289510455033093,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2851036228521933,
        "time": 0.2756681442260742,
        "additional_info": {
            "duration": 0.25310301780700684,
            "num_run": 529,
            "train_loss": 1.2187048130557674,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00015347602875806542,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15287531634886875,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 200,
            "classifier:CustomMLPClassifier:tol": 0.0063317710439344714,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09961326258668432,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.38319074815969667,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2748709406694663,
        "time": 0.33799123764038086,
        "additional_info": {
            "duration": 0.31998419761657715,
            "num_run": 530,
            "train_loss": 1.221764181742015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007650162743489271,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009902618340890658,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 166,
            "classifier:CustomMLPClassifier:tol": 0.007940381602575578,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012121706551608824,
            "feature_preprocessor:select_rates_classification:alpha": 0.06308153333838556,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1243278980255127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4314811560885204e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1577515850847388,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 3.577631911707995e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18347193937472686,
            "feature_preprocessor:select_percentile_classification:percentile": 21.21450250904416,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2603001031899161,
        "time": 0.3634769916534424,
        "additional_info": {
            "duration": 0.33901500701904297,
            "num_run": 532,
            "train_loss": 1.1797534276987867,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.1294551547432895e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013430794016362028,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.009839628801433693,
            "feature_preprocessor:select_rates_classification:alpha": 0.1479294846438314,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09721493721008301,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3966738260631232e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04402079166321658,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.00013898138368681796,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7697374026666126,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.34917569160461426,
        "additional_info": {
            "duration": 0.33325791358947754,
            "num_run": 534,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01243089028326871,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014419783275032504,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 0.0011351142117629368,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03327601040774231,
            "feature_preprocessor:select_rates_classification:alpha": 0.08838173513187897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1305692195892334,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.9979900122319718e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7624905490445785,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 1.1427977722799621e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.30138071722006304,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1242818832397461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01690582994499256,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05896325280058162,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 0.00011270499413632399,
            "feature_preprocessor:select_rates_classification:alpha": 0.1632729389904495,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13483381271362305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06295132505010351,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9798418935187577,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 1.999560127304187e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000140494219582111,
            "feature_preprocessor:select_rates_classification:alpha": 0.038672032983225885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12420296669006348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.169303315055598e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08473470091733261,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 3.4114769557148196e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036454575972774367,
            "feature_preprocessor:select_rates_classification:alpha": 0.3031230263812966,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12922883033752441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.555781400078711e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024552644797401577,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 9.914900943363403e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.21582809745915585,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13303899765014648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.026095648343489555,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005838535628111886,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.0014142685330588195,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002703700095632801,
            "feature_preprocessor:select_rates_classification:alpha": 0.12977220837845627,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12545990943908691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.827713416311322e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004603088274001537,
            "classifier:CustomMLPClassifier:max_iter": 350,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.0002870092895907496,
            "feature_preprocessor:select_rates_classification:alpha": 0.17213057041425064,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.18253302574157715,
        "additional_info": {
            "duration": 0.16983699798583984,
            "num_run": 542,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.606816872111677e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027734414811016405,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.004104102967240653,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.042611069938386814,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7397808295928815,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.015264916588339734,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.23868385341415976,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2084854694077016,
        "time": 0.31757473945617676,
        "additional_info": {
            "duration": 0.3007190227508545,
            "num_run": 543,
            "train_loss": 1.1749267261126757,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.34646873202045e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03304278683880608,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.00985908763921722,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.04887366060172206,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10355114936828613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.507336264036467e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06860165937171814,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.0010293435069204354,
            "feature_preprocessor:select_rates_classification:alpha": 0.44392881309424986,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12535715103149414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02598260112035638,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042438601600066283,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 103,
            "classifier:CustomMLPClassifier:tol": 0.0034307840146205826,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08693779595200184,
            "feature_preprocessor:select_rates_classification:alpha": 0.04852145478747793,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0986781120300293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.741882173536285e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17351729921296383,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.0003537885742542393,
            "feature_preprocessor:select_percentile_classification:percentile": 61.927813970087556,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2839423109280177,
        "time": 0.4968898296356201,
        "additional_info": {
            "duration": 0.4799458980560303,
            "num_run": 547,
            "train_loss": 1.0308818618698001,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.171153503151656e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5033507428788291,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 4.0611452034831565e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003089272228647806,
            "feature_preprocessor:select_rates_classification:alpha": 0.4778388884146397,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10110592842102051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.600593190987732e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024327400854321185,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 0.00852501774400908,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0068461314166618345,
            "feature_preprocessor:select_percentile_classification:percentile": 12.867663892159525,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.2332170009613037,
        "additional_info": {
            "duration": 0.2193150520324707,
            "num_run": 549,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.8942782721880637e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013260689993333213,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.0018923386410565875,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15800253318930418,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 408,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3073879916791935,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2388056932082405,
        "time": 0.3333418369293213,
        "additional_info": {
            "duration": 0.3005058765411377,
            "num_run": 550,
            "train_loss": 1.1743707606180522,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.028242061208997978,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003121005361515065,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 3.0020629868807818e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3726527702736802,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12404990196228027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007128538961021719,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6181666123765132,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 1.1008019893765558e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12796098629369224,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12637615203857422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00021992152419599985,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020878779046997784,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 1.3599579298899706e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.010526080261018719,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09695172309875488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0058548910996296015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31282679766575133,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 7.13052475926128e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19282256427645686,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8140269002147734,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03207503583748948,
            "feature_preprocessor:select_rates_classification:alpha": 0.22877635556828285,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2482045444193013,
        "time": 0.4142289161682129,
        "additional_info": {
            "duration": 0.39778804779052734,
            "num_run": 554,
            "train_loss": 1.2241882790090357,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.420613132103203e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.049152916760222945,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.0036028477264084253,
            "feature_preprocessor:select_rates_classification:alpha": 0.4758787924284347,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10304927825927734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00234891230496013,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021729691039296649,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.00021117704717353128,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9037446856570209,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2547642491964168,
        "time": 0.45638203620910645,
        "additional_info": {
            "duration": 0.44022393226623535,
            "num_run": 556,
            "train_loss": 1.2272101831704931,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.0057775112450854e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15349792176038393,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.004968521690672091,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 737,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 23.227481184557004,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2674733619459626,
        "time": 0.43627095222473145,
        "additional_info": {
            "duration": 0.4235877990722656,
            "num_run": 557,
            "train_loss": 1.2460532825947777,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5096987713695671e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015347647658195361,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.00013256359619545277,
            "feature_preprocessor:select_rates_classification:alpha": 0.2867166964082337,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09710383415222168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.118354073737087e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05824260465170197,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 1.6233376111374526e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03303878189311563,
            "feature_preprocessor:select_rates_classification:alpha": 0.46592729317636955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09647512435913086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.050374884327212766,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8394624912502161,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 2.5504613713801365e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018981049995151706,
            "feature_preprocessor:select_percentile_classification:percentile": 87.74992984902649,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2303621768951416,
        "additional_info": {
            "duration": 0.2148292064666748,
            "num_run": 560,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005133555333405341,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005670649386747856,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0071361198906971296,
            "feature_preprocessor:select_percentile_classification:percentile": 8.888057145822645,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2451349050064278,
        "time": 0.21299409866333008,
        "additional_info": {
            "duration": 0.19912505149841309,
            "num_run": 561,
            "train_loss": 1.229676121837327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.775231832568417e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04081067906805691,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.001420034509709559,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.053911186537834756,
            "feature_preprocessor:select_rates_classification:alpha": 0.04417195651756823,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09688115119934082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.019941023389851e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026019404871799205,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.004415087672371414,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4080619486516453,
            "feature_preprocessor:select_rates_classification:alpha": 0.3537471557051229,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1020810604095459,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004032915066171714,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08293579952321958,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 1.8836816372684484e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.047346492224122155,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3046000228092026,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.236643766750164,
        "time": 0.42949724197387695,
        "additional_info": {
            "duration": 0.36240482330322266,
            "num_run": 564,
            "train_loss": 1.1495800208397313,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0318964086584186e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1733758483339274,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.00411592437038461,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6222599604291061,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3596680164337158,
        "additional_info": {
            "duration": 0.2949361801147461,
            "num_run": 565,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002000475075603079,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.37595777399179486,
            "classifier:CustomMLPClassifier:max_iter": 370,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 0.0004212506545459694,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038970111030242,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18219462862411595,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.23504061872337,
        "time": 0.34049105644226074,
        "additional_info": {
            "duration": 0.3260202407836914,
            "num_run": 566,
            "train_loss": 1.2395655683524083,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.6299582133818405e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13565030608739106,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.0002671062514606057,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001572344608137846,
            "feature_preprocessor:select_rates_classification:alpha": 0.49594708950157423,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09951329231262207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.447508153172115e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09062541768942156,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0015084995333253315,
            "feature_preprocessor:select_rates_classification:alpha": 0.07622370942981553,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.544107844094213,
        "time": 0.22275781631469727,
        "additional_info": {
            "duration": 0.21111321449279785,
            "num_run": 568,
            "train_loss": 1.544258233216406,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1373584909668334e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016345334702182068,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 254,
            "classifier:CustomMLPClassifier:tol": 0.00012578465163989747,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15414834847516495,
            "feature_preprocessor:select_rates_classification:alpha": 0.41078871025697444,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5119760036468506,
        "additional_info": {
            "duration": 0.5005199909210205,
            "num_run": 569,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010642819161445999,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09571354186867337,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 6.680474188815355e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2815452285169439,
            "feature_preprocessor:select_rates_classification:alpha": 0.07566889427927324,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13215899467468262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6776752478181456e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5232238719534538,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.00016586538214894062,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1277,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3141786870695744,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2761899720275678,
        "time": 0.49425721168518066,
        "additional_info": {
            "duration": 0.4795820713043213,
            "num_run": 571,
            "train_loss": 1.1711962644273166,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.021547837020795588,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017417540927418145,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.00038604398015186427,
            "feature_preprocessor:select_percentile_classification:percentile": 69.31888572147861,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2239892558692471,
        "time": 0.3277301788330078,
        "additional_info": {
            "duration": 0.308485746383667,
            "num_run": 572,
            "train_loss": 1.1638828437186477,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.591667419966911e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001141092873954857,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.00032977419033499713,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000224226183448781,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7668708350359593,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.6360290050506592,
        "additional_info": {
            "duration": 0.6230850219726562,
            "num_run": 573,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03305029801208908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9882677703681475,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 0.006188632636386198,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009927982724441302,
            "feature_preprocessor:select_rates_classification:alpha": 0.18274128535628983,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2330605827080439,
        "time": 0.2276320457458496,
        "additional_info": {
            "duration": 0.21345829963684082,
            "num_run": 574,
            "train_loss": 1.2304634688029041,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00020140260727554725,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008287266252436118,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.0007524933963758516,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00029066833776890416,
            "feature_preprocessor:select_rates_classification:alpha": 0.18028696051313048,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.16128206253051758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.989926537285898e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03014965132726272,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 350,
            "classifier:CustomMLPClassifier:tol": 0.0004965360931579297,
            "feature_preprocessor:select_rates_classification:alpha": 0.03013074349419311,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1251051425933838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0022614382785522053,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15491949291533544,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 1.3101986618494401e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 92.16777456978923,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2508588224541484,
        "time": 0.7667789459228516,
        "additional_info": {
            "duration": 0.7442529201507568,
            "num_run": 577,
            "train_loss": 1.1168125461571743,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00428170082637091,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000236922435465585,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0008147233161676297,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039282732908987335,
            "feature_preprocessor:select_rates_classification:alpha": 0.4640308139269461,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10261201858520508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007540095386682418,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041261081431854916,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 410,
            "classifier:CustomMLPClassifier:tol": 0.0004337658918730978,
            "feature_preprocessor:select_rates_classification:alpha": 0.40647025741081166,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12431693077087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0072825479778383835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032429401221348823,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 313,
            "classifier:CustomMLPClassifier:tol": 0.005937784561707127,
            "feature_preprocessor:select_rates_classification:alpha": 0.4727796963073657,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16488981246948242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008786701763011402,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5531939044741316,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 378,
            "classifier:CustomMLPClassifier:tol": 0.008421600978174265,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9125657726772616,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17618853523472672,
            "feature_preprocessor:select_percentile_classification:percentile": 74.24056491414468,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2549917642189967,
        "time": 0.29834699630737305,
        "additional_info": {
            "duration": 0.28621697425842285,
            "num_run": 581,
            "train_loss": 1.2145304454509538,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007837879559448917,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09343527619128918,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 2.3837702691478822e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008993692188993152,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9867022349155687,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2748995518415115,
            "feature_preprocessor:select_rates_classification:alpha": 0.487228192221341,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2152403019898634,
        "time": 0.4993860721588135,
        "additional_info": {
            "duration": 0.4845759868621826,
            "num_run": 582,
            "train_loss": 1.1279227818259456,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003788995012197417,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.034928728795701275,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 392,
            "classifier:CustomMLPClassifier:tol": 0.0001278268825751279,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005955185110857752,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7574904370864144,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2698097863633799,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.36544802255958087,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2194327799374176,
        "time": 0.40390563011169434,
        "additional_info": {
            "duration": 0.39103007316589355,
            "num_run": 583,
            "train_loss": 1.1265547750070892,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.054549665170877e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00616960345369191,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.00028716528820248036,
            "feature_preprocessor:select_rates_classification:alpha": 0.2984167970534016,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12609577178955078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.862515533246895e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006599496079520326,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.0051981684425914405,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8022663359488,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.019209788376545665,
            "feature_preprocessor:select_rates_classification:alpha": 0.4674967529985267,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2451187765272933,
        "time": 0.26340413093566895,
        "additional_info": {
            "duration": 0.2470719814300537,
            "num_run": 585,
            "train_loss": 1.1938617681462917,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03022042117738709,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21302824838337156,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.00032005780762265284,
            "feature_preprocessor:select_rates_classification:alpha": 0.406444170615347,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1255350112915039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1194135728311518e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026757570861473005,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 8.556457857241048e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9461079092806255,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3592500686645508,
        "additional_info": {
            "duration": 0.3406858444213867,
            "num_run": 587,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.044672112632086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2683903785727352,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 4.356629422130928e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012825135221082816,
            "feature_preprocessor:select_percentile_classification:percentile": 88.53430198117722,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.33922576904296875,
        "additional_info": {
            "duration": 0.32417917251586914,
            "num_run": 588,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015350095461808043,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006132293925137957,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0003123757584688354,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8084050925245421,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2607549595560568,
        "time": 0.6644580364227295,
        "additional_info": {
            "duration": 0.6458191871643066,
            "num_run": 589,
            "train_loss": 1.1845027467935652,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005163819409326995,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9177518335986272,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 70,
            "classifier:CustomMLPClassifier:tol": 0.0002851863219508404,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00035649779841026574,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.415041968644848,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.4705068148109595,
        "time": 0.303617000579834,
        "additional_info": {
            "duration": 0.2855219841003418,
            "num_run": 590,
            "train_loss": 1.46186554962089,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0944538275554126,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04798390099050232,
            "classifier:CustomMLPClassifier:max_iter": 152,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.001005264355774794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09283640787344509,
            "feature_preprocessor:select_rates_classification:alpha": 0.3074548856583222,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12866711616516113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4487049969613924e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010842247618045673,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 289,
            "classifier:CustomMLPClassifier:tol": 0.0036033093901820315,
            "feature_preprocessor:select_rates_classification:alpha": 0.10344412561056145,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10211777687072754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.248596215746162e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00040979822832047186,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.00016259932960944768,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0074461422138372224,
            "feature_preprocessor:select_rates_classification:alpha": 0.43025672288265115,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09662914276123047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.071462424339092e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011159024056728653,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 0.0033527711078769483,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04011737678223698,
            "feature_preprocessor:select_rates_classification:alpha": 0.02557345453614486,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10245299339294434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.273202598570878e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3787800563170028,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 0.0029159520043164563,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008087490433224752,
            "feature_preprocessor:select_rates_classification:alpha": 0.08665339651841213,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09670519828796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003541456929071105,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21625409618515043,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 0.0007566382606903088,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25543698791320424,
            "feature_preprocessor:select_rates_classification:alpha": 0.06797684770883647,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10560989379882812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01640933193528779,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06269823944397532,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 0.0018410911956584215,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019025982767601395,
            "feature_preprocessor:select_rates_classification:alpha": 0.353579053618469,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12919211387634277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001360015716160638,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008620791815172204,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 117,
            "classifier:CustomMLPClassifier:tol": 0.0072595533407837035,
            "feature_preprocessor:select_rates_classification:alpha": 0.39057084057102504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13055801391601562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004929167671988009,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1491033749300988,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 0.00022153191595376172,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002098378412629421,
            "feature_preprocessor:select_percentile_classification:percentile": 68.39051548031435,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.5227229595184326,
        "additional_info": {
            "duration": 0.5093240737915039,
            "num_run": 599,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.471805784994075e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000642976292914774,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 0.0003658805181674307,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003927111889838201,
            "feature_preprocessor:select_rates_classification:alpha": 0.24918677155147648,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3742690086364746,
        "additional_info": {
            "duration": 0.35847997665405273,
            "num_run": 600,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.5356307041878553e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04739980137498709,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 2.04011650448693e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10130290888897452,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.969299309855635,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21006089178218548,
            "feature_preprocessor:select_rates_classification:alpha": 0.3252204359966413,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2518604585866688,
        "time": 1.0944180488586426,
        "additional_info": {
            "duration": 1.0752019882202148,
            "num_run": 601,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09635915839485107,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002514501698661223,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 0.00018496705955662267,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3275150786351072,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2457606313292806,
        "time": 1.340425968170166,
        "additional_info": {
            "duration": 1.317453145980835,
            "num_run": 602,
            "train_loss": 1.1922012184621245,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017232542178369445,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009559623399996837,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 465,
            "classifier:CustomMLPClassifier:tol": 0.000429743183947425,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1420016471341852,
            "feature_preprocessor:select_percentile_classification:percentile": 10.003113316370026,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2589234485870828,
        "time": 0.2536640167236328,
        "additional_info": {
            "duration": 0.2432389259338379,
            "num_run": 603,
            "train_loss": 1.233851384418073,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1117585218862854e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7114234103609492,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 1.1104383035056342e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01920263130951155,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 271,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4431898944115664,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2124506060116955,
        "time": 0.30560803413391113,
        "additional_info": {
            "duration": 0.28676795959472656,
            "num_run": 604,
            "train_loss": 1.1953991800363815,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0451873503153334e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008038456751324453,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 0.0024997542011238705,
            "feature_preprocessor:select_rates_classification:alpha": 0.08781334594366429,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1029500961303711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.44240138522524e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21828858685359767,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 264,
            "classifier:CustomMLPClassifier:tol": 0.0005527138974699353,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03738995050917419,
            "feature_preprocessor:select_rates_classification:alpha": 0.12914389592893927,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09784221649169922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.152172454899303e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28967466127490354,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.008802246970033158,
            "feature_preprocessor:select_rates_classification:alpha": 0.05265826010425851,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10213279724121094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0043803489963686534,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04187613865891125,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 313,
            "classifier:CustomMLPClassifier:tol": 3.175785846581956e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020740160850577795,
            "feature_preprocessor:select_rates_classification:alpha": 0.011661412719751964,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.211558130196678,
        "time": 0.23721671104431152,
        "additional_info": {
            "duration": 0.22315502166748047,
            "num_run": 608,
            "train_loss": 1.2061252107188751,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011104099146116848,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006450166427421675,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 1.39473269562138e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08519581316133351,
            "feature_preprocessor:select_rates_classification:alpha": 0.10747763717713106,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0980072021484375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007256972671816596,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012834326189077967,
            "classifier:CustomMLPClassifier:max_iter": 264,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 2.3435836182801886e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05118914902960413,
            "feature_preprocessor:select_rates_classification:alpha": 0.2514510321717209,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12422776222229004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.5557186321328276e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7363786839218152,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.0028614859648003503,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9414488751682911,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1575622637343602,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9639542714548627,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2322479882086088,
        "time": 0.32891321182250977,
        "additional_info": {
            "duration": 0.315385103225708,
            "num_run": 611,
            "train_loss": 1.2396819558002803,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.95471020692578e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06291064252977556,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.006215148964793263,
            "feature_preprocessor:select_rates_classification:alpha": 0.022266933974196393,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1252269744873047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.2885230591322844e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014912959504440656,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 9.03602951789775e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17671691582622276,
            "feature_preprocessor:select_rates_classification:alpha": 0.209260280313098,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.417003870010376,
        "additional_info": {
            "duration": 0.40068888664245605,
            "num_run": 613,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.094875528346413e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016858981026900853,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.0002754015489091389,
            "feature_preprocessor:select_rates_classification:alpha": 0.2912871644867087,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2922701835632324,
        "additional_info": {
            "duration": 0.27245402336120605,
            "num_run": 614,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004824179700920896,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027608244825317067,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 0.00471875674548031,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 707,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.04812231618029575,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2493477280868586,
        "time": 0.30117297172546387,
        "additional_info": {
            "duration": 0.2854428291320801,
            "num_run": 615,
            "train_loss": 1.1991971214584616,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.1174925421526667e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00026214838361278056,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.004530052728653592,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0622815713349602,
            "feature_preprocessor:select_rates_classification:alpha": 0.1144269610797245,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09647178649902344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06217312523343512,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00502589284706521,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.001146791787945767,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08366184720215351,
            "feature_preprocessor:select_rates_classification:alpha": 0.24592933360601896,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.22457170486450195,
        "additional_info": {
            "duration": 0.20826125144958496,
            "num_run": 617,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0006955199543177701,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0679790661118885,
            "classifier:CustomMLPClassifier:max_iter": 234,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0002821823298650522,
            "feature_preprocessor:select_rates_classification:alpha": 0.09148163908114582,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10170483589172363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00016075401520735793,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010292196976152705,
            "classifier:CustomMLPClassifier:max_iter": 269,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.0027832176596306836,
            "feature_preprocessor:select_rates_classification:alpha": 0.032158455252064955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09699606895446777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0013096108306684332,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000141473968407688,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 0.0011110432657561308,
            "feature_preprocessor:select_rates_classification:alpha": 0.2737941254638635,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09645605087280273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.791154398941662e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007248400982765165,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 1.9890935016053967e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039182805312338836,
            "feature_preprocessor:select_percentile_classification:percentile": 4.074016565690592,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3439981937408447,
        "additional_info": {
            "duration": 0.3312339782714844,
            "num_run": 621,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00026196642939990054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17493050266484952,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 346,
            "classifier:CustomMLPClassifier:tol": 0.0005303249914368795,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011334737474012205,
            "feature_preprocessor:select_rates_classification:alpha": 0.46265413076063056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09687995910644531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.7398492657878436e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5008138011293823,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.0025652067104384225,
            "feature_preprocessor:select_rates_classification:alpha": 0.48638515304179775,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12967300415039062,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0276014785170449,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020302561118130157,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.004320751645637613,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008730075676400146,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9276757636096687,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.28119564056396484,
        "additional_info": {
            "duration": 0.26949501037597656,
            "num_run": 624,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.927916726499814e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1455029005371573,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0001679932620330527,
            "feature_preprocessor:select_rates_classification:alpha": 0.34036852814390534,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13205814361572266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.038614974252995e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014957413168388334,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.003051985224220302,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018498549322359117,
            "feature_preprocessor:select_rates_classification:alpha": 0.23988428358089406,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12426590919494629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.574900935291435e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016248529973411606,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 0.0024464820591450194,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07138617202083417,
            "feature_preprocessor:select_percentile_classification:percentile": 91.39329113548861,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.2551610469818115,
        "additional_info": {
            "duration": 0.24276256561279297,
            "num_run": 627,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.016494517338211643,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012311481015347275,
            "classifier:CustomMLPClassifier:max_iter": 421,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.0006243181145077608,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018349397707920146,
            "feature_preprocessor:select_rates_classification:alpha": 0.35835463061502787,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2454331503767713,
        "time": 0.28400206565856934,
        "additional_info": {
            "duration": 0.2639460563659668,
            "num_run": 628,
            "train_loss": 1.2017118343550401,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.5287562926011965e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8584040023212847,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.005332508387659365,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017489106289982615,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.05500553505261652,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2583159807801128,
        "time": 0.33828210830688477,
        "additional_info": {
            "duration": 0.32709217071533203,
            "num_run": 629,
            "train_loss": 1.0751504560087042,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00018230671766709082,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003994923518439878,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.00021611625349272052,
            "feature_preprocessor:select_rates_classification:alpha": 0.4438688563315697,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.274507999420166,
        "additional_info": {
            "duration": 0.25980591773986816,
            "num_run": 630,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.140586074699234e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015349267814389155,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 351,
            "classifier:CustomMLPClassifier:tol": 0.00014580585699620647,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0033292743212484247,
            "feature_preprocessor:select_percentile_classification:percentile": 43.20668090354338,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.235733032419264,
        "time": 1.3734877109527588,
        "additional_info": {
            "duration": 1.3558249473571777,
            "num_run": 631,
            "train_loss": 1.1891977393192787,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005351238184850617,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.40820099485987765,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.001978580076985433,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008923214747688035,
            "feature_preprocessor:select_rates_classification:alpha": 0.13601040072151221,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0973060131072998,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.93304271385991e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010415175757739997,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.0010278963623638246,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.23559967772717672,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2562440213645472,
        "time": 0.3721022605895996,
        "additional_info": {
            "duration": 0.35616517066955566,
            "num_run": 633,
            "train_loss": 1.1992331255220718,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008688693875490216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06758301050932941,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 2.4440738287886538e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04788179835905374,
            "feature_preprocessor:select_rates_classification:alpha": 0.3482234900623277,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3131389617919922,
        "additional_info": {
            "duration": 0.29187893867492676,
            "num_run": 634,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1973176223876319e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005222720683279114,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.0013622372671422067,
            "feature_preprocessor:select_rates_classification:alpha": 0.41202272827884784,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12410902976989746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08770377113929839,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019037176251837984,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.0019070374764631373,
            "feature_preprocessor:select_rates_classification:alpha": 0.49213056380904807,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10190391540527344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.279163223540409e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020356722202874142,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 0.0007180586541240119,
            "feature_preprocessor:select_rates_classification:alpha": 0.2931753772329975,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10242104530334473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0021467885157452175,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10738951968815998,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 0.001980755441258676,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023111690418113504,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8204782814314674,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21415525732377572,
            "feature_preprocessor:select_rates_classification:alpha": 0.30852724843338286,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.222694438939725,
        "time": 0.4169631004333496,
        "additional_info": {
            "duration": 0.4008822441101074,
            "num_run": 638,
            "train_loss": 1.1819214491361978,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.032400267005581,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5060515519696608,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.0003006798481574627,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01772569443367415,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7036880071271209,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2626389338365663,
            "feature_preprocessor:select_rates_classification:alpha": 0.3246050618026901,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.233207194816422,
        "time": 0.4218909740447998,
        "additional_info": {
            "duration": 0.40160393714904785,
            "num_run": 639,
            "train_loss": 1.1588661880916247,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3206126781544884e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9880755383897393,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.008868771786346843,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06918372811963014,
            "feature_preprocessor:select_rates_classification:alpha": 0.39817617469129046,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10248684883117676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001913920159552292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09645117051366882,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 1.3108484284316666e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012661079665734855,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1264,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.49357292089480864,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2785480478893099,
        "time": 0.37706923484802246,
        "additional_info": {
            "duration": 0.3565819263458252,
            "num_run": 641,
            "train_loss": 1.0727942214799264,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2461379517695361e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013108079651858885,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.0005528346872950139,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14265428300393315,
            "feature_preprocessor:select_rates_classification:alpha": 0.1898357459357626,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10010910034179688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.572067944333272e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012020127439481677,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.00017780462211533182,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004670056943957011,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09010810625041565,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.27585887908935547,
        "additional_info": {
            "duration": 0.2583470344543457,
            "num_run": 643,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03293663061453459,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01978167101507536,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.005797623491371116,
            "feature_preprocessor:select_rates_classification:alpha": 0.1537725414973267,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12435102462768555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.018585930475648292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031929248436038276,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0011387104759684687,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018118156381131513,
            "feature_preprocessor:select_rates_classification:alpha": 0.047096672939525366,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12443017959594727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.013181006509822483,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010674519369206833,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 0.000331883797809696,
            "feature_preprocessor:select_rates_classification:alpha": 0.48344255484156934,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.22225689888000488,
        "additional_info": {
            "duration": 0.2104501724243164,
            "num_run": 646,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007150887793240864,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010028451417722665,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 1.0828536386815512e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07709699113239867,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.6925413608551025,
        "additional_info": {
            "duration": 0.6821980476379395,
            "num_run": 647,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003229725032772516,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006733946836918134,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 5.4967228658219784e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004753709658406582,
            "feature_preprocessor:select_rates_classification:alpha": 0.31990075574453447,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.253326993392503,
        "time": 0.2950279712677002,
        "additional_info": {
            "duration": 0.28238677978515625,
            "num_run": 648,
            "train_loss": 1.1786985127149197,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03963596836265592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.38444488658734643,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.0060313980830210305,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.610099416288648,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2233494008447436,
        "time": 0.36359214782714844,
        "additional_info": {
            "duration": 0.3425867557525635,
            "num_run": 649,
            "train_loss": 1.1796749187454763,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.315503622416869e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2814325283414419,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.0014272767650578447,
            "feature_preprocessor:select_percentile_classification:percentile": 17.485695295169947,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.247415186169581,
        "time": 0.32291316986083984,
        "additional_info": {
            "duration": 0.29987001419067383,
            "num_run": 650,
            "train_loss": 1.2100192401392644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007314816908559246,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031455012367065677,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.00029034340208429824,
            "feature_preprocessor:select_percentile_classification:percentile": 65.92470371786668,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.2937290668487549,
        "additional_info": {
            "duration": 0.27764892578125,
            "num_run": 651,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04388483740722844,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16808955774073017,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 8.307933546900961e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4548142896723194,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2550422362733937,
        "time": 0.3690953254699707,
        "additional_info": {
            "duration": 0.35652899742126465,
            "num_run": 652,
            "train_loss": 1.02621217819031,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012544228906094215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009886799664347821,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 0.00017198970479105668,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039203958930702273,
            "feature_preprocessor:select_rates_classification:alpha": 0.43859955893330294,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12531709671020508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02924501845818916,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07157988391094552,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.00010148981277114438,
            "feature_preprocessor:select_rates_classification:alpha": 0.4647439233565363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12387609481811523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007834119564976797,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019556637590004512,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.0005627573316354761,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013221489901268094,
            "feature_preprocessor:select_rates_classification:alpha": 0.31797244855470524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09720396995544434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.884800573301962e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001676093043475215,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 3.284807129387043e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.032851336908254244,
            "feature_preprocessor:select_rates_classification:alpha": 0.1928037158528979,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.252033328320865,
        "time": 1.1572790145874023,
        "additional_info": {
            "duration": 1.1433420181274414,
            "num_run": 656,
            "train_loss": 1.1716053952582957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2032648015149737e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000772953009723026,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.004978891006580987,
            "feature_preprocessor:select_rates_classification:alpha": 0.38373516251959255,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12463688850402832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003980801646323366,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04267274046246915,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 2.2355634865646218e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.23455895457129483,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10198593139648438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00027982124425917075,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000428343878855251,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 144,
            "classifier:CustomMLPClassifier:tol": 0.00041780196299070474,
            "feature_preprocessor:select_rates_classification:alpha": 0.47836596201060266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12505292892456055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004763683130748299,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.42142908752604047,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.00041664504787929037,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04098128270355719,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5126955016604825,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.29912686347961426,
        "additional_info": {
            "duration": 0.2859232425689697,
            "num_run": 660,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.025508967673232328,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2121310405059577,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.007752277679803901,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019902924516680313,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45555711922077113,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2652082745028341,
        "time": 0.3236229419708252,
        "additional_info": {
            "duration": 0.30657005310058594,
            "num_run": 661,
            "train_loss": 1.2190966453301126,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.021028736668129,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005663126028356404,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 1.0923111858760663e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.012378088468055855,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09848594665527344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2066343726548447e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022100947736377946,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.0002919359405812325,
            "feature_preprocessor:select_rates_classification:alpha": 0.43106728261294225,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09733819961547852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.015820186834865323,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007756747999184915,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 6.893231281794175e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2663726466391149,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12439894676208496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010189031286036904,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036759881202964547,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.001518629080796607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10937022808790438,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5507456797920923,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.29584789276123047,
        "additional_info": {
            "duration": 0.27347254753112793,
            "num_run": 665,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.779276782188592e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06121486570110445,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 90,
            "classifier:CustomMLPClassifier:tol": 5.460023436098596e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.42792096781513245,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12590289115905762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.288875333477036e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4205827791551053,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 421,
            "classifier:CustomMLPClassifier:tol": 2.5482877197882665e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49683494409104406,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10212182998657227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.409202252979863e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24519837414677342,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 0.002443779440496311,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010110209929891137,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1029,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12198538358474564,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.224054921643669,
        "time": 0.3183879852294922,
        "additional_info": {
            "duration": 0.30478692054748535,
            "num_run": 668,
            "train_loss": 1.199685041731116,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0031594727204009234,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6539242178569619,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 0.0011062141687456608,
            "feature_preprocessor:select_rates_classification:alpha": 0.16707428369045568,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10195517539978027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001340735155013205,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004807295680255277,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.0009673950196575235,
            "feature_preprocessor:select_percentile_classification:percentile": 75.50429561985,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.2596743106842041,
        "additional_info": {
            "duration": 0.249039888381958,
            "num_run": 670,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008884122867172089,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08661273177158553,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 4.4101577038024714e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2527133722127575,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09644699096679688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08720387950179835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001608130769715557,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 0.00010595755305390914,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1190,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.36358589360983595,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2458748562201252,
        "time": 1.0211012363433838,
        "additional_info": {
            "duration": 1.0082769393920898,
            "num_run": 672,
            "train_loss": 1.107845076590428,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007355833895233337,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27437972452146625,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 1.2314670533799407e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2058533088996355,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2560549797314617,
        "time": 0.4241039752960205,
        "additional_info": {
            "duration": 0.4080538749694824,
            "num_run": 673,
            "train_loss": 1.2281425748478498,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0034043906928459535,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00033462132800676683,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 2.5436488664510476e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002017763814642523,
            "feature_preprocessor:select_rates_classification:alpha": 0.27472436977229225,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09721684455871582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1540345468413015e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004067647860546593,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.00012375304519133583,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8073297116181976,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12518709434230113,
            "feature_preprocessor:select_percentile_classification:percentile": 28.744130672660283,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2393868599696378,
        "time": 0.5382390022277832,
        "additional_info": {
            "duration": 0.52236008644104,
            "num_run": 675,
            "train_loss": 1.0913332368479003,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.5927189344996067e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001624184962041299,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0006024077971771216,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9892468919393794,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2528100953534929,
            "feature_preprocessor:select_rates_classification:alpha": 0.20611777015758095,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.24615097045898438,
        "additional_info": {
            "duration": 0.23045086860656738,
            "num_run": 676,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002782462282749463,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3016192021288051,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 0.00016040613220439571,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004496121535113242,
            "feature_preprocessor:select_rates_classification:alpha": 0.47749647040486815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12781095504760742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.84680525525815e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001340324432742327,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.00022585697274570313,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.057216245806896646,
            "feature_preprocessor:select_rates_classification:alpha": 0.3804173765366184,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1245577335357666,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001009957717889746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5328856159568554,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 0.0029199590458196425,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029166232161653805,
            "feature_preprocessor:select_rates_classification:alpha": 0.33925448068608055,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09732198715209961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.024748032340026427,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019771285800410637,
            "classifier:CustomMLPClassifier:max_iter": 234,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.00923486171330133,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9951877613997853,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13358388631182316,
            "feature_preprocessor:select_rates_classification:alpha": 0.2926131007411291,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.262780489891948,
        "time": 0.20583486557006836,
        "additional_info": {
            "duration": 0.1898057460784912,
            "num_run": 680,
            "train_loss": 1.1095422448257728,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.028926274546151e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008649777509792284,
            "classifier:CustomMLPClassifier:max_iter": 481,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.0018159426851838479,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11483452660505701,
            "feature_preprocessor:select_rates_classification:alpha": 0.4861917130502532,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12460088729858398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.640093053939166e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015177310116998322,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.00019672663533401244,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016258302467544836,
            "feature_preprocessor:select_rates_classification:alpha": 0.21962366658838242,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12498188018798828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.652225083653975e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00038653849599973387,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.0008967364529159742,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2711512836127883,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2650698351834104,
        "time": 0.46344923973083496,
        "additional_info": {
            "duration": 0.40083909034729004,
            "num_run": 683,
            "train_loss": 1.2002347378856948,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001052293322122715,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004881466512485355,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.0005574234074687856,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.42458638754969014,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3881525993347168,
        "additional_info": {
            "duration": 0.3745880126953125,
            "num_run": 684,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.207308341637111e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001986729360919516,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.0007817697616136251,
            "feature_preprocessor:select_rates_classification:alpha": 0.28795668922075274,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12934517860412598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012007742210495466,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018579288572529702,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.0003396061985488383,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040673641476935096,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6352013086272178,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2403804101527136,
        "time": 0.2988770008087158,
        "additional_info": {
            "duration": 0.2816751003265381,
            "num_run": 686,
            "train_loss": 1.1972375280828935,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1575554446400351e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3075651313963575,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 2.0491715426585247e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003908957053753782,
            "feature_preprocessor:select_rates_classification:alpha": 0.3739209932500245,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12482118606567383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.053455359079584e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018461638902413254,
            "classifier:CustomMLPClassifier:max_iter": 461,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 2.0759646787076207e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024087595158385204,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8009464025029793,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26423567719404406,
            "feature_preprocessor:select_rates_classification:alpha": 0.045177668432741076,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2451349050064278,
        "time": 0.33272409439086914,
        "additional_info": {
            "duration": 0.27031874656677246,
            "num_run": 688,
            "train_loss": 1.229676121837327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00103023779435264,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015345557946524398,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 0.0005370847449291849,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2093645216444101,
            "feature_preprocessor:select_percentile_classification:percentile": 52.58986540912854,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2551969343312166,
        "time": 0.3996748924255371,
        "additional_info": {
            "duration": 0.3888239860534668,
            "num_run": 689,
            "train_loss": 1.027591726200166,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.015704360450754663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0046316356003686795,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 0.00024066662077439286,
            "feature_preprocessor:select_rates_classification:alpha": 0.38433983590191084,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09682297706604004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.95471020692578e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028149900783342154,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.006215148964793263,
            "feature_preprocessor:select_rates_classification:alpha": 0.010244249553211121,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1290602684020996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018965967916295496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35657437647658247,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 0.003334190061420733,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011194250452517266,
            "feature_preprocessor:select_percentile_classification:percentile": 79.89770158235474,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.23572206497192383,
        "additional_info": {
            "duration": 0.21967506408691406,
            "num_run": 692,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.6329396304173584e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11661599096079327,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.0020744708462306465,
            "feature_preprocessor:select_rates_classification:alpha": 0.4673555233743721,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2513095490060566,
        "time": 0.6038899421691895,
        "additional_info": {
            "duration": 0.5913777351379395,
            "num_run": 693,
            "train_loss": 1.0974431669595128,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07027886418366368,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006067719736184638,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 133,
            "classifier:CustomMLPClassifier:tol": 0.0017997527614909807,
            "feature_preprocessor:select_rates_classification:alpha": 0.09798500177702205,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09718489646911621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1446726934826156e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03852081502815393,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.0029220509124950056,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.030344894362261732,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.6502718925476074,
        "additional_info": {
            "duration": 0.6301591396331787,
            "num_run": 695,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.033296404231070595,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012678051053683027,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.0007267730178453948,
            "feature_preprocessor:select_rates_classification:alpha": 0.07053872260443082,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.11307311058044434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007399564348179905,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007413553152091117,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 3.507736555325356e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22520629360418132,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10137724876403809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003172515822020725,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13774125282873953,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.0010360967911664165,
            "feature_preprocessor:select_rates_classification:alpha": 0.34267746046248765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1249392032623291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9404728714598714e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011283011028044022,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.002079040478297382,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022373830692484255,
            "feature_preprocessor:select_rates_classification:alpha": 0.3249388728085684,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09762120246887207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0853268405946527e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006095877178779502,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.00021633892561903287,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002750001817361135,
            "feature_preprocessor:select_percentile_classification:percentile": 2.4127653022796967,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.23331904411315918,
        "additional_info": {
            "duration": 0.22029709815979004,
            "num_run": 700,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0051460773504461545,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018635591544680884,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.0008670702453948939,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015314489022620766,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9824192007056314,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04688334144632001,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14503324409937313,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2207437253460744,
        "time": 0.28527307510375977,
        "additional_info": {
            "duration": 0.2721290588378906,
            "num_run": 701,
            "train_loss": 1.182349004985788,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007095192089340736,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0032721272148131513,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 103,
            "classifier:CustomMLPClassifier:tol": 0.0032206949305451115,
            "feature_preprocessor:select_rates_classification:alpha": 0.11331217565406053,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12965679168701172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002633799721911632,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011817105374336368,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 7.034715836652613e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.059167629422719796,
            "feature_preprocessor:select_rates_classification:alpha": 0.02972817967137048,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09847068786621094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011606163926979216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008900846743349574,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.0001474905099817156,
            "feature_preprocessor:select_rates_classification:alpha": 0.15388210223625004,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.216674492997919,
        "time": 0.3828749656677246,
        "additional_info": {
            "duration": 0.371082067489624,
            "num_run": 704,
            "train_loss": 1.2011742938790284,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4546286685544827e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009720486363489261,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.0012951799784124505,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027297583969814607,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 83,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20639212682698782,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2167836533154222,
        "time": 0.3453707695007324,
        "additional_info": {
            "duration": 0.32979297637939453,
            "num_run": 705,
            "train_loss": 1.1776665511401636,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005068439268077079,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09236199619712648,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.002230260086170492,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2101751999928563,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9500109657112294,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.30226588249206543,
        "additional_info": {
            "duration": 0.2855679988861084,
            "num_run": 706,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009727664036235774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027970368410783267,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 0.00040300688886552976,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.76284175193691,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1767725752306419,
            "feature_preprocessor:select_rates_classification:alpha": 0.2576547834470479,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.292877197265625,
        "additional_info": {
            "duration": 0.2767519950866699,
            "num_run": 707,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0026307359986116434,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013350065671783196,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 3.436434746479521e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001701577525090227,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1103,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 85.54218516825736,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2520151132247368,
        "time": 0.8340880870819092,
        "additional_info": {
            "duration": 0.8152132034301758,
            "num_run": 708,
            "train_loss": 1.0239962774990865,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09524077853107266,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2812170131971252,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 9.876673223555849e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0119910335059931,
            "feature_preprocessor:select_rates_classification:alpha": 0.02885852437455596,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10244297981262207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007560421601857658,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002123827128051811,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 1.534018247635723e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.46350648146042256,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2311311490063792,
        "time": 0.4017019271850586,
        "additional_info": {
            "duration": 0.38460206985473633,
            "num_run": 710,
            "train_loss": 1.1992212013295502,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02599878577645214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.452803264300706,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 5.089346497569828e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007188771892761574,
            "feature_preprocessor:select_rates_classification:alpha": 0.48380973567352303,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2397072331515668,
        "time": 0.2856907844543457,
        "additional_info": {
            "duration": 0.27140307426452637,
            "num_run": 711,
            "train_loss": 1.156014583977333,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002194450397594481,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9175772606715992,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 2.0913485900908398e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000631640174866965,
            "feature_preprocessor:select_rates_classification:alpha": 0.16085277234018747,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0971829891204834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.3046908575627184e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002767699151727813,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.00015698721393655468,
            "feature_preprocessor:select_rates_classification:alpha": 0.19936843739734766,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2252819861817759,
        "time": 1.6135470867156982,
        "additional_info": {
            "duration": 1.5379748344421387,
            "num_run": 713,
            "train_loss": 1.1597563553676464,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01782718038012981,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05801521137876249,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 0.0006214321907328946,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030219185178034036,
            "feature_preprocessor:select_rates_classification:alpha": 0.4291092822368992,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09681105613708496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.392938263413354e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002353555804841629,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.0015779629629801928,
            "feature_preprocessor:select_percentile_classification:percentile": 72.98720095539292,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2460749617590037,
        "time": 0.26164984703063965,
        "additional_info": {
            "duration": 0.25113391876220703,
            "num_run": 715,
            "train_loss": 1.1817691911061217,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011536849230342806,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19784179400872856,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 0.004910965878256983,
            "feature_preprocessor:select_percentile_classification:percentile": 40.028130249679634,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2362332962664595,
        "time": 0.2943727970123291,
        "additional_info": {
            "duration": 0.278839111328125,
            "num_run": 716,
            "train_loss": 1.0082898267392255,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0032423335611979276,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14264936320383356,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.001066163368155371,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25057133535759624,
            "feature_preprocessor:select_rates_classification:alpha": 0.18649478969187408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12412071228027344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.246792955162913e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03518754371416452,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 3.5802131601379724e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020446554231493526,
            "feature_preprocessor:select_rates_classification:alpha": 0.02693161129394389,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12908697128295898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016650636319117236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5614471006276962,
            "classifier:CustomMLPClassifier:max_iter": 193,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 1.604715699257523e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015057220031108615,
            "feature_preprocessor:select_rates_classification:alpha": 0.1630729247816891,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09770083427429199,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001318864564139024,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02053999045389985,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 437,
            "classifier:CustomMLPClassifier:tol": 8.909618741835421e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.48870784929880307,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.9546349048614502,
        "additional_info": {
            "duration": 0.9416220188140869,
            "num_run": 720,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.035451199681808286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011217009608091088,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.004715967698833124,
            "feature_preprocessor:select_rates_classification:alpha": 0.34456719759776994,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1239480972290039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012529279827116766,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8814400489011507,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 1.690943537492863e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4513812311471689,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12462687492370605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0032937681700477674,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016957433292486834,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 0.00029659080624267283,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1883189260954733,
            "feature_preprocessor:select_percentile_classification:percentile": 79.76443232683798,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2546824549428606,
        "time": 2.456996202468872,
        "additional_info": {
            "duration": 2.443835973739624,
            "num_run": 723,
            "train_loss": 1.1792904822731531,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06940879789499248,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003140985844693706,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.0068180178017007995,
            "feature_preprocessor:select_rates_classification:alpha": 0.4252259088535888,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12387514114379883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011683821562407894,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019144228835875186,
            "classifier:CustomMLPClassifier:max_iter": 295,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.00020043294028976332,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04816206977345768,
            "feature_preprocessor:select_rates_classification:alpha": 0.3849875953371945,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12393379211425781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.507336264036467e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06860165937171814,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.0010293435069204354,
            "feature_preprocessor:select_rates_classification:alpha": 0.46653208955098957,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09655594825744629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.423799458013517e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0037270466563184305,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 2.6634046869482887e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39351873799268333,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09774112701416016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011568665278706592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8395528243202057,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.00012780114991801293,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1960,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.11065528204607167,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3037710189819336,
        "additional_info": {
            "duration": 0.27705907821655273,
            "num_run": 728,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.035451199681808286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011217009608091088,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.004715967698833124,
            "feature_preprocessor:select_rates_classification:alpha": 0.34456719759776994,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10194206237792969,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.027414705414200772,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01772176295268126,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.0021985995395978667,
            "feature_preprocessor:select_rates_classification:alpha": 0.25579720154429725,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12381672859191895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.838446491638881e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14911507906290347,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.004042748817470888,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010314792443960117,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1189,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.212611395490182,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.38475489616394043,
        "additional_info": {
            "duration": 0.375032901763916,
            "num_run": 731,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006585109449679423,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011460554959829375,
            "classifier:CustomMLPClassifier:max_iter": 264,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.0009325141243081445,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20805807921915576,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.8896942138671875,
        "additional_info": {
            "duration": 0.8705978393554688,
            "num_run": 732,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3832896616515252e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03771798192165354,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.0015300747511771077,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010353466623356962,
            "feature_preprocessor:select_rates_classification:alpha": 0.45488804912387915,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09718513488769531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.024628891685643067,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002230739711821793,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.0015946508050304312,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03541695402345032,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 127,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4691036525286666,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2353095416720377,
        "time": 0.8727302551269531,
        "additional_info": {
            "duration": 0.8573708534240723,
            "num_run": 734,
            "train_loss": 1.19301914612488,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6520664967059844e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016854180887765734,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.005545513650275393,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003103960979482558,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3916266629794811,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3282771110534668,
        "additional_info": {
            "duration": 0.3159668445587158,
            "num_run": 735,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011995359940634774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15781600662974543,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.003564114927555528,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7382732368206244,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.035874582399964994,
            "feature_preprocessor:select_percentile_classification:percentile": 51.93654204650998,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2214947404655647,
        "time": 1.285559892654419,
        "additional_info": {
            "duration": 1.2583458423614502,
            "num_run": 736,
            "train_loss": 1.1856266019753334,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.257790761691429e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014300440299010422,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.009485342783625906,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0057315738854405085,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8383736800771837,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.02021467435046263,
            "feature_preprocessor:select_rates_classification:alpha": 0.48464082428772287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2293057242093663,
        "time": 0.20682907104492188,
        "additional_info": {
            "duration": 0.19562792778015137,
            "num_run": 737,
            "train_loss": 1.2074557530129413,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2708356951505635e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0050989318664325664,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.001374471029273168,
            "feature_preprocessor:select_rates_classification:alpha": 0.2665108551999516,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2426111540205795,
        "time": 0.33488011360168457,
        "additional_info": {
            "duration": 0.3240211009979248,
            "num_run": 738,
            "train_loss": 1.2169607140533798,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000228687617026476,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016004108136969493,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 387,
            "classifier:CustomMLPClassifier:tol": 0.00036926176173050974,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000283066174812928,
            "feature_preprocessor:select_percentile_classification:percentile": 5.0823410460525835,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2675349712371826,
        "additional_info": {
            "duration": 0.2459430694580078,
            "num_run": 739,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.6534877361485485e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31639693081002523,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 1.2439078980379812e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015337864936367754,
            "feature_preprocessor:select_rates_classification:alpha": 0.22720980637278537,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.6037800312042236,
        "additional_info": {
            "duration": 0.5839402675628662,
            "num_run": 740,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.024749451975379096,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04518321195467012,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.0001291151107409904,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026155910095093417,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 470,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.40137777873218927,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2857404999203486,
        "time": 0.6125190258026123,
        "additional_info": {
            "duration": 0.5986969470977783,
            "num_run": 741,
            "train_loss": 1.1338991104121392,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01284543427976233,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09039746392226561,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.00015380756197557724,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 313,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8718443473306839,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2286821279232618,
        "time": 0.6032030582427979,
        "additional_info": {
            "duration": 0.5841007232666016,
            "num_run": 742,
            "train_loss": 1.166733116344648,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009039534038740606,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021158968854760558,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 0.0026671910324330282,
            "feature_preprocessor:select_rates_classification:alpha": 0.255934039724175,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.127485990524292,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0613186365269523e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007922421146790823,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 0.006390034103959305,
            "feature_preprocessor:select_percentile_classification:percentile": 72.17447493745733,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.2715919017791748,
        "additional_info": {
            "duration": 0.2583010196685791,
            "num_run": 744,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03025799141271173,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000692104445419933,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 0.00010590193685087756,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016526506924653638,
            "feature_preprocessor:select_percentile_classification:percentile": 86.5281320876472,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.67818284034729,
        "additional_info": {
            "duration": 0.6653120517730713,
            "num_run": 745,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.9378221021528895e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016346816570654396,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.00864978916694237,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005523220788119491,
            "feature_preprocessor:select_rates_classification:alpha": 0.17277042550459537,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09650921821594238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010240015450635467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010902076802425586,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 167,
            "classifier:CustomMLPClassifier:tol": 0.0020099871242454216,
            "feature_preprocessor:select_rates_classification:alpha": 0.2770566018622533,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.273021936416626,
        "additional_info": {
            "duration": 0.25870728492736816,
            "num_run": 747,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.018266102859022183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009761419923940221,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 4.15755104318943e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11913350240827172,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12894582748413086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.014585693507118e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011992294880178733,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.00014595465195027486,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1271118086333274,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6669688538199385,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2531895756716986,
        "time": 2.216893196105957,
        "additional_info": {
            "duration": 2.196010112762451,
            "num_run": 749,
            "train_loss": 1.2126447836358774,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.016265358764358778,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11540310163854027,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 2.7678831683716763e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005375584453717418,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.035441258292249755,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2321752146636067,
        "time": 1.647510051727295,
        "additional_info": {
            "duration": 1.6251499652862549,
            "num_run": 750,
            "train_loss": 1.0539923979702075,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.624413879827713e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7102412828467362,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 6.334467919413245e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01586166022085713,
            "feature_preprocessor:select_rates_classification:alpha": 0.010197739265700738,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1252899169921875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00017143246846999195,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008460715456342797,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 1.2592890783776264e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008280422117855181,
            "feature_preprocessor:select_rates_classification:alpha": 0.42199152164301973,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.6092789173126221,
        "additional_info": {
            "duration": 0.596825122833252,
            "num_run": 752,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0035557050519709225,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01580672566362198,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.009990298471283793,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020668940319937116,
            "feature_preprocessor:select_rates_classification:alpha": 0.44350851967997107,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09762096405029297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.1913615912533107e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2765844372991284,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 127,
            "classifier:CustomMLPClassifier:tol": 2.1486387819626603e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007832398733753862,
            "feature_preprocessor:select_rates_classification:alpha": 0.06519115488017443,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09752988815307617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005065975257448673,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26750968220671295,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.0014079815700517178,
            "feature_preprocessor:select_rates_classification:alpha": 0.24486917360724372,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10246920585632324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009938216278853107,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0033125843126076576,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 3.044761862617555e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06704797963013226,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12308883666992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.571707261748065e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.030993915372843808,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 0.000857437362293074,
            "feature_preprocessor:select_rates_classification:alpha": 0.22920840045444088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0969388484954834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.965749526772276e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22121080982638516,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.0005234156568246839,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00213877925852638,
            "feature_preprocessor:select_rates_classification:alpha": 0.19956259084433522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12473011016845703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002480368524849267,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07644454805325654,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 6.180489305238364e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07231469894743649,
            "feature_preprocessor:select_rates_classification:alpha": 0.3250551761333992,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09781789779663086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00015471266977240225,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001811588215585169,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.008809226907689106,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018399285505667596,
            "feature_preprocessor:select_rates_classification:alpha": 0.4020256248964354,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1253669261932373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.926695809607388e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041687758444550134,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 3.959897884052404e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001593479269298607,
            "feature_preprocessor:select_rates_classification:alpha": 0.35108932407559534,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2386005230960206,
        "time": 3.227969169616699,
        "additional_info": {
            "duration": 3.216527223587036,
            "num_run": 761,
            "train_loss": 1.184797133121578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.047550829767714e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003609483252735352,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.00021936979549492334,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010509424354345145,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8324800754709522,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.255729585395946,
        "time": 5.138927936553955,
        "additional_info": {
            "duration": 5.126913070678711,
            "num_run": 762,
            "train_loss": 1.0633323798167553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008096620766555338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012839742428276098,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.00016837539580890644,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09559968606093831,
            "feature_preprocessor:select_rates_classification:alpha": 0.4796130338650644,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12405824661254883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02216980039793823,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010983108159667976,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.008819120551411742,
            "feature_preprocessor:select_rates_classification:alpha": 0.39480562682883724,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09743094444274902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.176178361271632e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01036411124279757,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0004840256671459895,
            "feature_preprocessor:select_rates_classification:alpha": 0.4886464306809243,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09683513641357422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5129861482864471e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03784814869063132,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 3.8440427283392144e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01713394586237693,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1485,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8264401605391658,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2513146135793982,
        "time": 0.8033590316772461,
        "additional_info": {
            "duration": 0.727808952331543,
            "num_run": 766,
            "train_loss": 1.1545365925320554,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000525076715347281,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0046955039322553365,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.00029581371114963367,
            "feature_preprocessor:select_percentile_classification:percentile": 94.8915666762495,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.7129826545715332,
        "additional_info": {
            "duration": 0.6922521591186523,
            "num_run": 767,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2454154728397886e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002059836356620522,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.0036650652435041373,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0073852813259276465,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.26684134044078167,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.235733032419264,
        "time": 0.5591540336608887,
        "additional_info": {
            "duration": 0.4953601360321045,
            "num_run": 768,
            "train_loss": 1.1925374951922703,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03774368925275542,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007172942431441187,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.0036005684324200184,
            "feature_preprocessor:select_rates_classification:alpha": 0.4143892932532134,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12872600555419922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.018201356221688406,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012637368813464077,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.000986350569319987,
            "feature_preprocessor:select_rates_classification:alpha": 0.32505063264552575,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.30579495429992676,
        "additional_info": {
            "duration": 0.29396820068359375,
            "num_run": 770,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012273599198340574,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005627080077421281,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 0.0019453315962247386,
            "feature_preprocessor:select_rates_classification:alpha": 0.12253508937426347,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09628796577453613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00014318841944508138,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003714301762217157,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.00019258467912548654,
            "feature_preprocessor:select_rates_classification:alpha": 0.45973470955634055,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1257002353668213,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005503194781074498,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016512899044245797,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.0004237625880029322,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01518028227772893,
            "feature_preprocessor:select_rates_classification:alpha": 0.4906704981743652,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10174393653869629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.842991150438983e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.036473126075400465,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0012713537255682065,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3114634657312379,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7408338359445057,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15913519188614042,
            "feature_preprocessor:select_percentile_classification:percentile": 48.140336192898395,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2525477642894662,
        "time": 0.6600520610809326,
        "additional_info": {
            "duration": 0.6500551700592041,
            "num_run": 774,
            "train_loss": 1.1804568423446216,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.922647749525329e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006015442916069237,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 0.0030299829154849215,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001844897158072513,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.971942754418351,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.250503975437692,
        "time": 0.427152156829834,
        "additional_info": {
            "duration": 0.41039586067199707,
            "num_run": 775,
            "train_loss": 1.2253230608942365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002845937813867605,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026101842308229536,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.00046805218822656384,
            "feature_preprocessor:select_rates_classification:alpha": 0.49216416901574656,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1246790885925293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.346068747000093e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6300742855560836,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 6.162254706726367e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00036019532818567623,
            "feature_preprocessor:select_rates_classification:alpha": 0.4039990398918973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12525629997253418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0992168784018583e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013323481830231757,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.004461463339025055,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038612992179088416,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9745185097923255,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21023836989480216,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.37151014762398704,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.291133871619702,
        "time": 0.6022181510925293,
        "additional_info": {
            "duration": 0.590782880783081,
            "num_run": 778,
            "train_loss": 1.1996787723910716,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014623699601748535,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002213336664363009,
            "classifier:CustomMLPClassifier:max_iter": 123,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.008564077627567616,
            "feature_preprocessor:select_rates_classification:alpha": 0.06921215785869324,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12422990798950195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000659668734704203,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003948462417734654,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.00023068973391722136,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00045801729653431974,
            "feature_preprocessor:select_percentile_classification:percentile": 27.038836623196445,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2473494769754043,
        "time": 1.0469651222229004,
        "additional_info": {
            "duration": 1.0332419872283936,
            "num_run": 780,
            "train_loss": 1.1840657247017223,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00018656273164665226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24846499565068114,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 0.003677371133447341,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012458500935288522,
            "feature_preprocessor:select_rates_classification:alpha": 0.38758234097065675,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1018991470336914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.960565147806982e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006307602830109341,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 1.4411262974808372e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003771989825952008,
            "feature_preprocessor:select_rates_classification:alpha": 0.33659065516965914,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12360382080078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009680208475451871,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000547362668732289,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.00010391654298833794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000992138407958934,
            "feature_preprocessor:select_rates_classification:alpha": 0.26515870237470934,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.266920804977417,
        "additional_info": {
            "duration": 0.23783183097839355,
            "num_run": 783,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07699161481673816,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17994861287295597,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 310,
            "classifier:CustomMLPClassifier:tol": 0.0004380336184206758,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8629373441716751,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2383723179089014,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.26514550872187137,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2228329650986585,
        "time": 1.7433829307556152,
        "additional_info": {
            "duration": 1.7284941673278809,
            "num_run": 784,
            "train_loss": 1.2018212044938943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010245627482134215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00039190711982865474,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 4.0767346573285286e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.37877754707441413,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10229706764221191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0060309031577264844,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15078734895701656,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 0.0030387141303860484,
            "feature_preprocessor:select_rates_classification:alpha": 0.49187817353197755,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0969846248626709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.0843275654013215e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.272791676374138,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 0.0006589407138984677,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013563528023785478,
            "feature_preprocessor:select_rates_classification:alpha": 0.22746603572779836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09673118591308594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0032199346082546374,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008745765613388532,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 0.0008370165224236269,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.80165577512775,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2501840098761442,
            "feature_preprocessor:select_percentile_classification:percentile": 84.20980204755253,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2188273987474412,
        "time": 2.04709792137146,
        "additional_info": {
            "duration": 2.0255846977233887,
            "num_run": 788,
            "train_loss": 1.1238387983646445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010610339543685756,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04067213648516422,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 1.449071946672115e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018084009821210966,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 285,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7115846180942247,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2358745365345456,
        "time": 0.9668500423431396,
        "additional_info": {
            "duration": 0.9548869132995605,
            "num_run": 789,
            "train_loss": 1.1970727313727285,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 789,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08888632106451042,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5049965166631535,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.00015357128913352783,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010011310082775547,
            "feature_preprocessor:select_rates_classification:alpha": 0.15143059843914214,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10126590728759766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 790,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00018361582395417869,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021094059550736958,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.00026121040124218027,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7284355098564583,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22384911749594114,
            "feature_preprocessor:select_rates_classification:alpha": 0.3933601396231156,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2368377426973265,
        "time": 2.117563247680664,
        "additional_info": {
            "duration": 2.0979812145233154,
            "num_run": 791,
            "train_loss": 1.2029822927144074,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 791,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010224229863138368,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024624676427749024,
            "classifier:CustomMLPClassifier:max_iter": 277,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 1.4145929901577861e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.13367824171193665,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10151505470275879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 792,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006394011529626627,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022097627694765535,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.0002064025122435402,
            "feature_preprocessor:select_rates_classification:alpha": 0.16216378615170812,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.216142820112054,
        "time": 1.741431713104248,
        "additional_info": {
            "duration": 1.7291760444641113,
            "num_run": 793,
            "train_loss": 1.1497827940490972,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 793,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.6907862148826315e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3708821344684858,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 308,
            "classifier:CustomMLPClassifier:tol": 5.687028183207423e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06679066304517702,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1783,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.31302199202845343,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.3085407473175845,
        "time": 0.5062720775604248,
        "additional_info": {
            "duration": 0.48720717430114746,
            "num_run": 794,
            "train_loss": 1.1555995178055118,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 794,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010644606334193063,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011984844653027444,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.005896352277141358,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0029134121881424506,
            "feature_preprocessor:select_rates_classification:alpha": 0.024639440408279402,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12955999374389648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 795,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2661140249301352e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017897423493509754,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 304,
            "classifier:CustomMLPClassifier:tol": 1.1777850772475267e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29153403130120326,
            "feature_preprocessor:select_rates_classification:alpha": 0.09112243395615649,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1253671646118164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 796,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00045802859195759863,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7683891419748804,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 4.198569422074409e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3614751732770948,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0961751937866211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 797,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002419285095740976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25465232897530926,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 7.57371236901328e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 15,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.26547670425050524,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.249811605161553,
        "time": 0.811614990234375,
        "additional_info": {
            "duration": 0.7967543601989746,
            "num_run": 798,
            "train_loss": 1.2183093473668551,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 798,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.3026106890528752e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002067406946485371,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 1.6040072447738837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4031329023679336,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7555228727046347,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13009757755338705,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.537935862632451,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2476497221232314,
        "time": 7.553693771362305,
        "additional_info": {
            "duration": 7.5348711013793945,
            "num_run": 799,
            "train_loss": 1.1862319561872687,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 799,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004354554823738853,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004043377009433636,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 2.948857780689911e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002014678464287312,
            "feature_preprocessor:select_rates_classification:alpha": 0.4475912104264108,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2326461995088815,
        "time": 0.7622809410095215,
        "additional_info": {
            "duration": 0.7519528865814209,
            "num_run": 800,
            "train_loss": 1.1671673245358045,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 800,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.685799146274566e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022664750199153767,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 5.8674582003749774e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06056693255027753,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0964210033416748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 801,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0036082803150728226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17431758530304478,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 1.7486535920250707e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10464009382778863,
            "feature_preprocessor:select_rates_classification:alpha": 0.16909868156527036,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12277507781982422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 802,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00023091885140092235,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8743099543044396,
            "classifier:CustomMLPClassifier:max_iter": 297,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 1.523595692961214e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.15087663160488746,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12911224365234375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 803,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.531906830804311e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6025001230738655,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.008187685679753079,
            "feature_preprocessor:select_rates_classification:alpha": 0.09561504305480444,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0972599983215332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 804,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05307301253462305,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009344921638046186,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0010124839065200316,
            "feature_preprocessor:select_rates_classification:alpha": 0.07472437382623213,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12396597862243652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 805,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002975571296140756,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000824576066424183,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 254,
            "classifier:CustomMLPClassifier:tol": 0.00036468698543049634,
            "feature_preprocessor:select_rates_classification:alpha": 0.14619338614479388,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12912917137145996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 806,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0038668545459743576,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019639689830349928,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.00011942361600537254,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42978068225919847,
            "feature_preprocessor:select_rates_classification:alpha": 0.17249334274387576,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12438392639160156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 807,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005798433067287446,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002736750516349876,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.0077611339472731565,
            "feature_preprocessor:select_percentile_classification:percentile": 78.14157876884524,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.36182498931884766,
        "additional_info": {
            "duration": 0.3480551242828369,
            "num_run": 808,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 808,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0023159987594723024,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006211250289779251,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 0.00035302872944709243,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06714730985576028,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1651,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8967865348248275,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2550422796931486,
        "time": 5.491015911102295,
        "additional_info": {
            "duration": 5.477643966674805,
            "num_run": 809,
            "train_loss": 1.1307918134697597,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 809,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005925877512763194,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07669832733209912,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.009333070683588124,
            "feature_preprocessor:select_rates_classification:alpha": 0.2861276694494759,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10341787338256836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 810,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04283521147002729,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10361564109907218,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.0001386615695232227,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019004943289560006,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7053848594566378,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15424265550510033,
            "feature_preprocessor:select_percentile_classification:percentile": 36.01393659143951,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2543094362500313,
        "time": 0.42317914962768555,
        "additional_info": {
            "duration": 0.40929102897644043,
            "num_run": 811,
            "train_loss": 1.120579243392189,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 811,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00034660266643349086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03234947703693437,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.0038068310736061634,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24689569684419552,
            "feature_preprocessor:select_percentile_classification:percentile": 8.343657079627377,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2568332306556342,
        "time": 0.41135692596435547,
        "additional_info": {
            "duration": 0.3979959487915039,
            "num_run": 812,
            "train_loss": 1.2307934761930055,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 812,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010203797476143724,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016044706720010708,
            "classifier:CustomMLPClassifier:max_iter": 359,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.0025027099581709355,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18275243357699233,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.19527609281096,
        "time": 0.34125375747680664,
        "additional_info": {
            "duration": 0.3251359462738037,
            "num_run": 813,
            "train_loss": 1.2122047916193548,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 813,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00028195914841908396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006223172450126003,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.000354533591069196,
            "feature_preprocessor:select_rates_classification:alpha": 0.1313426940595989,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2488635058792874,
        "time": 1.2007510662078857,
        "additional_info": {
            "duration": 1.1883351802825928,
            "num_run": 814,
            "train_loss": 1.161168608025748,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 814,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.959102976495464e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0806853410254563,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 0.003287851793140121,
            "feature_preprocessor:select_rates_classification:alpha": 0.14299803933279717,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.20575690269470215,
        "additional_info": {
            "duration": 0.19428300857543945,
            "num_run": 815,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 815,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05421835287147906,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002039722539153388,
            "classifier:CustomMLPClassifier:max_iter": 321,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 4.497870373115622e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4425676968968013,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1288130283355713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 816,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3820163157033572e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9540572852890672,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.0011770325183713308,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003701065384810684,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 140,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 32.38518719710619,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.3057369660575209,
        "time": 0.9090878963470459,
        "additional_info": {
            "duration": 0.8979499340057373,
            "num_run": 817,
            "train_loss": 1.1689250396779391,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 817,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03276405228635316,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010007604374808893,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 3.210337515627083e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03818708479921534,
            "feature_preprocessor:select_rates_classification:alpha": 0.35128314903291075,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1246793270111084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 818,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0883003765605468e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038185264416022097,
            "classifier:CustomMLPClassifier:max_iter": 268,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 6.396717665656076e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.044743970691026924,
            "feature_preprocessor:select_percentile_classification:percentile": 75.8870645433616,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.253949698339253,
        "time": 5.33201003074646,
        "additional_info": {
            "duration": 5.314717769622803,
            "num_run": 819,
            "train_loss": 1.0038517560167346,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 819,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07143405624658115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4178525113724995,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.0010614207596234798,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.624589117222407,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2469037281573279,
        "time": 0.9915306568145752,
        "additional_info": {
            "duration": 0.9781599044799805,
            "num_run": 820,
            "train_loss": 1.1948319048368037,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 820,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.032233564670815805,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5361714619692217,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 1.3324681503829352e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 732,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4723382933574287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2408949329608245,
        "time": 1.3476839065551758,
        "additional_info": {
            "duration": 1.337266206741333,
            "num_run": 821,
            "train_loss": 1.1759572272262517,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 821,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.069224504080666e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001475203354015756,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 212,
            "classifier:CustomMLPClassifier:tol": 0.0020007594872779723,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08049155504600174,
            "feature_preprocessor:select_rates_classification:alpha": 0.39906921499994485,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12884187698364258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 822,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0309033635859478e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012929427138122004,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.0039150503683984305,
            "feature_preprocessor:select_rates_classification:alpha": 0.30238175843399934,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.47101402282714844,
        "additional_info": {
            "duration": 0.4558258056640625,
            "num_run": 823,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 823,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.499576869815618e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011600324432169108,
            "classifier:CustomMLPClassifier:max_iter": 124,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 0.0023392410611702947,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0826212542768473,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 844,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.03785012688539502,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2644784958555748,
        "time": 0.5434162616729736,
        "additional_info": {
            "duration": 0.5310440063476562,
            "num_run": 824,
            "train_loss": 1.08923420461071,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 824,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.18252799296187e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008109392012428023,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 2.097532005785664e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08035389530861628,
            "feature_preprocessor:select_percentile_classification:percentile": 63.27730350678238,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.3233170509338379,
        "additional_info": {
            "duration": 0.31237006187438965,
            "num_run": 825,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 825,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006163014105132271,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016436089681250295,
            "classifier:CustomMLPClassifier:max_iter": 260,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.0014614026781653298,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14409453147595264,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.4717898368835449,
        "additional_info": {
            "duration": 0.4593470096588135,
            "num_run": 826,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 826,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.595229892133921e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012790851425892668,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.0014366024491397848,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001071638004354449,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1789,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4106982558880364,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2575953531006723,
        "time": 1.1904451847076416,
        "additional_info": {
            "duration": 1.1678109169006348,
            "num_run": 827,
            "train_loss": 1.2144150864604204,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 827,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00027556524206592424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006848685479532871,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.004734771831374162,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00134634611141817,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1312,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 70.26277023952086,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2408948895410696,
        "time": 0.31493687629699707,
        "additional_info": {
            "duration": 0.30279994010925293,
            "num_run": 828,
            "train_loss": 1.174596104235007,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 828,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005344355030983639,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0855518874813795,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 9.433027770459649e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.040025184144014764,
            "feature_preprocessor:select_rates_classification:alpha": 0.27339580183966716,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2570041006123467,
        "time": 1.0104267597198486,
        "additional_info": {
            "duration": 0.9970040321350098,
            "num_run": 829,
            "train_loss": 1.0482666728448726,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 829,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.05443169064759e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021244911644486506,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 1.1939139145886925e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.121577062505278,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2298838695946606,
        "time": 5.782132148742676,
        "additional_info": {
            "duration": 5.770404100418091,
            "num_run": 830,
            "train_loss": 1.1963821358953475,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 830,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025901155812509482,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009223337917681749,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 335,
            "classifier:CustomMLPClassifier:tol": 0.0010269905071443486,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007365464563721583,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 266,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 70.9969156648508,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2364021664456881,
        "time": 3.2217538356781006,
        "additional_info": {
            "duration": 3.2083420753479004,
            "num_run": 831,
            "train_loss": 1.0292035016545886,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 831,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0040592567682635645,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010648785978038592,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 0.00014070823057176057,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00099269208308277,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8670306696138543,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09541402344163717,
            "feature_preprocessor:select_percentile_classification:percentile": 73.74031675856283,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2513915169386325,
        "time": 6.586916923522949,
        "additional_info": {
            "duration": 6.574822187423706,
            "num_run": 832,
            "train_loss": 1.0535107470375975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 832,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.22035690760143e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001040047640716183,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 8.074412549834477e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 91,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 98.63997663918802,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2376676175337797,
        "time": 5.54523491859436,
        "additional_info": {
            "duration": 5.5308520793914795,
            "num_run": 833,
            "train_loss": 1.1686149667699492,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 833,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0014380440126943242,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5376736466691938,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.0002302744863217547,
            "feature_preprocessor:select_percentile_classification:percentile": 32.81976874250953,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.3155280292364033,
        "time": 0.8857500553131104,
        "additional_info": {
            "duration": 0.8744261264801025,
            "num_run": 834,
            "train_loss": 1.081170286973687,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 834,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011164630798819502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005505571114957283,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.0003287180346949964,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2220109657956026,
            "feature_preprocessor:select_percentile_classification:percentile": 13.556614640552333,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3992960453033447,
        "additional_info": {
            "duration": 0.38646602630615234,
            "num_run": 835,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 835,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09264176800905094,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6405431523654563,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 0.00014300401535070399,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014227842842718754,
            "feature_preprocessor:select_rates_classification:alpha": 0.1764514332167925,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09615325927734375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 836,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0018028926948211788,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005512635309376486,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.00017319096436615354,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036279595196431792,
            "feature_preprocessor:select_rates_classification:alpha": 0.1312906446201113,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1238868236541748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 837,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002362847758671309,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002514441330780334,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.005605527929607922,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006839095169309592,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5436677035539442,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.391948938369751,
        "additional_info": {
            "duration": 0.3753368854522705,
            "num_run": 838,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 838,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.084468031409399e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006963908834144991,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 310,
            "classifier:CustomMLPClassifier:tol": 1.1724400822039237e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00027864612894176413,
            "feature_preprocessor:select_percentile_classification:percentile": 72.66480832867482,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 1.0239300727844238,
        "additional_info": {
            "duration": 1.0115571022033691,
            "num_run": 839,
            "train_loss": 1.2321424435056831,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 839,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002632722268990146,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005239034284620161,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 1.840962527257632e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008930994476810255,
            "feature_preprocessor:select_rates_classification:alpha": 0.2976830265587886,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1289842128753662,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 840,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05131014038820359,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027131896989425917,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.0010443997868180557,
            "feature_preprocessor:select_rates_classification:alpha": 0.03806483392655667,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12868404388427734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 841,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010614167796818119,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012364181997750632,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.0016067227768154374,
            "feature_preprocessor:select_rates_classification:alpha": 0.14445307230866433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09643006324768066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 842,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002968666677558352,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05193460287600694,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0009549565656923586,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.10100709181764655,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2051763163073455,
        "time": 0.5257151126861572,
        "additional_info": {
            "duration": 0.5034322738647461,
            "num_run": 843,
            "train_loss": 1.2009186010509405,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 843,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005492006773309402,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018252316509879175,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 0.0002344441118172115,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28597737726547806,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.48161059076027035,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.235824021060394,
        "time": 0.4796879291534424,
        "additional_info": {
            "duration": 0.4677720069885254,
            "num_run": 844,
            "train_loss": 1.2008514018025844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 844,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.777487172936926e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007007251230182811,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 7.770911153685293e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09068475862524411,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9731825013135353,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29513238218965143,
            "feature_preprocessor:select_percentile_classification:percentile": 91.72647855570449,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2335024188106625,
        "time": 0.4314751625061035,
        "additional_info": {
            "duration": 0.4190709590911865,
            "num_run": 845,
            "train_loss": 1.1859941228925446,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 845,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.527850915401064e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012099196896920825,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.0007855270171166129,
            "feature_preprocessor:select_rates_classification:alpha": 0.16704201398258095,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12490963935852051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 846,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019325257182199128,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009287868979350654,
            "classifier:CustomMLPClassifier:max_iter": 253,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0005473702688397911,
            "feature_preprocessor:select_rates_classification:alpha": 0.014638889780947498,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12421178817749023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 847,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011932623699598469,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012334401796580982,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 0.0013119740709718556,
            "feature_preprocessor:select_rates_classification:alpha": 0.039977499020165126,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12888288497924805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 848,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0686725278972388,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8317132998072461,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 0.001707303177323891,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015543986100484802,
            "feature_preprocessor:select_rates_classification:alpha": 0.38884278334952893,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.129425048828125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 849,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011058695316814732,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005024918012068385,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.0010222081441247555,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013343941214130213,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6289434166188613,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.5047921317957376,
        "time": 0.5183823108673096,
        "additional_info": {
            "duration": 0.501396894454956,
            "num_run": 850,
            "train_loss": 1.4707693508406903,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 850,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005403849721550409,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022690836241212137,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 1.2324940383993908e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 3.987714444397615,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.8579490184783936,
        "additional_info": {
            "duration": 0.8440439701080322,
            "num_run": 851,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 851,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001212510709813295,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09669162434579309,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 1.5199042392324376e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034216415585259875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1964,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8737023852175531,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231022032108631,
        "time": 1.2720611095428467,
        "additional_info": {
            "duration": 1.248779058456421,
            "num_run": 852,
            "train_loss": 1.096558040048401,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 852,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005846581822543111,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8563027463609257,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 0.00015718701483261263,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003701134226413061,
            "feature_preprocessor:select_rates_classification:alpha": 0.3270033195180916,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1251688003540039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 853,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0038901832922341815,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004282708363430825,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 305,
            "classifier:CustomMLPClassifier:tol": 1.3743399574421052e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.463771226229861,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2466986014648629,
        "time": 3.1590678691864014,
        "additional_info": {
            "duration": 3.1484789848327637,
            "num_run": 854,
            "train_loss": 1.179894607509954,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 854,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.3866569222535117e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007396905384930467,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.0006477182403175548,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01002214266054529,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8130996564577301,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3477349281311035,
        "additional_info": {
            "duration": 0.3339059352874756,
            "num_run": 855,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 855,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.5907644447698605e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021673781026455615,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 0.0006496502972471528,
            "feature_preprocessor:select_percentile_classification:percentile": 58.626973356451785,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.31183481216430664,
        "additional_info": {
            "duration": 0.2980520725250244,
            "num_run": 856,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 856,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011861500419913774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004764186544879896,
            "classifier:CustomMLPClassifier:max_iter": 195,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 0.00020755238503457628,
            "feature_preprocessor:select_rates_classification:alpha": 0.40711286221215176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10186505317687988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 857,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00019197839648219737,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002264692396868993,
            "classifier:CustomMLPClassifier:max_iter": 241,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 3.905431503181436e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022716500051034026,
            "feature_preprocessor:select_rates_classification:alpha": 0.4475933731409842,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2129913864456243,
        "time": 5.645143985748291,
        "additional_info": {
            "duration": 5.6333839893341064,
            "num_run": 858,
            "train_loss": 1.2172413817284888,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 858,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.835631340956724e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.033358261463356347,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 6.595640180838518e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06048157840169242,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1298542022705078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 859,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.033016088462181764,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12328865689613533,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.0003556778345715518,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06145709502398141,
            "feature_preprocessor:select_rates_classification:alpha": 0.3173331570773674,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09736299514770508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 860,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011671012107636842,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002926368578232597,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.002692385940225492,
            "feature_preprocessor:select_rates_classification:alpha": 0.44664837699583343,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12940716743469238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 861,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09116658022754166,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11341167610782728,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 2.590691796186775e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7487381966809541,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13969443561693742,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.10150616829585601,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2222730348094921,
        "time": 0.8643100261688232,
        "additional_info": {
            "duration": 0.8509950637817383,
            "num_run": 862,
            "train_loss": 1.171300313712896,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 862,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03885912039023254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013195760258413896,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 337,
            "classifier:CustomMLPClassifier:tol": 2.8358781639720727e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021975798647419465,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 721,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3201783493816064,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2376949401779718,
        "time": 8.660362005233765,
        "additional_info": {
            "duration": 8.64512300491333,
            "num_run": 863,
            "train_loss": 1.0714203283225476,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 863,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.548545080196591e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00035405968819453683,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 4.084052081356312e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.24503491502931374,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12465572357177734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 864,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012208669078062087,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01282271341297791,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 0.00045029408983751894,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000867785647788983,
            "feature_preprocessor:select_percentile_classification:percentile": 30.261742840225963,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.253840494601995,
        "time": 0.3193850517272949,
        "additional_info": {
            "duration": 0.30592799186706543,
            "num_run": 865,
            "train_loss": 1.1981348106725722,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 865,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.021947239432861733,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009932984863946712,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.00484999431266392,
            "feature_preprocessor:select_percentile_classification:percentile": 63.09520989281001,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.25360989570617676,
        "additional_info": {
            "duration": 0.24128413200378418,
            "num_run": 866,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 866,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004828504831970877,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07206236610630332,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.0003500910958139626,
            "feature_preprocessor:select_rates_classification:alpha": 0.063565844860757,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13261890411376953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 867,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.027500195362581324,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002669032227947078,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 0.0016696466229308073,
            "feature_preprocessor:select_rates_classification:alpha": 0.4030856129711657,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2550877305939587,
        "time": 0.6328129768371582,
        "additional_info": {
            "duration": 0.6124143600463867,
            "num_run": 868,
            "train_loss": 1.1788144861930205,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 868,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009441862776516126,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025319970274489336,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.0010124942529362811,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000463409578591728,
            "feature_preprocessor:select_rates_classification:alpha": 0.2738180074803115,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.27704501152038574,
        "additional_info": {
            "duration": 0.26568007469177246,
            "num_run": 869,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 869,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.024252383387304677,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.037936546922709626,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 0.001531065578519242,
            "feature_preprocessor:select_rates_classification:alpha": 0.4591664485092595,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09767007827758789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 870,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.887000143970688e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14584349615352368,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.003550802237892155,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00038071217113881185,
            "feature_preprocessor:select_rates_classification:alpha": 0.07689138417870986,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.47368311882019043,
        "additional_info": {
            "duration": 0.4577929973602295,
            "num_run": 871,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 871,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3665336986243034e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020974854784485054,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.0025809472156582136,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003427702578768544,
            "feature_preprocessor:select_rates_classification:alpha": 0.14710973078458853,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.252420388875835,
        "time": 0.2729780673980713,
        "additional_info": {
            "duration": 0.2576918601989746,
            "num_run": 872,
            "train_loss": 1.1854556874406004,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 872,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9945616650638968e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002022865608748517,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 6.894940735953809e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01817821396494632,
            "feature_preprocessor:select_rates_classification:alpha": 0.39915188379996464,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10297703742980957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 873,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009645866406727386,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010488777770637754,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 397,
            "classifier:CustomMLPClassifier:tol": 3.0057550327288247e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 47.365497589179505,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2481641580918328,
        "time": 0.4485487937927246,
        "additional_info": {
            "duration": 0.4368410110473633,
            "num_run": 874,
            "train_loss": 1.1853093647513666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 874,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1925148721148713e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007039866214682747,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 0.0019631213733415317,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015514595102791888,
            "feature_preprocessor:select_rates_classification:alpha": 0.19572118318166154,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2953779697418213,
        "additional_info": {
            "duration": 0.28008484840393066,
            "num_run": 875,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 875,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.595344120861079e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.054843794512944403,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 0.006808263787026427,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00031245749792621565,
            "feature_preprocessor:select_rates_classification:alpha": 0.44648530043343604,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1023092269897461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 876,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.626281294713607e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04659997237749978,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 1.8167485709782602e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07157332979098491,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14897783993953728,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229219800141578,
        "time": 0.8124089241027832,
        "additional_info": {
            "duration": 0.800321102142334,
            "num_run": 877,
            "train_loss": 1.0289344241727991,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 877,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01348851042869114,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001957146800339027,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 98,
            "classifier:CustomMLPClassifier:tol": 0.000345404921080046,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42436312969199913,
            "feature_preprocessor:select_rates_classification:alpha": 0.0357362252431165,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12930893898010254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 878,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00035307701953013384,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021336706501831775,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 1.0890136918486632e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.026597127563047614,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1245880126953125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 879,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.5342481636923738e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0411893819651075,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.00044259644800755414,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02463536050651763,
            "feature_preprocessor:select_rates_classification:alpha": 0.26619332032268106,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1029508113861084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 880,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6692510892134063e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017339209225892025,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 0.0001592151385713829,
            "feature_preprocessor:select_percentile_classification:percentile": 69.45535038162079,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2501442375269138,
        "time": 1.79030179977417,
        "additional_info": {
            "duration": 1.7666940689086914,
            "num_run": 881,
            "train_loss": 1.175158339069675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 881,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.580368362234063e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016392304100872312,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 0.004230648393590846,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033490997989337405,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8555621902736477,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.00804788780235573,
            "feature_preprocessor:select_rates_classification:alpha": 0.3747526486025553,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2433388026310905,
        "time": 0.6792628765106201,
        "additional_info": {
            "duration": 0.667963981628418,
            "num_run": 882,
            "train_loss": 1.2241641991379473,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 882,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001517657718921944,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05344400228700881,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 0.0008250001644818153,
            "feature_preprocessor:select_rates_classification:alpha": 0.41424594651251345,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2677239829589926,
        "time": 0.4250171184539795,
        "additional_info": {
            "duration": 0.3972969055175781,
            "num_run": 883,
            "train_loss": 1.0159933387726947,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 883,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.020359475571044e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009655701093519733,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.0016543763824463816,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018899416496313533,
            "feature_preprocessor:select_rates_classification:alpha": 0.3658350260823473,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1253659725189209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 884,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02719890193420942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.034863251908787335,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 1.9319587986833013e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018750881898407425,
            "feature_preprocessor:select_rates_classification:alpha": 0.228852623773441,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12948083877563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 885,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.016242873036913092,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022247194433115573,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.005947577878924596,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012153771785327692,
            "feature_preprocessor:select_percentile_classification:percentile": 17.514860021075002,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2404197748815626,
        "time": 0.2503170967102051,
        "additional_info": {
            "duration": 0.23751568794250488,
            "num_run": 886,
            "train_loss": 1.2129751740275003,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 886,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.9440843707923785e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1509094101570299,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 0.0002052474478638996,
            "feature_preprocessor:select_rates_classification:alpha": 0.493872796345973,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.3332178592681885,
        "additional_info": {
            "duration": 0.3197810649871826,
            "num_run": 887,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 887,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4862812653426954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11157871198386089,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 0.0010724645922367952,
            "feature_preprocessor:select_rates_classification:alpha": 0.40291487267405024,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12453007698059082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 888,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.008530425976367e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05812275631321565,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 4.6469242093395656e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1449819397732881,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2267020484881808,
        "time": 0.7166459560394287,
        "additional_info": {
            "duration": 0.7020361423492432,
            "num_run": 889,
            "train_loss": 1.186176681131434,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 889,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.178153236577238e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002818580254724354,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 9.590394072015475e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4322913147278373,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1292250156402588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 890,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005258201713173573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00555857961182212,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 0.00767890982427753,
            "feature_preprocessor:select_rates_classification:alpha": 0.19663133736615457,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0991511344909668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 891,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.589445305293851e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3250642811752393,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 3.91822331324638e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6144707388438303,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2663221357487158,
        "time": 1.0692782402038574,
        "additional_info": {
            "duration": 1.0573837757110596,
            "num_run": 892,
            "train_loss": 1.1540612109394899,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 892,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.058771121386612e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002074945183211011,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 58,
            "classifier:CustomMLPClassifier:tol": 1.295507375452418e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02636879542069009,
            "feature_preprocessor:select_rates_classification:alpha": 0.34743349840220444,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12540626525878906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 893,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.033859971835232e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021495019823368375,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 0.0016769051325238936,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012231850614780542,
            "feature_preprocessor:select_rates_classification:alpha": 0.42107812898536995,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13043498992919922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 894,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002881435023002928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008573426997273748,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.0008955985549732839,
            "feature_preprocessor:select_rates_classification:alpha": 0.14048169750594416,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12463164329528809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 895,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002277499522631747,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03178588540691344,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.0003492073269414849,
            "feature_preprocessor:select_rates_classification:alpha": 0.26009773066771696,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.126129150390625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 896,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00185793009377153,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22943377650209565,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.0033493008465153634,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003225970579526639,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1706,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.020506530568948213,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2608226251079622,
        "time": 0.7684140205383301,
        "additional_info": {
            "duration": 0.7510662078857422,
            "num_run": 897,
            "train_loss": 1.2150198261847884,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 897,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.543925275872217e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5558362771761493,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 1.6034748341587112e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006317106932262867,
            "feature_preprocessor:select_rates_classification:alpha": 0.17613589317757009,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3393349773395014,
        "time": 0.5013229846954346,
        "additional_info": {
            "duration": 0.4890618324279785,
            "num_run": 898,
            "train_loss": 1.2772583705402238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 898,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2613990706478423e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015587468862041773,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.0013532634407683948,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021373473355708873,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 253,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6811120392638008,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2956133573527873,
        "time": 0.6055691242218018,
        "additional_info": {
            "duration": 0.5936028957366943,
            "num_run": 899,
            "train_loss": 1.2476891379202888,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 899,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001001602563856878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017911612408102674,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 0.0001501977212504638,
            "feature_preprocessor:select_percentile_classification:percentile": 47.92231025924239,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.27219510078430176,
        "additional_info": {
            "duration": 0.25878095626831055,
            "num_run": 900,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 900,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.8111163031175706e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0711490236108459,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 2.445730955003382e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026999705109078592,
            "feature_preprocessor:select_percentile_classification:percentile": 37.4122124754354,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2611097631527581,
        "time": 0.43268895149230957,
        "additional_info": {
            "duration": 0.41370320320129395,
            "num_run": 901,
            "train_loss": 1.1850593267757559,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 901,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009780137076139952,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013532222160009376,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 9.619662256659094e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22475019608504476,
            "feature_preprocessor:select_rates_classification:alpha": 0.24393011195131878,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.48525285720825195,
        "additional_info": {
            "duration": 0.4738647937774658,
            "num_run": 902,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 902,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001145331379319526,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017538330989615876,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 3.974362095549214e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014210890033509052,
            "feature_preprocessor:select_rates_classification:alpha": 0.494921546587189,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09699606895446777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 903,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0049128580405149065,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023427645200789016,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 8.132614037308577e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8301142419295031,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 1.4006659984588623,
        "additional_info": {
            "duration": 1.3794341087341309,
            "num_run": 904,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 904,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.394775580097323e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005476448812383723,
            "classifier:CustomMLPClassifier:max_iter": 260,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 0.00016777480423926997,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0828104709302928,
            "feature_preprocessor:select_rates_classification:alpha": 0.1892347271052253,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09679102897644043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 905,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.010773551208857665,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014028587873320016,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 380,
            "classifier:CustomMLPClassifier:tol": 0.0020523565301441772,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9180410147809474,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2592114300345407,
            "feature_preprocessor:select_rates_classification:alpha": 0.10607124341126142,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.27695417404174805,
        "additional_info": {
            "duration": 0.2638828754425049,
            "num_run": 906,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 906,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9704292905373636e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012144107308745843,
            "classifier:CustomMLPClassifier:max_iter": 350,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.00024490206622287773,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023345212572784264,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1394,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 65.709493498364,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2427203143380825,
        "time": 0.43247485160827637,
        "additional_info": {
            "duration": 0.41471004486083984,
            "num_run": 907,
            "train_loss": 1.166386246910272,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 907,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0806891404374058e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020841284017401177,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.0008667191552032986,
            "feature_preprocessor:select_rates_classification:alpha": 0.29861289478174563,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2536352376502653,
        "time": 0.5878620147705078,
        "additional_info": {
            "duration": 0.5759081840515137,
            "num_run": 908,
            "train_loss": 1.2439783302286762,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 908,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.046348313169342e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003941879787906705,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 0.00276015565460399,
            "feature_preprocessor:select_rates_classification:alpha": 0.01180542635253143,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12879395484924316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 909,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.9979642582367675e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046889777319205413,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.0026707830730489414,
            "feature_preprocessor:select_rates_classification:alpha": 0.22418667745809018,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12569975852966309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 910,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.8402549670464196e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14523458027874706,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.00025333592364202234,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.059940098113065964,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1020,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.590789872790651,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2702235195162617,
        "time": 0.8838169574737549,
        "additional_info": {
            "duration": 0.8680100440979004,
            "num_run": 911,
            "train_loss": 1.1836292635866097,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 911,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00203600845775364,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14798748733874467,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 410,
            "classifier:CustomMLPClassifier:tol": 1.2289601341317108e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 498,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.02890314636626904,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5641262531280518,
        "additional_info": {
            "duration": 0.540924072265625,
            "num_run": 912,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 912,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.225299980242319e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019331896221608515,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.003579834022158012,
            "feature_preprocessor:select_percentile_classification:percentile": 76.88695662540529,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.3813507556915283,
        "additional_info": {
            "duration": 0.3629128932952881,
            "num_run": 913,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 913,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.020893763062801197,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4197677383923329,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.0012066036910814751,
            "feature_preprocessor:select_rates_classification:alpha": 0.3375893309895793,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2359514398937799,
        "time": 0.24831795692443848,
        "additional_info": {
            "duration": 0.22745513916015625,
            "num_run": 914,
            "train_loss": 1.0682952208491239,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 914,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010892435319243233,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27265947748164016,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.003688939186797037,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17846883963084878,
            "feature_preprocessor:select_rates_classification:alpha": 0.42604861245994474,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13466787338256836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 915,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0908440885179815e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8223096723791378,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.00012077552844477833,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011226627719031202,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7844030723187786,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3885672152925168,
        "time": 0.3666069507598877,
        "additional_info": {
            "duration": 0.3538539409637451,
            "num_run": 916,
            "train_loss": 1.3602319944773844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 916,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3839092848111037e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9754389409588812,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.00021055416098637205,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2011836003737512,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7080873703472063,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25736539258115354,
            "feature_preprocessor:select_rates_classification:alpha": 0.09350294138267966,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2230734569650052,
        "time": 0.25334978103637695,
        "additional_info": {
            "duration": 0.23454904556274414,
            "num_run": 917,
            "train_loss": 1.2081830160438194,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 917,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.6801075641755424e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005161475932637143,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 4.68881237567056e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.41263666324820425,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1273789405822754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 918,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010346550611778631,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006033616175972374,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.00014441428119983996,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043164362259513485,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9644835872198039,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.028797061485801585,
            "feature_preprocessor:select_rates_classification:alpha": 0.46802208516070454,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 1.4938890933990479,
        "additional_info": {
            "duration": 1.4266130924224854,
            "num_run": 919,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 919,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0718327171033304e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010587965756596221,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.004428063009819819,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7292984688537394,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2563531382622954,
        "time": 0.4583439826965332,
        "additional_info": {
            "duration": 0.3789238929748535,
            "num_run": 920,
            "train_loss": 1.2225823898931358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 920,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.786739479921112e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01127349098037715,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.00377971435182778,
            "feature_preprocessor:select_rates_classification:alpha": 0.43005044700868533,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12516212463378906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 921,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.017851727845480107,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008043942409751342,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.00011919966345845715,
            "feature_preprocessor:select_rates_classification:alpha": 0.454252071344892,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1255500316619873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 922,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.290930262744194e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003152010850597354,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.0001708389648522358,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001964519727131094,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8752964618896976,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2640913918808496,
        "time": 2.8123788833618164,
        "additional_info": {
            "duration": 2.797757148742676,
            "num_run": 923,
            "train_loss": 1.2159652685166444,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 923,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04218352534874778,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8335181382235719,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 0.00041215771539014607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001917528127023204,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1023,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3913656520659865,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3168257807025188,
        "time": 0.599395751953125,
        "additional_info": {
            "duration": 0.5856540203094482,
            "num_run": 924,
            "train_loss": 1.276403592840245,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 924,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.2390347242907076e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07419507260307744,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 337,
            "classifier:CustomMLPClassifier:tol": 0.000325606520395144,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7348789076590825,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.019499650318820554,
            "feature_preprocessor:select_rates_classification:alpha": 0.05711702405436169,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2507223394924534,
        "time": 0.5947980880737305,
        "additional_info": {
            "duration": 0.57291579246521,
            "num_run": 925,
            "train_loss": 1.1895589418941257,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 925,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.026500439580121424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005152448302291369,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 6.588599717825061e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004370630629726152,
            "feature_preprocessor:select_rates_classification:alpha": 0.15437167559525142,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1241312026977539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 926,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012517185932564833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6244174648165349,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 1.980628955618963e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.05403263073594845,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09742999076843262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 927,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.010511170582094451,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028526461899375955,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.00604144879508312,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1819,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.11477088059422556,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.7142379283905029,
        "additional_info": {
            "duration": 0.6918239593505859,
            "num_run": 928,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 928,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0688126882207743e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0061692230737981565,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 1.6844756766265924e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011362604018173585,
            "feature_preprocessor:select_rates_classification:alpha": 0.07036628435162343,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09765291213989258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 929,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011531837750616792,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015888818828960045,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 0.003910098744990676,
            "feature_preprocessor:select_percentile_classification:percentile": 5.649706851572468,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.26337695121765137,
        "additional_info": {
            "duration": 0.24533891677856445,
            "num_run": 930,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 930,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.9416446116555876e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011281070366284113,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 0.004288535370233992,
            "feature_preprocessor:select_percentile_classification:percentile": 85.22948950252946,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2343715281167005,
        "time": 0.6331520080566406,
        "additional_info": {
            "duration": 0.6205708980560303,
            "num_run": 931,
            "train_loss": 1.2304881631615603,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 931,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.851605344770479e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08752829506778216,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 0.003288438521137879,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1199913597654192,
            "feature_preprocessor:select_percentile_classification:percentile": 31.313177381292448,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3096609115600586,
        "additional_info": {
            "duration": 0.2936220169067383,
            "num_run": 932,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 932,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09253033519636622,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04936755441232782,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.0037185403588337125,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024070588216295426,
            "feature_preprocessor:select_percentile_classification:percentile": 89.93582644571356,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2441859143848075,
        "time": 0.7000210285186768,
        "additional_info": {
            "duration": 0.6891720294952393,
            "num_run": 933,
            "train_loss": 1.167735445708995,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 933,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0034305276835605485,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042524705728066325,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.0008954377758150963,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4013815424365251,
            "feature_preprocessor:select_percentile_classification:percentile": 23.933521235257146,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.278611757306003,
        "time": 0.662437915802002,
        "additional_info": {
            "duration": 0.6514589786529541,
            "num_run": 934,
            "train_loss": 1.225659337624382,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 934,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3723207362442991e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006965818519844904,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.001924749361139491,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02783335280049994,
            "feature_preprocessor:select_rates_classification:alpha": 0.2539075537340684,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12346124649047852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 935,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000309322326656599,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002301337534069979,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.0002996924375264134,
            "feature_preprocessor:select_rates_classification:alpha": 0.16959599660637234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12532496452331543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 936,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.7982572848298663e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9327920735298808,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.005584085566028928,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00046018190388528887,
            "feature_preprocessor:select_rates_classification:alpha": 0.3550831665109693,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.23155784606933594,
        "additional_info": {
            "duration": 0.22049498558044434,
            "num_run": 937,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 937,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.969730529307062e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015488800561732123,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.0031139703627401753,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24401997689052082,
            "feature_preprocessor:select_rates_classification:alpha": 0.3270021729520986,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09628582000732422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 938,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002607290512502088,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007509832004964205,
            "classifier:CustomMLPClassifier:max_iter": 203,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 0.0026215441776571927,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001013656855165933,
            "feature_preprocessor:select_rates_classification:alpha": 0.1522005584370855,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1239471435546875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 939,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.034347161550621e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2393431705131391,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 1.09531380496837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011784060147874765,
            "feature_preprocessor:select_rates_classification:alpha": 0.18866561256244757,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.4587900638580322,
        "additional_info": {
            "duration": 0.4405379295349121,
            "num_run": 940,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 940,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00490832656839336,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013260163185946352,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.00028680916353985794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03209057289137305,
            "feature_preprocessor:select_rates_classification:alpha": 0.30771206894796654,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12299799919128418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 941,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002323281695087767,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0074042232688833025,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0002459093490700809,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011866634818078057,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.023083444514501728,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.6004209518432617,
        "additional_info": {
            "duration": 0.5870962142944336,
            "num_run": 942,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 942,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002912686373384734,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001020385692334454,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.00013253684666457462,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04498404560336166,
            "feature_preprocessor:select_rates_classification:alpha": 0.28197721077678267,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09711170196533203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 943,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.5083860567924784e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47574720314103924,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 1.8531781688033e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22893877640700275,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09613966941833496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 944,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.127083503780589e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004586147039479214,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 5.36909454209617e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11962507912791182,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09704875946044922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 945,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.530490512089195e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001791467253497075,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.0005719163456605998,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.048860766201924255,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3501701354980469,
        "additional_info": {
            "duration": 0.3330717086791992,
            "num_run": 946,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 946,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012998751575786208,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021871333295772226,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 1.4235078444915462e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04461310284380489,
            "feature_preprocessor:select_rates_classification:alpha": 0.16499675616401094,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09604787826538086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 947,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.9195981624066206e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02023219525270045,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 0.00022091726560922702,
            "feature_preprocessor:select_rates_classification:alpha": 0.4158487519508796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09630727767944336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 948,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08492347325440804,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05152015587638004,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 1.6856710386979516e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.05729524411019285,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12298893928527832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 949,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6748194563635322e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003854608961187335,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.00020112479447194364,
            "feature_preprocessor:select_rates_classification:alpha": 0.09794414960323856,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12384605407714844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 950,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.016562517551729546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026312187098138946,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 9.310185313032343e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001018571619148674,
            "feature_preprocessor:select_rates_classification:alpha": 0.10131799001382664,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2916691303253174,
        "additional_info": {
            "duration": 0.2658560276031494,
            "num_run": 951,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 951,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003017431216309242,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008971715358251121,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.000502122264104564,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.329889878047378,
            "feature_preprocessor:select_rates_classification:alpha": 0.17883366027819148,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12876415252685547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 952,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.347385917977571e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5255492581398822,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 1.607158309474132e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.42298583123839983,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1233530044555664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 953,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.679576487874103e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014105413714232484,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.008406919771837726,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009481212874726726,
            "feature_preprocessor:select_percentile_classification:percentile": 28.436480507744264,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.3242828845977783,
        "additional_info": {
            "duration": 0.3129770755767822,
            "num_run": 954,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 954,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.5522102609254374e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0904576923415895,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 0.0034370273777684698,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9925598707331955,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2541548250317178,
        "time": 1.1577301025390625,
        "additional_info": {
            "duration": 1.1375670433044434,
            "num_run": 955,
            "train_loss": 1.194362409582761,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 955,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.992911915731199e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18590232542148988,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.0005784262570745948,
            "feature_preprocessor:select_rates_classification:alpha": 0.11870437961635105,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12334918975830078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 956,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.196558215271872e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07399324701324014,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 0.00037643697327415334,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013896901725663598,
            "feature_preprocessor:select_rates_classification:alpha": 0.44619178381351926,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09640383720397949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 957,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0018996514384680588,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004988752853416963,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.003242402411684846,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2102617022086836,
            "feature_preprocessor:select_percentile_classification:percentile": 82.20824372104904,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.26735997200012207,
        "additional_info": {
            "duration": 0.25634098052978516,
            "num_run": 958,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 958,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0062789531402014254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1381559329671133,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.0012917773924899381,
            "feature_preprocessor:select_rates_classification:alpha": 0.06384283457042643,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10157370567321777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 959,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.186867327423031e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008550407159867018,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 1.0672100558859783e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12184301025116236,
            "feature_preprocessor:select_rates_classification:alpha": 0.08800542010627026,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09734201431274414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 960,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09098230680732082,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005620043342668244,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 1.3512038428047508e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07186097491202736,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1176562635668208,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.663093090057373,
        "additional_info": {
            "duration": 0.6400740146636963,
            "num_run": 961,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 961,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001898135401693314,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01937437964796973,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 0.007083297334191465,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002559794524543117,
            "feature_preprocessor:select_rates_classification:alpha": 0.23780650122458302,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12893176078796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 962,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000916950942099379,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03408661023825767,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 1.3248551508805203e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004024438280861003,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.34541304900458747,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2686114376204232,
        "time": 7.560763835906982,
        "additional_info": {
            "duration": 7.490097284317017,
            "num_run": 963,
            "train_loss": 1.0852655801399425,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 963,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.474869203237674e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13125316079218985,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.002134348234799659,
            "feature_preprocessor:select_rates_classification:alpha": 0.034405311018670594,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09723877906799316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 964,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.833774849349076e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0107873340555635,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.0007974103657909069,
            "feature_preprocessor:select_rates_classification:alpha": 0.4259157754355768,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10168981552124023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 965,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00017437082394263024,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5271145221359625,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 0.0005223579895706979,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012368823735468062,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7003535681879177,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2182025769734003,
            "feature_preprocessor:select_rates_classification:alpha": 0.4750009677411708,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.4685429072747678,
        "time": 0.4886291027069092,
        "additional_info": {
            "duration": 0.47341394424438477,
            "num_run": 966,
            "train_loss": 1.490061450060176,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 966,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.8148844661478475e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014499410129375184,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 0.005640612992669737,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037569108172937227,
            "feature_preprocessor:select_rates_classification:alpha": 0.3766418729784872,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2303528546624518,
        "time": 0.2194061279296875,
        "additional_info": {
            "duration": 0.20836091041564941,
            "num_run": 967,
            "train_loss": 1.1602811256775238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 967,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.369561410784615e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004146056750201495,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.00011933182009712732,
            "feature_preprocessor:select_rates_classification:alpha": 0.43582098477910325,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.25917792320251465,
        "additional_info": {
            "duration": 0.2432858943939209,
            "num_run": 968,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 968,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.506860047930602e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024430787003926483,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 1.0934968625015128e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10485372233662517,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7177145030475923,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16423547202564823,
            "feature_preprocessor:select_rates_classification:alpha": 0.07985494130805816,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2164774088351438,
        "time": 0.8488519191741943,
        "additional_info": {
            "duration": 0.8380708694458008,
            "num_run": 969,
            "train_loss": 1.1932263987224256,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 969,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03285527643076381,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004984336595779718,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 0.00034327881114085677,
            "feature_preprocessor:select_rates_classification:alpha": 0.34380366640012266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10196518898010254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 970,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011887704155591245,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07521647060052618,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 0.00011922544645946953,
            "feature_preprocessor:select_rates_classification:alpha": 0.1967661370344027,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10318779945373535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 971,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00033998780463560905,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01201498560078229,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 1.9425059405701076e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9348363121577413,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2547916586801184,
        "time": 0.45413684844970703,
        "additional_info": {
            "duration": 0.4421958923339844,
            "num_run": 972,
            "train_loss": 1.1864941498414465,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 972,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1661220789477392e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010894884723613393,
            "classifier:CustomMLPClassifier:max_iter": 357,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.0026125279614594783,
            "feature_preprocessor:select_rates_classification:alpha": 0.4392887787519377,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09788227081298828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 973,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006865952033437584,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022233185385008827,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 2.6165171417930612e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002055054968950072,
            "feature_preprocessor:select_rates_classification:alpha": 0.10720917965005551,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12401294708251953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 974,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009160279613228515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04341172607131218,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.00014683520455704353,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025189560799207714,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 23,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.1729339537477753,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2685932225242953,
        "time": 0.8592610359191895,
        "additional_info": {
            "duration": 0.8468878269195557,
            "num_run": 975,
            "train_loss": 1.0659389863203461,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 975,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006083655437390395,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3977972668050607,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 305,
            "classifier:CustomMLPClassifier:tol": 0.004410615062915751,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1608747997038441,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2354055080469997,
        "time": 0.6595199108123779,
        "additional_info": {
            "duration": 0.6415762901306152,
            "num_run": 976,
            "train_loss": 1.0361747102922698,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 976,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.648172818712072e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05143199902905474,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 4.017889600997066e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011931943558653589,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5629927245131239,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.257554966773204,
        "time": 2.830688953399658,
        "additional_info": {
            "duration": 2.807400941848755,
            "num_run": 977,
            "train_loss": 1.0576244652224644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 977,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.301729458557285e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01490706949216233,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 2.3296233058258414e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42883053133069776,
            "feature_preprocessor:select_rates_classification:alpha": 0.029921421599834963,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12988519668579102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 978,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.60581976207037e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02624839002563097,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.0034341450314439533,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7683978843673848,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3613290786743164,
        "additional_info": {
            "duration": 0.3431861400604248,
            "num_run": 979,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 979,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6354154084636942e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00329025561696632,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 3.426092444714808e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029159034337344507,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9429369814920514,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.7649719715118408,
        "additional_info": {
            "duration": 0.7446880340576172,
            "num_run": 980,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 980,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.7053053723724e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.259306698720744,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0027992390889141753,
            "feature_preprocessor:select_rates_classification:alpha": 0.026915278592300806,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.243516780358383,
        "time": 0.22264599800109863,
        "additional_info": {
            "duration": 0.21174407005310059,
            "num_run": 981,
            "train_loss": 1.1754571512750303,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 981,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09879399640761291,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011747833073770134,
            "classifier:CustomMLPClassifier:max_iter": 229,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.004649015430998919,
            "feature_preprocessor:select_rates_classification:alpha": 0.08065154806397085,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12430524826049805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 982,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002031459194020715,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011244910745375398,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 6.711852590064014e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00034423483508025463,
            "feature_preprocessor:select_rates_classification:alpha": 0.48096839237273475,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10204601287841797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 983,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.220587808479254e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06015788647001484,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 116,
            "classifier:CustomMLPClassifier:tol": 0.0003241519290451122,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015769472336362502,
            "feature_preprocessor:select_rates_classification:alpha": 0.17061256059590163,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10349321365356445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 984,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.059273273392334125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4702238799402711,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 0.0004065492399544174,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21236281245985758,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.34212643139300425,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.253949698339253,
        "time": 0.48749494552612305,
        "additional_info": {
            "duration": 0.4687380790710449,
            "num_run": 985,
            "train_loss": 1.1586405104754678,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 985,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.427074076385143e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004130415449203584,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00140892350612496,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11639144784884455,
            "feature_preprocessor:select_rates_classification:alpha": 0.20911757687442056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10287284851074219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 986,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00021023303784189503,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08975491920647248,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 0.0004786121402859289,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019555237974327671,
            "feature_preprocessor:select_percentile_classification:percentile": 71.05330927822767,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2474768958087903,
        "time": 0.5270829200744629,
        "additional_info": {
            "duration": 0.5124027729034424,
            "num_run": 987,
            "train_loss": 1.2144573108617556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 987,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001328250446261406,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035625674417953533,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 3.750606613438735e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05054387452881344,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9457308440171984,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.45973873138427734,
        "additional_info": {
            "duration": 0.4474010467529297,
            "num_run": 988,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 988,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04685740552951726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004729600907089577,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.0006838176429385829,
            "feature_preprocessor:select_rates_classification:alpha": 0.09463377214671896,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12485694885253906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 989,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2474858090360554e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017560170454456318,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 1.1189474204781325e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007962121408803953,
            "feature_preprocessor:select_rates_classification:alpha": 0.197158856821433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09704399108886719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 990,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0102909477631974e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10896100641120363,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 314,
            "classifier:CustomMLPClassifier:tol": 1.9616170455115226e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006274626892906309,
            "feature_preprocessor:select_rates_classification:alpha": 0.32037671934777145,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12469124794006348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 991,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008172205896179013,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006732030299079425,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 0.00018263012339661395,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001327518253797858,
            "feature_preprocessor:select_rates_classification:alpha": 0.15554948643636413,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12350583076477051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 992,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000475268204179807,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005045523422346502,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.000313614988782185,
            "feature_preprocessor:select_rates_classification:alpha": 0.11913523894642367,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10263895988464355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 993,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.0271264082151904e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7828034397107451,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.006020037057081174,
            "feature_preprocessor:select_percentile_classification:percentile": 36.07096413078324,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.235908836690053,
        "time": 0.6256990432739258,
        "additional_info": {
            "duration": 0.6056568622589111,
            "num_run": 994,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 994,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.695706533527862e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017335132037454384,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.009093484504631056,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013411975052330983,
            "feature_preprocessor:select_rates_classification:alpha": 0.32156986753346967,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1594829559326172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 995,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.051767715472036284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020883749135494834,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0008890604164591322,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1311303065527446,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.6616482734680176,
        "additional_info": {
            "duration": 0.5887632369995117,
            "num_run": 996,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 996,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0026022978477764818,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00781044622687261,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.00012358004488818446,
            "feature_preprocessor:select_percentile_classification:percentile": 14.736664503258387,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.3676168918609619,
        "additional_info": {
            "duration": 0.2930891513824463,
            "num_run": 997,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 997,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5367194667700233e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016831237855426317,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.004009947127790491,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004485081582876072,
            "feature_preprocessor:select_percentile_classification:percentile": 56.80643862352196,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.4509282112121582,
        "additional_info": {
            "duration": 0.4392869472503662,
            "num_run": 998,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 998,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.745471281290707e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006257160091391359,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0013935339757433043,
            "feature_preprocessor:select_rates_classification:alpha": 0.4939238680904384,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.7384171485900879,
        "additional_info": {
            "duration": 0.722017765045166,
            "num_run": 999,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 999,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00275413750294396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046102307667122256,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 412,
            "classifier:CustomMLPClassifier:tol": 1.9965456906003158e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03405240067555067,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.7775161266326904,
        "additional_info": {
            "duration": 0.7652370929718018,
            "num_run": 1000,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1000,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008325705670320128,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007023134145506014,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 5.171657206617107e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09318198154851894,
            "feature_preprocessor:select_rates_classification:alpha": 0.3954822297001593,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10789608955383301,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1001,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001054996370888502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3222340286413607,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.006744199430375784,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023802620138287017,
            "feature_preprocessor:select_rates_classification:alpha": 0.27104446298791895,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.2790229320526123,
        "additional_info": {
            "duration": 0.26343393325805664,
            "num_run": 1002,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1002,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.427501553425549e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018292506565444267,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.008436147543931821,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007543660450739868,
            "feature_preprocessor:select_rates_classification:alpha": 0.45267752268862965,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09678483009338379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1003,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01885199817778628,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004881944135546408,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 1.557113827465999e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005800527977149763,
            "feature_preprocessor:select_percentile_classification:percentile": 28.913968726070525,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2723896192083253,
        "time": 6.020582914352417,
        "additional_info": {
            "duration": 6.008504152297974,
            "num_run": 1004,
            "train_loss": 1.1264022854909679,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1004,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.677616277410069e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006338767701072795,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0008590415535589733,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000261025023166088,
            "feature_preprocessor:select_percentile_classification:percentile": 30.34894286519301,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.5148942470550537,
        "additional_info": {
            "duration": 0.5013778209686279,
            "num_run": 1005,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1005,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.853363416389326e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013065885466645293,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 221,
            "classifier:CustomMLPClassifier:tol": 0.004723857609849139,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003416346139296749,
            "feature_preprocessor:select_rates_classification:alpha": 0.2697560068676691,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0963132381439209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1006,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0756820423213698,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08115835891932169,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.0009335561040155929,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011666378541047666,
            "feature_preprocessor:select_rates_classification:alpha": 0.3855543850875279,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12683796882629395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1007,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002836172968019225,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022609032951765684,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 4.787363943795018e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04121405614657227,
            "feature_preprocessor:select_rates_classification:alpha": 0.29878438102695704,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2582058422837454,
        "time": 6.061396837234497,
        "additional_info": {
            "duration": 6.048090934753418,
            "num_run": 1008,
            "train_loss": 1.0159933387726947,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1008,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.572267119703017e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.30117032739714084,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 0.00017025593049959574,
            "feature_preprocessor:select_rates_classification:alpha": 0.37107037110786406,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.384289026260376,
        "additional_info": {
            "duration": 0.3709077835083008,
            "num_run": 1009,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1009,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.4535502164387215e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002808938593617187,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 0.0001508285596206694,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008757161058646866,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 859,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9694696436689909,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2422695443664193,
        "time": 0.8756396770477295,
        "additional_info": {
            "duration": 0.860152006149292,
            "num_run": 1010,
            "train_loss": 1.1738340661156532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1010,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1874222323612638e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023587230342084806,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0009561183676616554,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8514054574292754,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1550506875353961,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7519012472737803,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2570859382856578,
        "time": 0.4831240177154541,
        "additional_info": {
            "duration": 0.47180795669555664,
            "num_run": 1011,
            "train_loss": 1.2148604528410551,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1011,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.04996316956938e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06635194828878181,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 0.006052120218742739,
            "feature_preprocessor:select_rates_classification:alpha": 0.28945860296645853,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12756609916687012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1012,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07314397353260499,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016287135661503697,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.00017372052528747883,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013601537320263035,
            "feature_preprocessor:select_percentile_classification:percentile": 50.03776462534736,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2491931168685453,
        "time": 0.8060872554779053,
        "additional_info": {
            "duration": 0.7951841354370117,
            "num_run": 1013,
            "train_loss": 1.2293029460676388,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1013,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0032386650910718575,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004864093791013335,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.00044610983749456803,
            "feature_preprocessor:select_rates_classification:alpha": 0.30863467926054483,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 1.937183141708374,
        "additional_info": {
            "duration": 1.9256272315979004,
            "num_run": 1014,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1014,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.040633596244300366,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027283239532709087,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 0.002706152551583523,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018912013763028703,
            "feature_preprocessor:select_rates_classification:alpha": 0.06147399220488836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12393593788146973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1015,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00021112820966777318,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002284435982525352,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.0003836440778765679,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008749938074323395,
            "feature_preprocessor:select_rates_classification:alpha": 0.1479133334415936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09716486930847168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1016,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1043687708886795e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042196057597280496,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 4.665343561912635e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 31.74421302080513,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.258443356193744,
        "time": 2.9434587955474854,
        "additional_info": {
            "duration": 2.926666021347046,
            "num_run": 1017,
            "train_loss": 1.1791326183929196,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1017,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.574491645599549e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031356042191352,
            "classifier:CustomMLPClassifier:max_iter": 175,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 0.0017539402656288172,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02088009104145966,
            "feature_preprocessor:select_rates_classification:alpha": 0.4082690412300155,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2299475790113534,
        "time": 1.1287410259246826,
        "additional_info": {
            "duration": 1.1087520122528076,
            "num_run": 1018,
            "train_loss": 1.1277336737586467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1018,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0013637503564472026,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08209681053054078,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.00030324224054418516,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010516082328093746,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8916395635609039,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.008828148105705553,
            "feature_preprocessor:select_rates_classification:alpha": 0.13928835305036258,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226792993709556,
        "time": 0.2935202121734619,
        "additional_info": {
            "duration": 0.27492809295654297,
            "num_run": 1019,
            "train_loss": 1.214916342384457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1019,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.0236884289809588e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.053504979189191906,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 0.00032588234746062906,
            "feature_preprocessor:select_rates_classification:alpha": 0.23619514821672744,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12418818473815918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1020,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3846277411931553e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008189394277597748,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 2.7762128686541515e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008345786836634343,
            "feature_preprocessor:select_rates_classification:alpha": 0.04594097494285385,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09744906425476074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1021,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.020583876988116e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011106558240167488,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 1.661028705120615e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3208110159635484,
            "feature_preprocessor:select_rates_classification:alpha": 0.1155546062157283,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12573790550231934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1022,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006560812676515799,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005393752925904411,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 1.391350876773081e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.02933109946122249,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09687113761901855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1023,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021491235903053194,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005380613066729231,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 5.085104987845548e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 9.181508026857278,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2496297147188027,
        "time": 1.0688681602478027,
        "additional_info": {
            "duration": 1.0568459033966064,
            "num_run": 1024,
            "train_loss": 1.217852390792901,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1024,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7271335634720727e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001774588016408765,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 4.772295966634062e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.36596227156484384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10240912437438965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1025,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.5595867647917693e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016247058076299457,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 409,
            "classifier:CustomMLPClassifier:tol": 1.7334231289115786e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7293648618779651,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21637519526638566,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7555192210960435,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2537495059608648,
        "time": 1.2306580543518066,
        "additional_info": {
            "duration": 1.2134242057800293,
            "num_run": 1026,
            "train_loss": 1.1972184885767145,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1026,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.224375123638925e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5574148209264222,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.000364692659067783,
            "feature_preprocessor:select_percentile_classification:percentile": 96.51110953861644,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2480368695177115,
        "time": 1.4228839874267578,
        "additional_info": {
            "duration": 1.407151222229004,
            "num_run": 1027,
            "train_loss": 1.0091261794205928,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1027,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004137901687147093,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003976844445103518,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.0038738231425522957,
            "feature_preprocessor:select_rates_classification:alpha": 0.17331850207711716,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2186545290132451,
        "time": 0.33479881286621094,
        "additional_info": {
            "duration": 0.3177769184112549,
            "num_run": 1028,
            "train_loss": 1.1995143586824284,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1028,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5699355844117474e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.216895907475133,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.0021774319204704664,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002878842171077921,
            "feature_preprocessor:select_rates_classification:alpha": 0.31636877815744946,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09746932983398438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1029,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.126135133076001e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10612664567444151,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.004159475257855433,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2411289280511546,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2907880887315548,
        "time": 1.9439151287078857,
        "additional_info": {
            "duration": 1.9280869960784912,
            "num_run": 1030,
            "train_loss": 1.1336478924637134,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1030,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.900494553698623e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011233670567396012,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 6.609305139388889e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009987765355469044,
            "feature_preprocessor:select_rates_classification:alpha": 0.3317157451659231,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10253119468688965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1031,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.391569818196087e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005943669338820105,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.005094456727981837,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002839731675872589,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 803,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.39712264458903307,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2832939624786377,
        "additional_info": {
            "duration": 0.2698178291320801,
            "num_run": 1032,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1032,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4574487008462243e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013143250536068143,
            "classifier:CustomMLPClassifier:max_iter": 350,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.002057445712009544,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7558207119263823,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19977712195252814,
            "feature_preprocessor:select_rates_classification:alpha": 0.24276351885504413,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.231749637299387,
        "time": 0.561959981918335,
        "additional_info": {
            "duration": 0.5381669998168945,
            "num_run": 1033,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1033,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09388812570593895,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021938945376349903,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.004055511532749665,
            "feature_preprocessor:select_rates_classification:alpha": 0.18302486402614232,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12459397315979004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1034,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03328876729132568,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04768838078634395,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 2.5009631993748144e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09600697308457828,
            "feature_preprocessor:select_rates_classification:alpha": 0.28091027871708885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2528893305238713,
        "time": 0.7504651546478271,
        "additional_info": {
            "duration": 0.7381019592285156,
            "num_run": 1035,
            "train_loss": 1.0234468128305532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1035,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006886272567864048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9881154666044728,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0017461607168733958,
            "feature_preprocessor:select_percentile_classification:percentile": 8.682980762725517,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.3213619983409817,
        "time": 0.36447906494140625,
        "additional_info": {
            "duration": 0.34088778495788574,
            "num_run": 1036,
            "train_loss": 1.2741757679565002,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1036,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.6214754689244705e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1273523741382921,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 1.5618848336978568e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 51.3651337484974,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2236162371764179,
        "time": 1.4516019821166992,
        "additional_info": {
            "duration": 1.438424825668335,
            "num_run": 1037,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1037,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.202755999509112e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011593010797726442,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 0.00492819381582469,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039759857975723184,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7450608938775922,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.37616896629333496,
        "additional_info": {
            "duration": 0.363588809967041,
            "num_run": 1038,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1038,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.474224532387628e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008936839785820298,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 3.064461093516019e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18630155766558149,
            "feature_preprocessor:select_percentile_classification:percentile": 97.38211743306823,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.238400460976897,
        "time": 3.7789218425750732,
        "additional_info": {
            "duration": 3.768665075302124,
            "num_run": 1039,
            "train_loss": 1.05298597672772,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1039,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03588606477299215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5365075563615025,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 3.98754052178796e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4156727654460057,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12425112724304199,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1040,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.943323669125779e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008807027541037649,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 5.460512204417315e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1876783166104427,
            "feature_preprocessor:select_rates_classification:alpha": 0.4279171070243863,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09692597389221191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1041,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.6628620059734375e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006451527414687093,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 1.075253126295274e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002749058702219213,
            "feature_preprocessor:select_rates_classification:alpha": 0.24000170169283844,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12460494041442871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1042,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.988294290468329e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031892957193479884,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 2.584393624025939e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3513457997213875,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09660005569458008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1043,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.17873416578142e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020853969078601136,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 2.092187983013751e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 47.20657311902833,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.30071234703063965,
        "additional_info": {
            "duration": 0.28919386863708496,
            "num_run": 1044,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1044,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009086339607368632,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028101271455082196,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 1.2011423679218574e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35603352201564903,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09733891487121582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1045,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.84724965558632e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013389052734612442,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 0.008974141415507099,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12416143472506296,
            "feature_preprocessor:select_rates_classification:alpha": 0.01695306746472695,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13084888458251953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1046,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001148455559762129,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011183859072468126,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 282,
            "classifier:CustomMLPClassifier:tol": 0.003311141546713089,
            "feature_preprocessor:select_percentile_classification:percentile": 7.822771102789693,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.235908836690053,
        "time": 0.27941012382507324,
        "additional_info": {
            "duration": 0.26905012130737305,
            "num_run": 1047,
            "train_loss": 1.2349078088654397,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1047,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008168690192425346,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009614605732665994,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.00289986831275712,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013727622649035402,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 949,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.06907831834222121,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.5572888851165771,
        "additional_info": {
            "duration": 0.5264499187469482,
            "num_run": 1048,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1048,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008704894644621011,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001166175197321897,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 0.005260072845525785,
            "feature_preprocessor:select_rates_classification:alpha": 0.14787491451400836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09796404838562012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1049,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0004638103518462563,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013192591116013317,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.008416032114390218,
            "feature_preprocessor:select_rates_classification:alpha": 0.02942174284155711,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10299110412597656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1050,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0007003784287450594,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3869949702911543,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 6.215945269814309e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12398878764847408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09658074378967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1051,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00023382422617840214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9839899050631646,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.0002894260177496056,
            "feature_preprocessor:select_rates_classification:alpha": 0.066410795264433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12454390525817871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1052,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0800917199433609,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01818487836482395,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 4.9165316138071316e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06325415873014144,
            "feature_preprocessor:select_rates_classification:alpha": 0.21891193616871302,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09656906127929688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1053,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007469715467915673,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002243564089632823,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 9.685378947955194e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.10355992506415758,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10241222381591797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1054,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.032833545096399484,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014374307636219613,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 1.750683491632669e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007981004710703446,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1834,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 21.116099379888535,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2617515745349903,
        "time": 3.7086069583892822,
        "additional_info": {
            "duration": 3.6966960430145264,
            "num_run": 1055,
            "train_loss": 1.2347112024829614,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1055,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.017996901914190573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5437760940579294,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.0006106368131218123,
            "feature_preprocessor:select_rates_classification:alpha": 0.017818478956263296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12914395332336426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1056,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.085179135373423e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031465257981401696,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 291,
            "classifier:CustomMLPClassifier:tol": 4.706347717154829e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031867450600005197,
            "feature_preprocessor:select_rates_classification:alpha": 0.02867853699184362,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09741997718811035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1057,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010683103690887071,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5287788147905288,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 0.0029338309215610095,
            "feature_preprocessor:select_rates_classification:alpha": 0.35011721543325347,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16028594970703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1058,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004102770033418134,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005326698318599853,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 0.0007791123227701283,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8367188034668434,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18427275067000212,
            "feature_preprocessor:select_rates_classification:alpha": 0.1727492011026103,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.227216527876537,
        "time": 3.1484978199005127,
        "additional_info": {
            "duration": 3.1326138973236084,
            "num_run": 1059,
            "train_loss": 1.14458179023132,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1059,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.026561935876218693,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026750156081243592,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 4.183879790186173e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03640203085770116,
            "feature_preprocessor:select_rates_classification:alpha": 0.14119576491181066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09814906120300293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1060,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.557943633704641e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00544677060104647,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 1.2756904173813474e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.46936615641337553,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12424707412719727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1061,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0004899026238055282,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7487952606965985,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 0.0063783250850225565,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7030906444011554,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27657951306249146,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9646690280446834,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2991074656917516,
        "time": 0.37145209312438965,
        "additional_info": {
            "duration": 0.3524959087371826,
            "num_run": 1062,
            "train_loss": 1.189880987996957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1062,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0016617610440904029,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25262419001236663,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 0.0051622501305918535,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.055582107077231074,
            "feature_preprocessor:select_rates_classification:alpha": 0.033030451412379445,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13029098510742188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1063,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.6957887367959202e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0602117970599127,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.0027961917968037722,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1559,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 88.1453558324132,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2320690757222066,
        "time": 1.000964879989624,
        "additional_info": {
            "duration": 0.9899680614471436,
            "num_run": 1064,
            "train_loss": 1.1973656572395612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1064,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011809729015623563,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03826048006784997,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 0.001587057768041333,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08961578758210531,
            "feature_preprocessor:select_rates_classification:alpha": 0.301654671666428,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2593752835771204,
        "time": 0.2505347728729248,
        "additional_info": {
            "duration": 0.2376420497894287,
            "num_run": 1065,
            "train_loss": 1.2086102378942076,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1065,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.4984773253806196e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36097442258042073,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 3.860568487531872e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03152787756760259,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13070106506347656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1066,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000512099503289296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003921679329812624,
            "classifier:CustomMLPClassifier:max_iter": 203,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 2.6950573039543898e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07148707627718777,
            "feature_preprocessor:select_percentile_classification:percentile": 95.90087672643807,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2610278820596919,
        "time": 1.4511423110961914,
        "additional_info": {
            "duration": 1.4346020221710205,
            "num_run": 1067,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1067,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07216798135552333,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014061056418123094,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 9.231777256911264e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1902241814152095,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9696054191624152,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2570859382856578,
        "time": 0.4161498546600342,
        "additional_info": {
            "duration": 0.39594292640686035,
            "num_run": 1068,
            "train_loss": 1.2148604528410551,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1068,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.620651334854972e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0033989879112794274,
            "classifier:CustomMLPClassifier:max_iter": 395,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 0.005630384996618494,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4897321099572646,
            "feature_preprocessor:select_rates_classification:alpha": 0.1916106208146445,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09670376777648926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1069,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06999165158826812,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041517589776632834,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.0037638235509072546,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24514991224780985,
            "feature_preprocessor:select_percentile_classification:percentile": 35.199072569442365,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.347567081451416,
        "additional_info": {
            "duration": 0.32969117164611816,
            "num_run": 1070,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1070,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0018702574462084582,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023067165866406978,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.0011031979952808055,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016277277723388005,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8350139962703934,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.249198094602377,
        "time": 0.8458080291748047,
        "additional_info": {
            "duration": 0.8280031681060791,
            "num_run": 1071,
            "train_loss": 1.151974614869232,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1071,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0956876191934313,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006988448737887275,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 1.967033174251782e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 894,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.019719241306098766,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.6865899562835693,
        "additional_info": {
            "duration": 0.673475980758667,
            "num_run": 1072,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1072,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.5350180929866077e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004461200425884405,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 2.4027839846801454e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.30337811505363543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1024940013885498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1073,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001132223883105664,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006488326629325825,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 1.1278464683314821e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1367474787586428,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09681010246276855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1074,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004240906110580513,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002459958110534462,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.0003399060610852642,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3300816504515306,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.16341339802431754,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.4366879463195801,
        "additional_info": {
            "duration": 0.4189779758453369,
            "num_run": 1075,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1075,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0018782974179828893,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014307531282287698,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 1.1716839109059803e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3278499086917058,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2873152168648216,
        "time": 3.179516077041626,
        "additional_info": {
            "duration": 3.1657679080963135,
            "num_run": 1076,
            "train_loss": 1.0148638287384495,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1076,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.729872943104108e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019160793808292907,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.00037775245881375606,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1229,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.34621085261505874,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2467895901059929,
        "time": 4.168778896331787,
        "additional_info": {
            "duration": 4.153781890869141,
            "num_run": 1077,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1077,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.133200585288503e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0626689215952298,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 4.328420130459959e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.15072470819779882,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10234904289245605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1078,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0053673296720512685,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08987353004325481,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 0.00012564529753819666,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1791,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.15198990378602306,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2559387550631333,
        "time": 1.2714030742645264,
        "additional_info": {
            "duration": 1.2600109577178955,
            "num_run": 1079,
            "train_loss": 1.1131370790392847,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1079,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0015659634856623706,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035851836689947828,
            "classifier:CustomMLPClassifier:max_iter": 297,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 1.1542369000888106e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 17.21453478082133,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2295978399879939,
        "time": 0.5549721717834473,
        "additional_info": {
            "duration": 0.5363447666168213,
            "num_run": 1080,
            "train_loss": 1.2028589234342844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1080,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0033222959982677457,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3060276812611644,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.00019944106083571224,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022194371036495547,
            "feature_preprocessor:select_rates_classification:alpha": 0.4818191860065646,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2479913317773916,
        "time": 0.9755241870880127,
        "additional_info": {
            "duration": 0.9653940200805664,
            "num_run": 1081,
            "train_loss": 1.2014371020207735,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1081,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00019461840867194828,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001014430179812021,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.0009610838765604584,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1622,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6442919492608961,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2485188748490244,
        "time": 1.5458650588989258,
        "additional_info": {
            "duration": 1.534339189529419,
            "num_run": 1082,
            "train_loss": 1.2301887364686375,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1082,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2596415484738712e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09031321935549,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 0.00011655183823430598,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023034237863724844,
            "feature_preprocessor:select_rates_classification:alpha": 0.15287720645024275,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10279989242553711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1083,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00032889392173713895,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028472734163529273,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 2.676799776450943e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005624451521199752,
            "feature_preprocessor:select_rates_classification:alpha": 0.3861202935445549,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12981915473937988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1084,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7556738845374628e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5434507109705244,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.0067822436436558884,
            "feature_preprocessor:select_rates_classification:alpha": 0.21172736361196953,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10219287872314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1085,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001132554981364237,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0654225018345323,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.00016242554816676762,
            "feature_preprocessor:select_rates_classification:alpha": 0.15390852657373022,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1029970645904541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1086,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009964043735361545,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2081379780145417,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.000553548522431169,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00170217021015052,
            "feature_preprocessor:select_rates_classification:alpha": 0.03959145552846191,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12534093856811523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1087,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.850346651491665e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07980989520220949,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 7.101909792296124e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018788189717921486,
            "feature_preprocessor:select_percentile_classification:percentile": 17.073875693388562,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.258512043344269,
        "time": 0.7269148826599121,
        "additional_info": {
            "duration": 0.7131121158599854,
            "num_run": 1088,
            "train_loss": 1.203257025048674,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1088,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.325999617991534e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.050546623573216154,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.0014494257651388879,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003062088590182629,
            "feature_preprocessor:select_rates_classification:alpha": 0.17744887987148908,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12496733665466309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1089,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006430870939945223,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011076127598920099,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 1.107746644536299e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013722547585613267,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6340829418823729,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2659168166778625,
        "time": 2.103104829788208,
        "additional_info": {
            "duration": 2.0848519802093506,
            "num_run": 1090,
            "train_loss": 1.0554701089271201,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1090,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006037949606886242,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004570965067036971,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.0016908641000798353,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001860042766932809,
            "feature_preprocessor:select_rates_classification:alpha": 0.4201717437767127,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.15930581092834473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1091,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.027805874273038832,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00044448058465883694,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 6.056842232398671e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1419922523410478,
            "feature_preprocessor:select_rates_classification:alpha": 0.47946018188635375,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12995600700378418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1092,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.395947780583277e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05492579077074301,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 421,
            "classifier:CustomMLPClassifier:tol": 0.009304988862753662,
            "feature_preprocessor:select_rates_classification:alpha": 0.11935033210414141,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2364263808742673,
        "time": 0.3673820495605469,
        "additional_info": {
            "duration": 0.35145020484924316,
            "num_run": 1093,
            "train_loss": 1.1961385987458266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1093,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02139176234891726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023383076492367733,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.0003445431885474096,
            "feature_preprocessor:select_rates_classification:alpha": 0.4496965057323714,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16521000862121582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1094,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0631086895868664e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009058787135745276,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 3.9985467482518405e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03222481374535211,
            "feature_preprocessor:select_rates_classification:alpha": 0.21957162212238082,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12513113021850586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1095,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.015762536386689365,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005355615687703995,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 1.1707213364884786e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000915799113724699,
            "feature_preprocessor:select_rates_classification:alpha": 0.2369946229712902,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.16499996185302734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1096,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0675914472369746e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00781553123334583,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 299,
            "classifier:CustomMLPClassifier:tol": 0.00012061949212695445,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.032377758109532896,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1269,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.46518642299609003,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2584150987904426,
        "time": 0.716270923614502,
        "additional_info": {
            "duration": 0.7034869194030762,
            "num_run": 1097,
            "train_loss": 1.200777933214184,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1097,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002549104956482612,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026225329288138623,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 211,
            "classifier:CustomMLPClassifier:tol": 5.5429679789797316e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23702085976415765,
            "feature_preprocessor:select_rates_classification:alpha": 0.43538670249657546,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0973210334777832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1098,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.381159206035201e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022710009102487633,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 1.9898249710359197e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039292481780437935,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7882870233483118,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.013890471842230478,
            "feature_preprocessor:select_rates_classification:alpha": 0.04799146450072849,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2526679450930072,
        "time": 2.92618989944458,
        "additional_info": {
            "duration": 2.915065050125122,
            "num_run": 1099,
            "train_loss": 1.0571124650787214,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1099,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0021540704743711067,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7897892956751063,
            "classifier:CustomMLPClassifier:max_iter": 133,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 0.001357764068203887,
            "feature_preprocessor:select_rates_classification:alpha": 0.45533886332910806,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10255908966064453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1100,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0031756849317570008,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005138505881754707,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0003521653796662415,
            "feature_preprocessor:select_rates_classification:alpha": 0.10720813480977896,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12412405014038086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.2400247737973576e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029330055979576865,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 3.1714664176501085e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06757511195220174,
            "feature_preprocessor:select_rates_classification:alpha": 0.214751298610878,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1256577968597412,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1102,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015869823198198041,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006733363434965138,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.0010188645858522857,
            "feature_preprocessor:select_rates_classification:alpha": 0.2520144832346738,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12427210807800293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1103,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00953174174235255,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015108455227041651,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 4.6317574774610865e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.09482372083892573,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12462902069091797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1104,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05233377258935547,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016800321474775033,
            "classifier:CustomMLPClassifier:max_iter": 264,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.0006619103229195213,
            "feature_preprocessor:select_percentile_classification:percentile": 61.5935006307838,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2578187817287751,
        "time": 0.4713311195373535,
        "additional_info": {
            "duration": 0.4576408863067627,
            "num_run": 1105,
            "train_loss": 1.1730152924792847,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7433960368482818e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026774935333597647,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 359,
            "classifier:CustomMLPClassifier:tol": 0.0009257257702773045,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13397711009978566,
            "feature_preprocessor:select_rates_classification:alpha": 0.3854320850983869,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09762787818908691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008033332220566232,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020920857412668123,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 327,
            "classifier:CustomMLPClassifier:tol": 2.5791028709846635e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10612592960749911,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.986915068271434,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.248696852576317,
        "time": 2.6284267902374268,
        "additional_info": {
            "duration": 2.6160900592803955,
            "num_run": 1107,
            "train_loss": 1.1773679704208537,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07034317640847292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020498726384239408,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 0.0014375580012911456,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08714189375491216,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24076660610742406,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2570677666092849,
        "time": 0.9167790412902832,
        "additional_info": {
            "duration": 0.9032878875732422,
            "num_run": 1108,
            "train_loss": 1.193135119602981,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1108,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9769356261301303e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003319886983197332,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 1.961836162069131e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.968461244949176,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1437454890550474,
            "feature_preprocessor:select_percentile_classification:percentile": 98.75133502440073,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2345767850684302,
        "time": 7.6635801792144775,
        "additional_info": {
            "duration": 7.652477025985718,
            "num_run": 1109,
            "train_loss": 1.1644266535347039,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1109,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0091382066177443,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03357578230410877,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.0004403321429341712,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24258934561193113,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2140981399209254,
        "time": 0.5247108936309814,
        "additional_info": {
            "duration": 0.5117502212524414,
            "num_run": 1110,
            "train_loss": 1.1996618568359598,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002936199091059363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022214978821032065,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 0.0012412677620956944,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024223113670796207,
            "feature_preprocessor:select_rates_classification:alpha": 0.09811360107767124,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.9319970607757568,
        "additional_info": {
            "duration": 0.9191632270812988,
            "num_run": 1111,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8692933612128703e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.48528296249675407,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.0006054397558425094,
            "feature_preprocessor:select_rates_classification:alpha": 0.14096535897049894,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10126996040344238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.4656236018568194e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016083959624423345,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.0003607295977820274,
            "feature_preprocessor:select_rates_classification:alpha": 0.41494056331622586,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.495466947555542,
        "additional_info": {
            "duration": 0.4853641986846924,
            "num_run": 1113,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1113,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.9753249891741333e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005413381398161503,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.009426508476302914,
            "feature_preprocessor:select_rates_classification:alpha": 0.1983499467291308,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09629631042480469,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0034414093984294976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06375949806301928,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 345,
            "classifier:CustomMLPClassifier:tol": 0.0005778747945134479,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05748626660993997,
            "feature_preprocessor:select_rates_classification:alpha": 0.2569201851499519,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2897789478302002,
        "additional_info": {
            "duration": 0.2783679962158203,
            "num_run": 1115,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.667784687650642e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025508363045249325,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.0007563051472268467,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0064717394432807366,
            "feature_preprocessor:select_rates_classification:alpha": 0.2780377407295373,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2583787120179415,
        "time": 3.0900468826293945,
        "additional_info": {
            "duration": 3.0761327743530273,
            "num_run": 1116,
            "train_loss": 1.0298138962314336,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1116,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04249661213495249,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2964241122845112,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.00017263721444874368,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0052042373506759375,
            "feature_preprocessor:select_rates_classification:alpha": 0.3339492355814117,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12387490272521973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.984298940097544e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008934443092365426,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 2.7777514971470935e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030509705703094366,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1610,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4970203625598728,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5702042579650879,
        "additional_info": {
            "duration": 0.5501151084899902,
            "num_run": 1118,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.270147904421145e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16524501652458523,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 0.00016364518379731149,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10990405827805372,
            "feature_preprocessor:select_rates_classification:alpha": 0.40007731450268813,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10219001770019531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0024491938692406566,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005377377711462353,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.0003010154394900841,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02186938877578062,
            "feature_preprocessor:select_rates_classification:alpha": 0.370268227394636,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.25953102111816406,
        "additional_info": {
            "duration": 0.24802184104919434,
            "num_run": 1120,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1174904860489675e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006010277678408456,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 7.837807041527824e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.01068136310350219,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.4327881336212158,
        "additional_info": {
            "duration": 0.41930699348449707,
            "num_run": 1121,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011968451398342566,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9978999015021389,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 2.0493155867898492e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01004946489978538,
            "feature_preprocessor:select_rates_classification:alpha": 0.4716719492389613,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2109102326424848,
        "time": 0.3031880855560303,
        "additional_info": {
            "duration": 0.28031110763549805,
            "num_run": 1122,
            "train_loss": 1.1914326795166807,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005945044928499125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7664010535169098,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 5.1247416248544604e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06994503476030316,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2542507914066798,
        "time": 0.9559459686279297,
        "additional_info": {
            "duration": 0.940997838973999,
            "num_run": 1123,
            "train_loss": 1.2384327589027984,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0025597432054051,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2319553281018781,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 0.00021421849986095294,
            "feature_preprocessor:select_rates_classification:alpha": 0.47304383553605495,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10237693786621094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1124,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.2589303305130076e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004986760523973803,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.0026745259751753494,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003960593021420902,
            "feature_preprocessor:select_rates_classification:alpha": 0.09499645177981925,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.2792820930480957,
        "additional_info": {
            "duration": 0.26493215560913086,
            "num_run": 1125,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1125,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.249621961576841e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20076137855913573,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.0002133803051641296,
            "feature_preprocessor:select_rates_classification:alpha": 0.2058640042579753,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0973958969116211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.914992640949253e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007643980473572377,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 2.8688099914659283e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35030750678973127,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0990591049194336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.023605286697271806,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004695685539686447,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.00031459374660787947,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022590876702654996,
            "feature_preprocessor:select_rates_classification:alpha": 0.01651498163576239,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10525393486022949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1128,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.52755339184446e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07144004547719825,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 235,
            "classifier:CustomMLPClassifier:tol": 0.00014831906869773083,
            "feature_preprocessor:select_rates_classification:alpha": 0.33662985230318077,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1249690055847168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1129,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008827987051468669,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022057908423202475,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 0.0028437612217328927,
            "feature_preprocessor:select_rates_classification:alpha": 0.31253848814508356,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12495994567871094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1130,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001324698323649786,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012004591647255976,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 5.860313335127092e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004475688921892288,
            "feature_preprocessor:select_rates_classification:alpha": 0.2903626305566572,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09798097610473633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1131,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0013902664414358037,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06536703596457226,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.0013717946260382887,
            "feature_preprocessor:select_percentile_classification:percentile": 42.57574961516372,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.275429979619278,
        "time": 0.4466080665588379,
        "additional_info": {
            "duration": 0.43328404426574707,
            "num_run": 1132,
            "train_loss": 1.2181995942264794,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.693501234374502e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7507110106570352,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 0.0005005298417249082,
            "feature_preprocessor:select_rates_classification:alpha": 0.3428890749863539,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09999203681945801,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1133,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00012775343435766996,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006160244799556432,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 0.004377369553050374,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22485690012121504,
            "feature_preprocessor:select_rates_classification:alpha": 0.292748712119418,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1237039566040039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1134,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002910260414272528,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022435644453768946,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 1.2217026641440895e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003566319557847515,
            "feature_preprocessor:select_rates_classification:alpha": 0.021597877052167043,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2394293329140997,
        "time": 2.1147689819335938,
        "additional_info": {
            "duration": 2.1033689975738525,
            "num_run": 1135,
            "train_loss": 1.1909858036725463,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.62391488205417e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003625444732976888,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.00997943477724752,
            "feature_preprocessor:select_rates_classification:alpha": 0.09296506321721187,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09852910041809082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08603337765875517,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006071380135012216,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.0077443450461718855,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008517007096285742,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 266,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2186641938525753,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2409585989577627,
        "time": 0.5726838111877441,
        "additional_info": {
            "duration": 0.5529043674468994,
            "num_run": 1137,
            "train_loss": 1.1635903008533368,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.038892136441926704,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3383310014894877,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.00021642936580775241,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009541995001670049,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9097379960042888,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0322935277140217,
            "feature_preprocessor:select_percentile_classification:percentile": 52.129822387562534,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2407857726433216,
        "time": 0.5306627750396729,
        "additional_info": {
            "duration": 0.5130620002746582,
            "num_run": 1138,
            "train_loss": 1.178862877421243,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.425448219550724e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03751432446364929,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 0.0013016423434744715,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8936663016666949,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2666950676020352,
        "time": 0.4924137592315674,
        "additional_info": {
            "duration": 0.48073720932006836,
            "num_run": 1139,
            "train_loss": 1.2112955848371543,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001384579122604849,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12348859388982376,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 0.00016624637187021075,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006594479247550226,
            "feature_preprocessor:select_percentile_classification:percentile": 20.98286241516288,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2295746037382793,
        "time": 0.5464029312133789,
        "additional_info": {
            "duration": 0.525993824005127,
            "num_run": 1140,
            "train_loss": 1.1567064574321684,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1140,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.5624674291373805e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017727381779104306,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 0.0004970275907305325,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.03015962768547098,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.245214829741765,
        "time": 3.242079019546509,
        "additional_info": {
            "duration": 3.2259039878845215,
            "num_run": 1141,
            "train_loss": 1.092444321863534,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.433270340813656e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010353859618869037,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 8.742539289708494e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35158195767912903,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09638595581054688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05654060340959303,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25006623010481605,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 123,
            "classifier:CustomMLPClassifier:tol": 0.0006313947880457011,
            "feature_preprocessor:select_rates_classification:alpha": 0.03353519439190321,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12890005111694336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0298945119396001e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3287633796851811,
            "classifier:CustomMLPClassifier:max_iter": 253,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.0001024608447186792,
            "feature_preprocessor:select_rates_classification:alpha": 0.187170299622398,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10122990608215332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1144,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004089203287126451,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00244457610051558,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.0024797659004756824,
            "feature_preprocessor:select_rates_classification:alpha": 0.022252484805480838,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09646177291870117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.62513523640742e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04707099883231148,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 0.0002844671072373208,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09322234072814388,
            "feature_preprocessor:select_rates_classification:alpha": 0.04080742567752355,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2388481661527024,
        "time": 0.3997642993927002,
        "additional_info": {
            "duration": 0.3878030776977539,
            "num_run": 1146,
            "train_loss": 1.2028285742231513,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1146,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.033561440088350526,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.037124460802855926,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.0036892880427403653,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028040649850773324,
            "feature_preprocessor:select_rates_classification:alpha": 0.40572084796627234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09736299514770508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04684939790955136,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1527972070394166,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.004259631986186782,
            "feature_preprocessor:select_percentile_classification:percentile": 51.31805671221995,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2644512600508926,
        "time": 0.8162970542907715,
        "additional_info": {
            "duration": 0.8055689334869385,
            "num_run": 1148,
            "train_loss": 1.0594074892108225,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.018492097735254977,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010404099284989253,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.00012000543914393472,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1399,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6537971555348454,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2233474879067696,
        "time": 6.4789159297943115,
        "additional_info": {
            "duration": 6.466598272323608,
            "num_run": 1149,
            "train_loss": 1.0957897325890027,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0056871055183306185,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023312581075324284,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0005025707053811143,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 757,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.2115728980810414,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2311766433269442,
        "time": 5.432971000671387,
        "additional_info": {
            "duration": 5.421235799789429,
            "num_run": 1150,
            "train_loss": 1.0055060363608574,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1150,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.036896701558666256,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011467172405334584,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 0.0002047716987097335,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023140840226659853,
            "feature_preprocessor:select_rates_classification:alpha": 0.15323183803748502,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09715485572814941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1151,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009826457240571956,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20142116568724064,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 1.6810205319495143e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010774843775369116,
            "feature_preprocessor:select_rates_classification:alpha": 0.058401769033879926,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12505817413330078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.417723567444047e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.037812564385390275,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.004088998558056705,
            "feature_preprocessor:select_rates_classification:alpha": 0.4524061073632832,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09706592559814453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0024744940866648826,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6013812780883215,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 0.003909042812098752,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10226191444173639,
            "feature_preprocessor:select_rates_classification:alpha": 0.3234456226035389,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.231749637299387,
        "time": 0.6296048164367676,
        "additional_info": {
            "duration": 0.6136889457702637,
            "num_run": 1154,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00027456603553093845,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0044273991814339445,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 0.0001726721072590448,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006556165082747693,
            "feature_preprocessor:select_rates_classification:alpha": 0.1247762184692561,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2167836533154222,
        "time": 0.4305300712585449,
        "additional_info": {
            "duration": 0.41785383224487305,
            "num_run": 1155,
            "train_loss": 1.1757568094539983,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06836176610143654,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017741580969553247,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.00022464644360661016,
            "feature_preprocessor:select_percentile_classification:percentile": 23.420460517304445,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.294295072555542,
        "additional_info": {
            "duration": 0.28243422508239746,
            "num_run": 1156,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.010624287438699581,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10036738501402516,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 3.373558065294955e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013389892660929783,
            "feature_preprocessor:select_rates_classification:alpha": 0.10422818122280984,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12421488761901855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.016564028415810693,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05842734926672499,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.00024256037756715152,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03398771623087886,
            "feature_preprocessor:select_rates_classification:alpha": 0.11870780723885548,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12895822525024414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008639440496229911,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4714577827690919,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 3.467478362461405e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35107850967562,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1020958423614502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00016683039966409495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.045368254204169726,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.0004380536121046048,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0077183128451128605,
            "feature_preprocessor:select_rates_classification:alpha": 0.46923197386683085,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0978400707244873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005948997233123661,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034248571177953953,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.0004581644298169184,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012022871842126927,
            "feature_preprocessor:select_rates_classification:alpha": 0.1278316448897943,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16412115097045898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000400241941434304,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007228893381490184,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.008124026804117392,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010008944009187416,
            "feature_preprocessor:select_rates_classification:alpha": 0.06393763170175179,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09787917137145996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1162,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00015546360875102707,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6545532447734649,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 211,
            "classifier:CustomMLPClassifier:tol": 0.0029154837319108435,
            "feature_preprocessor:select_rates_classification:alpha": 0.4925831527241695,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2529075456199994,
        "time": 0.6765799522399902,
        "additional_info": {
            "duration": 0.6521260738372803,
            "num_run": 1163,
            "train_loss": 1.0165181090825721,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00017602241355099804,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13533438522587485,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 2.4987813906551686e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06771444681104653,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8431423148198521,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08707106098062165,
            "feature_preprocessor:select_rates_classification:alpha": 0.42751470391245094,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2431438050853088,
        "time": 0.3996601104736328,
        "additional_info": {
            "duration": 0.38639092445373535,
            "num_run": 1164,
            "train_loss": 1.1766957509597644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1164,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001170613829486795,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1598224586168679,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 4.417078406987256e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017793572840989525,
            "feature_preprocessor:select_percentile_classification:percentile": 62.43017631325368,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2270618732384688,
        "time": 0.8679389953613281,
        "additional_info": {
            "duration": 0.8566181659698486,
            "num_run": 1165,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.893638130191155e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1545516274204002,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.0035146168963644015,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029403957456227304,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9502488051522973,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03829896154662301,
            "feature_preprocessor:select_percentile_classification:percentile": 5.6815793865256135,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.23983526229858398,
        "additional_info": {
            "duration": 0.21726703643798828,
            "num_run": 1166,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1166,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001840290503811736,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000192343092313759,
            "classifier:CustomMLPClassifier:max_iter": 421,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.0005149067645194487,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 330,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 90.75473133224008,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.218231081685774,
        "time": 9.085357189178467,
        "additional_info": {
            "duration": 9.073980808258057,
            "num_run": 1167,
            "train_loss": 1.0016542803441228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.048113944100850785,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005738178454389687,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.00012763738856107798,
            "feature_preprocessor:select_rates_classification:alpha": 0.43914486434706385,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 1.1723439693450928,
        "additional_info": {
            "duration": 1.159430742263794,
            "num_run": 1168,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1168,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.601753752125661e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000707033467196183,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0025303246271689106,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7192171312214793,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.255793251392884,
        "time": 0.39827609062194824,
        "additional_info": {
            "duration": 0.38477110862731934,
            "num_run": 1169,
            "train_loss": 1.2121319375185213,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1169,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.028732232859643745,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021249303309731543,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 72,
            "classifier:CustomMLPClassifier:tol": 0.0006679482971731184,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002592978715889683,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.0450351931256493,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2444547070742105,
        "time": 1.6167759895324707,
        "additional_info": {
            "duration": 1.6045429706573486,
            "num_run": 1170,
            "train_loss": 1.0360459666480346,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1170,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1559343472719209e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09371244686048169,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 0.0004890750633846176,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004607806379608438,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20831877391218956,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.334368248022742,
        "time": 0.8904330730438232,
        "additional_info": {
            "duration": 0.8677880764007568,
            "num_run": 1171,
            "train_loss": 1.1264391355281909,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0031863609554371,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3772208581777013,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 0.00044136094547833794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021938145180828338,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8431530320719172,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 1.7474970817565918,
        "additional_info": {
            "duration": 1.7356750965118408,
            "num_run": 1172,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4563658292858363e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014718899203756343,
            "classifier:CustomMLPClassifier:max_iter": 241,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 1.2976189882750303e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022357364543937213,
            "feature_preprocessor:select_percentile_classification:percentile": 6.381011636189226,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 1.1982579231262207,
        "additional_info": {
            "duration": 1.1844229698181152,
            "num_run": 1173,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0006861237764845769,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014021524101274772,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.0029081983738405088,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.740786956853403,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2832803082347966,
            "feature_preprocessor:select_percentile_classification:percentile": 52.87415471980042,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.3435029983520508,
        "additional_info": {
            "duration": 0.32302212715148926,
            "num_run": 1174,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007199954770639365,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20518417055847216,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 381,
            "classifier:CustomMLPClassifier:tol": 0.00022544886921936117,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003829780315935224,
            "feature_preprocessor:select_percentile_classification:percentile": 3.473978063395533,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 1.417490005493164,
        "additional_info": {
            "duration": 1.404540777206421,
            "num_run": 1175,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1175,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00032259379906404023,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010501517080340474,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 0.0002076909103030741,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006586892425773413,
            "feature_preprocessor:select_rates_classification:alpha": 0.3072682505732428,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13123798370361328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.015700204436938814,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019503350850441233,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.0011907610683885744,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05006468892512977,
            "feature_preprocessor:select_rates_classification:alpha": 0.34242597915742007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12400221824645996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012674013138038182,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017508085420068055,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.000172501371384484,
            "feature_preprocessor:select_rates_classification:alpha": 0.25044468622534366,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.29091501235961914,
        "additional_info": {
            "duration": 0.2662007808685303,
            "num_run": 1178,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.013271285244214141,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0065067532303178304,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00027531532311402093,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17842349959954448,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.957774095360486,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09998356362240786,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6897942701927604,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2540133209164361,
        "time": 0.9582808017730713,
        "additional_info": {
            "duration": 0.9445521831512451,
            "num_run": 1179,
            "train_loss": 1.2101604199504317,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06532124094754525,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001960635074988395,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.00014575641384605414,
            "feature_preprocessor:select_rates_classification:alpha": 0.4264326269141078,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09819698333740234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1180,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.138359343520046e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9254258762008309,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 6.279760763598451e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 69.84866245050678,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.3221957858928928,
        "time": 0.9420490264892578,
        "additional_info": {
            "duration": 0.9317018985748291,
            "num_run": 1181,
            "train_loss": 1.327959555381139,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.3240885547243873e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006707644539137467,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 3.2992519262747945e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07010773842431738,
            "feature_preprocessor:select_percentile_classification:percentile": 10.575222153661269,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2490889777046288,
        "time": 1.1442439556121826,
        "additional_info": {
            "duration": 1.1272010803222656,
            "num_run": 1182,
            "train_loss": 1.2250864075723273,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1182,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00014119817319387855,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001507242156910023,
            "classifier:CustomMLPClassifier:max_iter": 392,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 0.009375431035785732,
            "feature_preprocessor:select_percentile_classification:percentile": 18.805310260562514,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.228618375086814,
        "time": 0.24745488166809082,
        "additional_info": {
            "duration": 0.2335660457611084,
            "num_run": 1183,
            "train_loss": 1.2121444761986102,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.05122287867405048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024869747140808862,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.0006413600791854107,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002956910589209255,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 284,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 10.492853957488045,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2462750672978817,
        "time": 0.8612029552459717,
        "additional_info": {
            "duration": 0.8507058620452881,
            "num_run": 1184,
            "train_loss": 1.2253979899438172,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1184,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007651346631471338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014474838802068207,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.00042564176989618683,
            "feature_preprocessor:select_rates_classification:alpha": 0.10319868178134269,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09610104560852051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.029794022138093606,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08461147072666866,
            "classifier:CustomMLPClassifier:max_iter": 356,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 0.004891778050583271,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014421314163843608,
            "feature_preprocessor:select_percentile_classification:percentile": 74.10280616736,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.243434899265317,
        "time": 1.3518931865692139,
        "additional_info": {
            "duration": 1.3417158126831055,
            "num_run": 1186,
            "train_loss": 1.0264622161659207,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1186,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.517908210858982e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01581498302396667,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.0004525734207574676,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7386284876593779,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29509835895424885,
            "feature_preprocessor:select_rates_classification:alpha": 0.19762571914886126,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2279493278998994,
        "time": 0.33597898483276367,
        "additional_info": {
            "duration": 0.3197941780090332,
            "num_run": 1187,
            "train_loss": 1.2028116096657198,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1187,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012705904507725248,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6008334262132996,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 3.191183143503766e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011171784988263534,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27914645106582514,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.3544638156890869,
        "additional_info": {
            "duration": 0.33150315284729004,
            "num_run": 1188,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.77650689597913e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05849615613987823,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 0.003313703299092224,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29773748427912805,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8085722625711983,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03462349629977426,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8903569242607651,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.239620374324669,
        "time": 0.39678502082824707,
        "additional_info": {
            "duration": 0.38401103019714355,
            "num_run": 1189,
            "train_loss": 1.1983544994370499,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1189,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005100238008173388,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020019937139290352,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.0004786550740182506,
            "feature_preprocessor:select_rates_classification:alpha": 0.24421650903915182,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10334587097167969,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0076313341438181415,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019467635953550953,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 6.621906929491444e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4190887638612825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09684205055236816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08861061814285373,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006498567308856581,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 5.0643162944896945e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 944,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.04338218088029358,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2907426812504996,
        "time": 1.051734209060669,
        "additional_info": {
            "duration": 1.0384421348571777,
            "num_run": 1192,
            "train_loss": 1.0609330259107101,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012894264183028354,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02180953980601351,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 1.6786870947903328e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7585765629445063,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15964539168021405,
            "feature_preprocessor:select_rates_classification:alpha": 0.3732234222437078,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2512660978827301,
        "time": 1.3758752346038818,
        "additional_info": {
            "duration": 1.3638179302215576,
            "num_run": 1193,
            "train_loss": 1.1205911675847107,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1193,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.947436203267285e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001653687192794098,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.001276404689033582,
            "feature_preprocessor:select_rates_classification:alpha": 0.4443351972970439,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 0.2158341407775879,
        "additional_info": {
            "duration": 0.1972489356994629,
            "num_run": 1194,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0029095170798287243,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012001400871995437,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.0016461493601516552,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10232515664192718,
            "feature_preprocessor:select_rates_classification:alpha": 0.18134977018778273,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.28937697410583496,
        "additional_info": {
            "duration": 0.2748568058013916,
            "num_run": 1195,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1195,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002645314778926358,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003937563986138748,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 1.784578760307752e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2595077193529829,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12536001205444336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1196,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4356793864324686e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005129212216084993,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 8.99505050786877e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 181,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 8.686152919721854,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.253885945502805,
        "time": 0.6128349304199219,
        "additional_info": {
            "duration": 0.6008529663085938,
            "num_run": 1197,
            "train_loss": 1.2333812746764627,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1197,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0004230322791045404,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00034634188800007864,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.00036371666962743275,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003152279668015994,
            "feature_preprocessor:select_rates_classification:alpha": 0.23867915505875154,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12460803985595703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1198,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.695951715694747e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015971972627979555,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 3.0325664592249026e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019888450256073308,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12422879650970076,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 0.4670400619506836,
        "additional_info": {
            "duration": 0.45507287979125977,
            "num_run": 1199,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0035752514098032584,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003128679848824895,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.0004903314568729594,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030512711655975307,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8943756664924516,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18053937885237345,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5484211439611149,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2778425705101393,
        "time": 3.09275221824646,
        "additional_info": {
            "duration": 3.075518846511841,
            "num_run": 1200,
            "train_loss": 1.1076497481854042,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1200,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00012471150955066304,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6998458550168902,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 5.035362045797472e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11111490416114217,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1243278980255127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1201,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012529955518423943,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001637592591179929,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0001661002167877887,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0040400281196440145,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9825330774587075,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04017078479187931,
            "feature_preprocessor:select_percentile_classification:percentile": 13.831813932167433,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2589234485870828,
        "time": 0.5878760814666748,
        "additional_info": {
            "duration": 0.5610268115997314,
            "num_run": 1202,
            "train_loss": 1.2297064710484602,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7430500889181478e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013990241181052954,
            "classifier:CustomMLPClassifier:max_iter": 269,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.0008838055214526355,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5212042817032434,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.254058858656756,
        "time": 0.5912520885467529,
        "additional_info": {
            "duration": 0.5768938064575195,
            "num_run": 1203,
            "train_loss": 1.1848645638559796,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1203,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00022557152099387476,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011565042381073577,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.005429746479236863,
            "feature_preprocessor:select_percentile_classification:percentile": 19.625927252765358,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2427606572457963,
        "time": 0.2927591800689697,
        "additional_info": {
            "duration": 0.27941465377807617,
            "num_run": 1204,
            "train_loss": 1.2387101761648625,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1204,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002053862216586057,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2874693220204019,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.00019404222371788307,
            "feature_preprocessor:select_rates_classification:alpha": 0.014822152126579568,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1301882266998291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1205,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0023177791719683274,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1637772629701978,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 0.007320442260904644,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011642111980225111,
            "feature_preprocessor:select_rates_classification:alpha": 0.3329379572213302,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0969839096069336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00023464839097735044,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17317139686741773,
            "classifier:CustomMLPClassifier:max_iter": 195,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 6.519856271562599e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8926631130413797,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1912055403606982,
            "feature_preprocessor:select_percentile_classification:percentile": 1.953750319779993,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.36446189880371094,
        "additional_info": {
            "duration": 0.35385608673095703,
            "num_run": 1207,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008664127710995596,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001907835084137761,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.005708937380408037,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04819571547342034,
            "feature_preprocessor:select_rates_classification:alpha": 0.447101281048022,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0969381332397461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1208,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3762349336535253e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013748865367238527,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.000885071036887264,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9349595287173866,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10663862275250564,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7467675406935433,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.24487317666785,
        "time": 0.5382709503173828,
        "additional_info": {
            "duration": 0.5238761901855469,
            "num_run": 1209,
            "train_loss": 1.1734793643668961,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1209,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004074164791241924,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009932084329393076,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.00058107801428609,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4329695593880182,
            "feature_preprocessor:select_percentile_classification:percentile": 97.8808645097601,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2355784212009506,
        "time": 0.8748888969421387,
        "additional_info": {
            "duration": 0.8630659580230713,
            "num_run": 1210,
            "train_loss": 1.1741688823846188,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1210,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.010384538521564115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012995228810102637,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 3.6070663881773284e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39214018324424493,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09786295890808105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02674250596716726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026788216776930263,
            "classifier:CustomMLPClassifier:max_iter": 375,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.00015487129977931495,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02426363393025,
            "feature_preprocessor:select_rates_classification:alpha": 0.36720589315551544,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13048768043518066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.413727557940049e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.824642442189266,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.008675423371266039,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00991673835164114,
            "feature_preprocessor:select_rates_classification:alpha": 0.40199319375816095,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12949180603027344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1213,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.710295114867109e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021270474423580703,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 0.0007572547456270913,
            "feature_preprocessor:select_rates_classification:alpha": 0.09529067114827323,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12392759323120117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1214,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00012424613552866986,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014653649319813281,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0003891281990831881,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7131661035845696,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12846621636942626,
            "feature_preprocessor:select_percentile_classification:percentile": 51.94287002218565,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2307712808363362,
        "time": 3.8982179164886475,
        "additional_info": {
            "duration": 3.8871030807495117,
            "num_run": 1215,
            "train_loss": 1.2010526655484506,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.019775169893456682,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013539363280679867,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.000580993287375526,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015128553699914612,
            "feature_preprocessor:select_rates_classification:alpha": 0.04356125612355631,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12384366989135742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1216,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.019477036949379783,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009902121603702756,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 8.885217707101894e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 30.80889479163473,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.39337682723999023,
        "additional_info": {
            "duration": 0.38036203384399414,
            "num_run": 1217,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1217,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02958600539063069,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010901994115067388,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 0.003119415435830729,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005844346242155812,
            "feature_preprocessor:select_percentile_classification:percentile": 7.905648079599578,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2419369120010586,
        "time": 0.2529420852661133,
        "additional_info": {
            "duration": 0.23593497276306152,
            "num_run": 1218,
            "train_loss": 1.2379475235579411,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1218,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008096620766555338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021555828252766118,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.00016837539580890644,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09559968606093831,
            "feature_preprocessor:select_rates_classification:alpha": 0.49238261839707914,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12442588806152344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.316452439985557e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07103750532651999,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 240,
            "classifier:CustomMLPClassifier:tol": 0.0024216744661405263,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003257384805997434,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8707129356952246,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10315116409459872,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14410570638325848,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2499440885682809,
        "time": 0.3546299934387207,
        "additional_info": {
            "duration": 0.3421189785003662,
            "num_run": 1220,
            "train_loss": 1.200021549947307,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1220,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.200627638758292e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015786443941744825,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 116,
            "classifier:CustomMLPClassifier:tol": 3.352669009287438e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.020230663458180052,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12392187118530273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1221,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004162112544779589,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004376007392272722,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 1.8646747880380777e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09532435220432847,
            "feature_preprocessor:select_rates_classification:alpha": 0.17151411029171926,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0976419448852539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009463839477151183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024026260857749785,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0008318340512195012,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12061575030158732,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12242828458954313,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3214135788335077,
        "time": 1.5796611309051514,
        "additional_info": {
            "duration": 1.55889892578125,
            "num_run": 1223,
            "train_loss": 1.0317366395697787,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1223,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009504761970666176,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005951417435753195,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.00029617411353989126,
            "feature_preprocessor:select_rates_classification:alpha": 0.48092300407507427,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10259032249450684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1224,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.0304335510684474e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001704464427473662,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.0006641200280905865,
            "feature_preprocessor:select_rates_classification:alpha": 0.3826814170499681,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2558660249378861,
        "time": 5.542510986328125,
        "additional_info": {
            "duration": 5.530719995498657,
            "num_run": 1225,
            "train_loss": 1.0033085606882457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1225,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.435191684256999e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.29629016342426795,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.0004027926915809429,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03547961857046058,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.46672452015392507,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231749637299387,
        "time": 1.5559370517730713,
        "additional_info": {
            "duration": 1.5439341068267822,
            "num_run": 1226,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1226,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.820326976588879e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6024612111007803,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 8.063618306656461e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00026408695402736423,
            "feature_preprocessor:select_rates_classification:alpha": 0.02617193028572777,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.4916514423495206,
        "time": 0.33492374420166016,
        "additional_info": {
            "duration": 0.3212008476257324,
            "num_run": 1227,
            "train_loss": 1.4922682139998318,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1227,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.449553163644066e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034238155489624044,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.00012104799530259769,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012587224907919232,
            "feature_preprocessor:select_rates_classification:alpha": 0.10360774725432957,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10168099403381348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.08874494630212e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008125751265631598,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 1.36974022622586e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4131754067081567,
            "feature_preprocessor:select_rates_classification:alpha": 0.4216841679224815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12845897674560547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07578566482417227,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2611116450394507,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 345,
            "classifier:CustomMLPClassifier:tol": 2.1685919724057733e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4317010207065637,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09653687477111816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004262964507666202,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10237022727329259,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 7.119075597335147e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7533678380057522,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2626688673040091,
            "feature_preprocessor:select_percentile_classification:percentile": 36.66571455357041,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2418328596766521,
        "time": 1.5489661693572998,
        "additional_info": {
            "duration": 1.5372397899627686,
            "num_run": 1231,
            "train_loss": 1.0983291398442374,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1231,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.211753864290289e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012542283600602763,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.00035974257644548816,
            "feature_preprocessor:select_rates_classification:alpha": 0.12112196391773092,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12912607192993164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1232,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.149525491268305e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014080339931535283,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 0.00032281813662970386,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015062302432032344,
            "feature_preprocessor:select_rates_classification:alpha": 0.42959386409983646,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2370258061515476,
        "time": 0.4911508560180664,
        "additional_info": {
            "duration": 0.48038673400878906,
            "num_run": 1233,
            "train_loss": 1.1909744939675921,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1233,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011881322047574198,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7899979555224391,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 288,
            "classifier:CustomMLPClassifier:tol": 8.699161208169015e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20280581315367588,
            "feature_preprocessor:select_rates_classification:alpha": 0.20754932474365503,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12344908714294434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1234,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005435749791674932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15126381524977175,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 4.7218924004126055e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020509281688106607,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8978946719042427,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2706642471807514,
        "time": 0.3997209072113037,
        "additional_info": {
            "duration": 0.37607693672180176,
            "num_run": 1235,
            "train_loss": 1.1003369419643023,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.7678365289325625e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004308065294184231,
            "classifier:CustomMLPClassifier:max_iter": 421,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 4.638568329034013e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06745956080926663,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7186675526246733,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2893938032478126,
            "feature_preprocessor:select_percentile_classification:percentile": 42.649398597220824,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.241536744343057,
        "time": 1.0081522464752197,
        "additional_info": {
            "duration": 0.9901788234710693,
            "num_run": 1236,
            "train_loss": 1.1788025620004987,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1236,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004551768627315146,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.523775154122549,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 2.4389893681957128e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 34.707722038118625,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.281160874578314,
        "time": 1.913874864578247,
        "additional_info": {
            "duration": 1.8998899459838867,
            "num_run": 1237,
            "train_loss": 1.1434665598267086,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1237,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001038206287078945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00545895026685957,
            "classifier:CustomMLPClassifier:max_iter": 321,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 0.005844502269157104,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019112973839869995,
            "feature_preprocessor:select_rates_classification:alpha": 0.12897048063269156,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09635400772094727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002179038763984819,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013516288548129887,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.003007112433445245,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05792705525799776,
            "feature_preprocessor:select_rates_classification:alpha": 0.38087779816248385,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.5353939533233643,
        "additional_info": {
            "duration": 0.5240240097045898,
            "num_run": 1239,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1239,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.5986308568734707e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4090088697792963,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 1.9493030050616205e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2468031878778074,
            "feature_preprocessor:select_rates_classification:alpha": 0.07349259862386269,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12852907180786133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1240,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.5361930265482165e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5115813615265703,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 98,
            "classifier:CustomMLPClassifier:tol": 0.00010729425742967939,
            "feature_preprocessor:select_rates_classification:alpha": 0.14845261316078953,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1285848617553711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009013013052173058,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16317196701881417,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.0009329178603435294,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004803200619964066,
            "feature_preprocessor:select_percentile_classification:percentile": 22.537274578816703,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.231749637299387,
        "time": 0.28024983406066895,
        "additional_info": {
            "duration": 0.26282596588134766,
            "num_run": 1242,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1242,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009571451114757447,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14898518383302933,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 1.606055458278568e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04634444603909107,
            "feature_preprocessor:select_rates_classification:alpha": 0.33606193349906527,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12473201751708984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.077376162470504e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015118369159703008,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 9.344097994540068e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005458022714129005,
            "feature_preprocessor:select_rates_classification:alpha": 0.303240601112837,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1244359016418457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.831219320640697e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0063211165001185515,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 1.4392536991174248e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011505566550188521,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1867,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 72.49966097147994,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2308905703005226,
        "time": 8.946913957595825,
        "additional_info": {
            "duration": 8.935730934143066,
            "num_run": 1245,
            "train_loss": 1.0082898267392255,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1245,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011899121784316926,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034082123128306805,
            "classifier:CustomMLPClassifier:max_iter": 253,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 0.0005977601620538863,
            "feature_preprocessor:select_rates_classification:alpha": 0.38735796641121334,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12961268424987793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1246,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.013730512048075395,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010841645592159685,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.002872220690934352,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25487279147982095,
            "feature_preprocessor:select_rates_classification:alpha": 0.3864202864460814,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10175204277038574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1247,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.511680430000232e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004141277576770324,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 0.004424930985725607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16215557843309622,
            "feature_preprocessor:select_rates_classification:alpha": 0.37377700890719695,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09621691703796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1248,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03321941989557998,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018632415421544282,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.00277094823010634,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1210137904722513,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1313,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 52.090481375489205,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2666445521278833,
        "time": 0.6651251316070557,
        "additional_info": {
            "duration": 0.654041051864624,
            "num_run": 1249,
            "train_loss": 1.1957660864660253,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004551344140041255,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00128145737356258,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 1.0813792309151841e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019711955308119244,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.32459378818800166,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2205890707080063,
        "time": 2.5531601905822754,
        "additional_info": {
            "duration": 2.540037155151367,
            "num_run": 1250,
            "train_loss": 1.1892592837151577,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1250,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.167147683589495e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5906683124002562,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 4.689200758936845e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3861039531378964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2508133281335834,
        "time": 1.0686030387878418,
        "additional_info": {
            "duration": 1.0564758777618408,
            "num_run": 1251,
            "train_loss": 1.0601094433954774,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1251,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.7548678477808915e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019663563362648878,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.0002831316391868997,
            "feature_preprocessor:select_percentile_classification:percentile": 6.007869914608886,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.8085589408874512,
        "additional_info": {
            "duration": 0.7957301139831543,
            "num_run": 1252,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1252,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09276160405989106,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0117093217347599,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 5.597624410835014e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25551510068276007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12313127517700195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2358559615800171e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08808253440602902,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.0007624861332918649,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08382307528765287,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7376032016684814,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2452279368447963,
        "time": 0.8007102012634277,
        "additional_info": {
            "duration": 0.7856838703155518,
            "num_run": 1254,
            "train_loss": 1.2192128992965783,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1254,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002290007247972785,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9932731281204957,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.006809889155350515,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015077077851454368,
            "feature_preprocessor:select_rates_classification:alpha": 0.3970980028300768,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12385106086730957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1255,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.764307501287536e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027063869181532884,
            "classifier:CustomMLPClassifier:max_iter": 274,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.003600019556244855,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017290606616753423,
            "feature_preprocessor:select_rates_classification:alpha": 0.4987868204551603,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12975406646728516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1256,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.018363415690868953,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002111670569668789,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.005029840706970181,
            "feature_preprocessor:select_rates_classification:alpha": 0.18006490270793424,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12918519973754883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1129028966727454e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3886482839407546,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.00011818251308776509,
            "feature_preprocessor:select_rates_classification:alpha": 0.1319367079757382,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.231749637299387,
        "time": 1.109281063079834,
        "additional_info": {
            "duration": 1.0943222045898438,
            "num_run": 1258,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1258,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07985271895940393,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007075573296883889,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 4.380187634709825e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003041109133115735,
            "feature_preprocessor:select_percentile_classification:percentile": 31.606971268826864,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2311169768849735,
        "time": 2.7099215984344482,
        "additional_info": {
            "duration": 2.6981351375579834,
            "num_run": 1259,
            "train_loss": 1.185870985098467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1259,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004108166213376945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015886805813988956,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.007415664026006891,
            "feature_preprocessor:select_rates_classification:alpha": 0.33291101991787037,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0972740650177002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1260,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.4638901478083985e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007985704087646402,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 0.0054543083859755126,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05664888972536253,
            "feature_preprocessor:select_rates_classification:alpha": 0.3369420220990874,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09723186492919922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1261,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006418498892732275,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007766271191769245,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 167,
            "classifier:CustomMLPClassifier:tol": 0.0009483851571702447,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013561559859996697,
            "feature_preprocessor:select_rates_classification:alpha": 0.207164934983359,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1294848918914795,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1262,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7367525584347984e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000380044291741723,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 0.00012561427512818095,
            "feature_preprocessor:select_rates_classification:alpha": 0.4850519328719889,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2266616187409574,
        "time": 7.7051403522491455,
        "additional_info": {
            "duration": 7.691076993942261,
            "num_run": 1263,
            "train_loss": 1.1556057871455563,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.727156871385012e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012791680734656015,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0005489847986553766,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1316,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6780213956289423,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2208711875992153,
        "time": 1.0551648139953613,
        "additional_info": {
            "duration": 1.0386388301849365,
            "num_run": 1264,
            "train_loss": 1.1589208486598919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011640885552798958,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011864551481058068,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 1.1749896059151658e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8153184825773,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17519146520319284,
            "feature_preprocessor:select_rates_classification:alpha": 0.4185883164575048,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.286095260097295,
        "time": 6.636838912963867,
        "additional_info": {
            "duration": 6.622522830963135,
            "num_run": 1265,
            "train_loss": 1.0305773948119676,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1265,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009785713178089527,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05229208795743296,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.0014408073865546747,
            "feature_preprocessor:select_percentile_classification:percentile": 47.699588413340415,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.268547771623485,
        "time": 1.7083840370178223,
        "additional_info": {
            "duration": 1.697988748550415,
            "num_run": 1266,
            "train_loss": 1.0305646246458333,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1266,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.1122949548814567e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.048266991528237706,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 129,
            "classifier:CustomMLPClassifier:tol": 0.00191670545143659,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18325998396516646,
            "feature_preprocessor:select_rates_classification:alpha": 0.29483229552055723,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09700703620910645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00019450496476092996,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009089092319027681,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 1.5978449197493186e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008130623148559195,
            "feature_preprocessor:select_percentile_classification:percentile": 82.80405613670975,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2499258734721528,
        "time": 3.2709388732910156,
        "additional_info": {
            "duration": 3.255896806716919,
            "num_run": 1268,
            "train_loss": 1.0041449133696128,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1268,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06531015196032056,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010366497520513898,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.005505371800066266,
            "feature_preprocessor:select_rates_classification:alpha": 0.10220622128744121,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09689688682556152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1269,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07904364909620491,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3614631828926676,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 123,
            "classifier:CustomMLPClassifier:tol": 6.508930218486029e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002606712120401796,
            "feature_preprocessor:select_rates_classification:alpha": 0.2851791987931822,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09625005722045898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1270,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008513629388639966,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016622106395460122,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 0.0023348431878742653,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0063041844548043765,
            "feature_preprocessor:select_percentile_classification:percentile": 1.7577644174063136,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.231749637299387,
        "time": 0.4385719299316406,
        "additional_info": {
            "duration": 0.41922879219055176,
            "num_run": 1271,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1271,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02047050971514729,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011084737035157508,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 0.009935441038408913,
            "feature_preprocessor:select_rates_classification:alpha": 0.07370106048070754,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12406015396118164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00019874801997602214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036656780344494,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.0008646684752414824,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3957750308586759,
            "feature_preprocessor:select_rates_classification:alpha": 0.2992576105643987,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10157394409179688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1273,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011432386455595109,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015937228710486852,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 4.5011145128547675e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2779204025360511,
            "feature_preprocessor:select_rates_classification:alpha": 0.3656716148250355,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1292400360107422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1274,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0016867987823981875,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018061352862133537,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 1.6042837164271743e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2845605972115295,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15881586074829102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1275,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.015008244119844423,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27857674434275753,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 0.00011705774241231141,
            "feature_preprocessor:select_rates_classification:alpha": 0.41425980387428163,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.128662109375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0015051125992959742,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3280912144337987,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 0.0035712781043116012,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010142385288382318,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11774072161254412,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2624802881638755,
        "time": 0.6564030647277832,
        "additional_info": {
            "duration": 0.645226001739502,
            "num_run": 1277,
            "train_loss": 1.1866092773459342,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1277,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.878003253204729e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00048551327127344373,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 117,
            "classifier:CustomMLPClassifier:tol": 1.2809497233548649e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09144409447149655,
            "feature_preprocessor:select_rates_classification:alpha": 0.3716208540319045,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13600420951843262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1278,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.214091152669586e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002328574265755747,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.00014617032742186132,
            "feature_preprocessor:select_rates_classification:alpha": 0.09730950028488519,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.22753085830626,
        "time": 3.8213140964508057,
        "additional_info": {
            "duration": 3.750234842300415,
            "num_run": 1279,
            "train_loss": 1.1716719800190845,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005889897765180646,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026070075240515926,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0018943646591186988,
            "feature_preprocessor:select_rates_classification:alpha": 0.48011939710041945,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12460923194885254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1280,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.4092839666270904e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004163124405440028,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.0006510775115959065,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.48724013967049185,
            "feature_preprocessor:select_rates_classification:alpha": 0.11521765699667634,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16012001037597656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1281,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2246632159336435e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010622633283507426,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 4.647446065677987e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0070209261447154074,
            "feature_preprocessor:select_rates_classification:alpha": 0.2668523326077749,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15920519828796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002161684812331917,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024714058955536237,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 6.375146715795688e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 76.35474041164744,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.231749637299387,
        "time": 0.42508792877197266,
        "additional_info": {
            "duration": 0.4099597930908203,
            "num_run": 1283,
            "train_loss": 1.231599248177194,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1283,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00032871826919469576,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008385773957864807,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 8.699042684309253e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031873370857997503,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.30866184447250455,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2383367515602042,
        "time": 3.7046761512756348,
        "additional_info": {
            "duration": 3.6933538913726807,
            "num_run": 1284,
            "train_loss": 1.0286356119674436,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1284,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4328671159140562e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0725587130942815,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 3.8648061722536783e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001667066520713493,
            "feature_preprocessor:select_percentile_classification:percentile": 64.07456473829251,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2519059529072338,
        "time": 3.271859884262085,
        "additional_info": {
            "duration": 3.258975028991699,
            "num_run": 1285,
            "train_loss": 1.0444645370314953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1285,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012831937109674564,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002043252244196973,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 2.160403299234298e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4511149918601786,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]