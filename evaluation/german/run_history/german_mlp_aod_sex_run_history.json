[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 0.0001,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.23482066536358,
        "time": 18.00822401046753,
        "additional_info": {
            "duration": 17.99266791343689,
            "num_run": 2,
            "train_loss": 1.1868935005246735,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005897913068713326,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015283020493786284,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 1.4677592009332837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009994383306256792,
            "feature_preprocessor:select_percentile_classification:percentile": 83.71076102633408,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3062300682067871,
        "additional_info": {
            "duration": 0.2937920093536377,
            "num_run": 3,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017335374469244055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21446023234155723,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 393,
            "classifier:CustomMLPClassifier:tol": 0.00020669606778637786,
            "feature_preprocessor:select_rates_classification:alpha": 0.37074326113847605,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.330524206161499,
        "additional_info": {
            "duration": 0.31842708587646484,
            "num_run": 4,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001265432263937216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025210486300051585,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 1.3134515968729273e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.886128143254935,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.6398811340332031,
        "additional_info": {
            "duration": 0.6278636455535889,
            "num_run": 5,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.476537348642138e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6094187968363136,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.000623601061960284,
            "feature_preprocessor:select_rates_classification:alpha": 0.37277199716070397,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3566648838137476,
        "time": 0.32760119438171387,
        "additional_info": {
            "duration": 0.31609010696411133,
            "num_run": 6,
            "train_loss": 1.2939871231405573,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.150721995132133e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010880231565364893,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0032008478454880612,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034494424153546144,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8627567984926874,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2249954133836727,
        "time": 0.5970380306243896,
        "additional_info": {
            "duration": 0.5860841274261475,
            "num_run": 7,
            "train_loss": 1.164643908036863,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.1977691813522454e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.44966367306334676,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.005806128069380193,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008876578344611543,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 93,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27320045729587017,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.2795419692993164,
        "additional_info": {
            "duration": 0.25566697120666504,
            "num_run": 8,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03859643951467421,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07212176876171598,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.003501543999506037,
            "feature_preprocessor:select_percentile_classification:percentile": 48.494598649907545,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2124892166857557,
        "time": 0.5616898536682129,
        "additional_info": {
            "duration": 0.5507183074951172,
            "num_run": 9,
            "train_loss": 1.1716922192714825,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0064573490471085985,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004381518149923512,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.0002733700584522358,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06150456670879498,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.855583339746374,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.523522138595581,
        "additional_info": {
            "duration": 0.5096681118011475,
            "num_run": 10,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2113387883960955e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008793932152283769,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 1.5270282363522163e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2921157922639459,
            "feature_preprocessor:select_percentile_classification:percentile": 17.667740711447795,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.214165197035013,
        "time": 4.517632961273193,
        "additional_info": {
            "duration": 4.5069639682769775,
            "num_run": 11,
            "train_loss": 1.2165467901713856,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.723027284717073e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.505587032871814,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 5.6354003801170204e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9722544287969952,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21522768778089335,
            "feature_preprocessor:select_rates_classification:alpha": 0.1812799335421737,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2331954747314444,
        "time": 0.3077230453491211,
        "additional_info": {
            "duration": 0.296525239944458,
            "num_run": 12,
            "train_loss": 1.2177232097175963,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005361952847079068,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011012897402261086,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 8.120553078461216e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 23.289027264858984,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2134377903378015,
        "time": 2.6283838748931885,
        "additional_info": {
            "duration": 2.616950035095215,
            "num_run": 13,
            "train_loss": 1.2162737597692643,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002779215751559284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002052279313576921,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 4.116955514663134e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 39.16778744670719,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.33304286003112793,
        "additional_info": {
            "duration": 0.31799888610839844,
            "num_run": 14,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.686481604786295e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.054332432955243905,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 2.3496137045046023e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8317715881374931,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24110913203175488,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5283974514604716,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2074039779954808,
        "time": 2.0177228450775146,
        "additional_info": {
            "duration": 2.0050971508026123,
            "num_run": 15,
            "train_loss": 1.0168179967702369,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007752166389076693,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06722484548312682,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.0025181867137596295,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08116053779573892,
            "feature_preprocessor:select_percentile_classification:percentile": 54.9019124591008,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2037037216937791,
        "time": 0.8205268383026123,
        "additional_info": {
            "duration": 0.8090040683746338,
            "num_run": 16,
            "train_loss": 1.0582324522473934,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011420891327545342,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15285417771432422,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 8.544752612283777e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00043907243118199927,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1925,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8629428661328159,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2337014834086286,
        "time": 0.4278419017791748,
        "additional_info": {
            "duration": 0.41570472717285156,
            "num_run": 17,
            "train_loss": 1.0928741721648716,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03138488420936836,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11690391070562885,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 0.0035360559992481944,
            "feature_preprocessor:select_percentile_classification:percentile": 54.46952194157422,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.6493551731109619,
        "additional_info": {
            "duration": 0.6344528198242188,
            "num_run": 18,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001642031670092218,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08869346676875478,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.00030104461060828744,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006596089836632878,
            "feature_preprocessor:select_percentile_classification:percentile": 52.59891834015377,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2154937853140417,
        "time": 2.3117029666900635,
        "additional_info": {
            "duration": 2.2989308834075928,
            "num_run": 19,
            "train_loss": 1.0481285142284509,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.021512398796104077,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010480865873692458,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.0030059076673326973,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005854804398710105,
            "feature_preprocessor:select_percentile_classification:percentile": 67.38900991093244,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2226037824441764,
        "time": 0.7927360534667969,
        "additional_info": {
            "duration": 0.7813498973846436,
            "num_run": 20,
            "train_loss": 1.1757005137113143,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01533960081597022,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016833276201700192,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.002301570686726288,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_percentile_classification:percentile": 57.964992305140235,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2185258591178592,
        "time": 0.5243260860443115,
        "additional_info": {
            "duration": 0.5135748386383057,
            "num_run": 21,
            "train_loss": 1.1695910133696008,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004960580765379055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05863342751662861,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 1.4677592009332837e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 81.46528951790268,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.252510350644626,
        "time": 2.1622977256774902,
        "additional_info": {
            "duration": 2.149613857269287,
            "num_run": 22,
            "train_loss": 1.0048202048815327,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001063675820408188,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012115818862528132,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.0038800128981615715,
            "feature_preprocessor:select_rates_classification:alpha": 0.38576737012295403,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2177263160282206,
        "time": 0.647730827331543,
        "additional_info": {
            "duration": 0.6367428302764893,
            "num_run": 23,
            "train_loss": 1.1841951224105096,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09315244137295575,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008519907704876778,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 0.0013352336641514037,
            "feature_preprocessor:select_percentile_classification:percentile": 90.47139259729751,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.4568040370941162,
        "additional_info": {
            "duration": 0.44330382347106934,
            "num_run": 24,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0006870742363572371,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4037185866491964,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.0018392207734121023,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1199,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.704119053409123,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2778292498259947,
        "time": 0.745934009552002,
        "additional_info": {
            "duration": 0.7342803478240967,
            "num_run": 25,
            "train_loss": 1.1419899354816598,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004125423562300409,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06621301606439244,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.001349718941250272,
            "feature_preprocessor:select_rates_classification:alpha": 0.37082392114483465,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.15907883644104004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0019187709670943518,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004413389530545715,
            "classifier:CustomMLPClassifier:max_iter": 295,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.006474633515920001,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037333047491316065,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8924217463408829,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2459552194633422,
            "feature_preprocessor:select_percentile_classification:percentile": 17.11177960975307,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2241707217684383,
        "time": 0.2599191665649414,
        "additional_info": {
            "duration": 0.24773883819580078,
            "num_run": 27,
            "train_loss": 1.1877061198052081,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0318134301333368e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020528437136733063,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 0.0031455324877041812,
            "feature_preprocessor:select_percentile_classification:percentile": 52.39493438955972,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.3536052703857422,
        "additional_info": {
            "duration": 0.3432598114013672,
            "num_run": 28,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.254018750907294e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021963775831353397,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 5.6200168626950576e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1998199954426827,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09431195259094238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006955657592535976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05145746000620704,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.004912368967559607,
            "feature_preprocessor:select_rates_classification:alpha": 0.14941551295851582,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2018251558099213,
        "time": 1.6558549404144287,
        "additional_info": {
            "duration": 1.6458320617675781,
            "num_run": 30,
            "train_loss": 1.0251366696797473,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.598127843312343e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020378106397147378,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 0.00039772458738470795,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9102623706119318,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2204678709659316,
        "time": 1.4167397022247314,
        "additional_info": {
            "duration": 1.4014010429382324,
            "num_run": 31,
            "train_loss": 1.1765236659586973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3079435966298017e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005498514847912083,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 0.005603213263101593,
            "feature_preprocessor:select_rates_classification:alpha": 0.4567610632544912,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12183594703674316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.98868155740909e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4741491750708343,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.006949780864338591,
            "feature_preprocessor:select_rates_classification:alpha": 0.4162126786716872,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.31870508193969727,
        "additional_info": {
            "duration": 0.3009767532348633,
            "num_run": 33,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.438627060002214e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017407311124045418,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 0.001665136318353441,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0027100316704321416,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 710,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2840890548075356,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1994591592762749,
        "time": 0.6726479530334473,
        "additional_info": {
            "duration": 0.6603083610534668,
            "num_run": 34,
            "train_loss": 1.1574340943205255,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.089701055905224e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4942302292023903,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 5.996891537416588e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.19346681028994311,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.9836709499359131,
        "additional_info": {
            "duration": 0.9702529907226562,
            "num_run": 35,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006955657592535976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05145746000620704,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.006180400581298693,
            "feature_preprocessor:select_rates_classification:alpha": 0.18833860742422254,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226552701828675,
        "time": 0.523961067199707,
        "additional_info": {
            "duration": 0.5094549655914307,
            "num_run": 36,
            "train_loss": 1.1616821821858512,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.609010435318872e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021245861704217504,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 1.3329874074969615e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006177642006617294,
            "feature_preprocessor:select_rates_classification:alpha": 0.04375011470797723,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.89823317527771,
        "additional_info": {
            "duration": 0.8846280574798584,
            "num_run": 37,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.603235861374549e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3822000314804822,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 6.924103210460333e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006142998397136532,
            "feature_preprocessor:select_rates_classification:alpha": 0.32818451692071,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.5588998794555664,
        "additional_info": {
            "duration": 0.5478391647338867,
            "num_run": 38,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003155072828718012,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001800746936268286,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.00415404282601998,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003010642809642634,
            "feature_preprocessor:select_rates_classification:alpha": 0.4774683969758961,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.3580658435821533,
        "additional_info": {
            "duration": 0.34650301933288574,
            "num_run": 39,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.015975719661528585,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017102361286122303,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.00013564672158361698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 882,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 47.46344453986244,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.219138796806649,
        "time": 7.415811777114868,
        "additional_info": {
            "duration": 7.404879808425903,
            "num_run": 40,
            "train_loss": 1.1809020796988803,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0023420901561305566,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004698529139719123,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 5.424094742331535e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 208,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2038343182871888,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2550190462242952,
        "time": 0.7735779285430908,
        "additional_info": {
            "duration": 0.761577844619751,
            "num_run": 41,
            "train_loss": 1.1008434995306726,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.8787033470542656e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6604289332006917,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 0.00043582130707767896,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005878878553913627,
            "feature_preprocessor:select_percentile_classification:percentile": 34.81360143510897,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.48181891441345215,
        "additional_info": {
            "duration": 0.4660942554473877,
            "num_run": 42,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0331606532426857e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009223961714166942,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 7.264010281894934e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 92.6690574419308,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.217224290134108,
        "time": 0.8987462520599365,
        "additional_info": {
            "duration": 0.8813152313232422,
            "num_run": 43,
            "train_loss": 1.149579762310464,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0034878283090569754,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027730960520363395,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 0.0013250372518860106,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0029127118998661782,
            "feature_preprocessor:select_percentile_classification:percentile": 30.958991231408277,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2201945463687387,
        "time": 0.3485748767852783,
        "additional_info": {
            "duration": 0.3387420177459717,
            "num_run": 44,
            "train_loss": 1.2309045094585485,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014864635584740011,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1616836771771392,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 0.001117374915318013,
            "feature_preprocessor:select_rates_classification:alpha": 0.23049899322119266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12783002853393555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4950872708696655e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003873143718401813,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 0.008114269212939465,
            "feature_preprocessor:select_rates_classification:alpha": 0.3465852735937649,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12677669525146484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.123961457558206e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008163690750298437,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.0007024884681344205,
            "feature_preprocessor:select_rates_classification:alpha": 0.4666712140010712,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12211823463439941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.751856181510738e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3781890802120992,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 5.6354003801170204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.24458562036049317,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12140297889709473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.022211333584851993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004914953136880002,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 2.0142100349181724e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12082178971528813,
            "feature_preprocessor:select_rates_classification:alpha": 0.019671403208193897,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2347734453006096,
        "time": 1.4307901859283447,
        "additional_info": {
            "duration": 1.419905662536621,
            "num_run": 49,
            "train_loss": 1.1942597660119334,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.576810629188829e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014521706100707732,
            "classifier:CustomMLPClassifier:max_iter": 133,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.0005138760165056591,
            "feature_preprocessor:select_percentile_classification:percentile": 84.98352628079691,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2150422977148283,
        "time": 1.8569390773773193,
        "additional_info": {
            "duration": 1.8470098972320557,
            "num_run": 50,
            "train_loss": 1.1316525423090578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.196918686208768e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002760280148971427,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 0.0005060979161748774,
            "feature_preprocessor:select_percentile_classification:percentile": 82.46423657401962,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2241702392810228,
        "time": 4.777162075042725,
        "additional_info": {
            "duration": 4.767293930053711,
            "num_run": 51,
            "train_loss": 1.0043336576642963,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.8070032397566802e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009595303684551361,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 0.0036320299331507187,
            "feature_preprocessor:select_percentile_classification:percentile": 84.82398422776104,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1823504514165148,
        "time": 1.9652397632598877,
        "additional_info": {
            "duration": 1.955456018447876,
            "num_run": 52,
            "train_loss": 1.0058351859159196,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.780473858433314e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008587854111366081,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.0018537664733847838,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.521799646762026,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.235891912572006,
        "time": 0.42021679878234863,
        "additional_info": {
            "duration": 0.4061391353607178,
            "num_run": 53,
            "train_loss": 1.172486014285672,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9275478570378195e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025826774823489856,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 59,
            "classifier:CustomMLPClassifier:tol": 0.0007024884681344205,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.47476718862393025,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12660813331604004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.6325771513344094e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2439655734804164,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.00012299241603099003,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.013781330939433123,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.5064530372619629,
        "additional_info": {
            "duration": 0.48482298851013184,
            "num_run": 55,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1853269600750767e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8042790706896207,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.003162808728872729,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018980902992932907,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9968673191113452,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2156832264594035,
        "time": 0.9890730381011963,
        "additional_info": {
            "duration": 0.9774489402770996,
            "num_run": 56,
            "train_loss": 1.0792516600047743,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.928440777442273e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6106071605692998,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 1.1887440689326448e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010571729672883938,
            "feature_preprocessor:select_rates_classification:alpha": 0.2870481350813086,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12630295753479004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.014982054605936906,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7526435032062845,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.0029121323889941364,
            "feature_preprocessor:select_rates_classification:alpha": 0.3082770081691107,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.4630758762359619,
        "additional_info": {
            "duration": 0.45276904106140137,
            "num_run": 58,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0179159848290442e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031058878872841693,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.006389463978253076,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.35560770308759204,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10007619857788086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010019363794107413,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007594373613577992,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 96,
            "classifier:CustomMLPClassifier:tol": 3.2596627019311944e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1257538748619262,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7585707804059371,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05998902505394872,
            "feature_preprocessor:select_percentile_classification:percentile": 84.66261506163231,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.233858467096772,
        "time": 4.84332013130188,
        "additional_info": {
            "duration": 4.833224058151245,
            "num_run": 60,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.023151763455685048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04569652248421685,
            "classifier:CustomMLPClassifier:max_iter": 274,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.00017804466620461294,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7472692798904496,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3079130058751187,
        "time": 1.3417787551879883,
        "additional_info": {
            "duration": 1.327091932296753,
            "num_run": 61,
            "train_loss": 1.072441794202082,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002693904159770022,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012481324220069317,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.002998015395961061,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022387209374979782,
            "feature_preprocessor:select_percentile_classification:percentile": 3.267737688942672,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.2651689052581787,
        "additional_info": {
            "duration": 0.25432300567626953,
            "num_run": 62,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002376812099924675,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009426267974966376,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.00013431391631439467,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000593995482566676,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.15377342994691556,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2267261560546086,
        "time": 2.7604117393493652,
        "additional_info": {
            "duration": 2.7476189136505127,
            "num_run": 63,
            "train_loss": 1.076149648320055,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.024229517709623324,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01410608365958767,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 350,
            "classifier:CustomMLPClassifier:tol": 6.41586368756337e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.452779593496218,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2179968105356307,
        "time": 4.0442328453063965,
        "additional_info": {
            "duration": 4.0328757762908936,
            "num_run": 64,
            "train_loss": 1.0811700749159858,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.833186018268724e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006966850536793533,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.0004954404441568342,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000933311619406303,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1617,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.28377825602492934,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.7890632152557373,
        "additional_info": {
            "duration": 0.7177321910858154,
            "num_run": 65,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0179159848290442e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013526453737122918,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.006389463978253076,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018026390463509224,
            "feature_preprocessor:select_rates_classification:alpha": 0.3811665445955444,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12084817886352539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0085463134601607e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02547394280408425,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 3.240679796244478e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019336907254647735,
            "feature_preprocessor:select_rates_classification:alpha": 0.19437737729458449,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09986996650695801,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.180932803672229e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005978147554417985,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.00013688401840113114,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048533555244841514,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6835709475685625,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2618225375688952,
        "time": 3.057023048400879,
        "additional_info": {
            "duration": 3.046049118041992,
            "num_run": 68,
            "train_loss": 1.1189464029795526,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.035021421643826e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6106071605692998,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 1.1496376131158883e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.2870481350813086,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12215495109558105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8117272918781926e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4517570078834713,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 5.6354003801170204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.24998132562464415,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12102913856506348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.8117272918781926e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4517570078834713,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 2.4737795453518284e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25726718417997785,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15359187126159668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002927883309314585,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04999433158653688,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 0.004291214766670287,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05773769768719703,
            "feature_preprocessor:select_rates_classification:alpha": 0.1011218845565242,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2496611429641857,
        "time": 0.44389915466308594,
        "additional_info": {
            "duration": 0.43125391006469727,
            "num_run": 72,
            "train_loss": 1.0407606860634162,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.373340375275703e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.32887575959356646,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 9.003393961564733e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.053366827095335155,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09454822540283203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0015678082297087487,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04533293651911816,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 1.1223775426058078e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39058884071770106,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09920406341552734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.3162992730649775e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04635031488874919,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 0.0021435377182133916,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2360409266964532,
            "feature_preprocessor:select_rates_classification:alpha": 0.04346876812906147,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09985208511352539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.8335498879217857e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09146169567120399,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.0033945455847760584,
            "feature_preprocessor:select_rates_classification:alpha": 0.34999553734684524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09451484680175781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2942415802850539e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001840852434280434,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 0.0016435719497410002,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008474375684484867,
            "feature_preprocessor:select_rates_classification:alpha": 0.2642180287298449,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12184405326843262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3987134959020284e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03651730133092275,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.00014639681207616017,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.031435502274979446,
            "feature_preprocessor:select_rates_classification:alpha": 0.45857179181314384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12588715553283691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.5667752687244933e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021095243262782385,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.006005932892263719,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007798182671236187,
            "feature_preprocessor:select_rates_classification:alpha": 0.35959675795190194,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10036420822143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7707326961149776e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016189154382898095,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 3.768873694786161e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 977,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6720730019322003,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2113016285682803,
        "time": 10.254695892333984,
        "additional_info": {
            "duration": 10.24163007736206,
            "num_run": 80,
            "train_loss": 1.1718638530240493,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.747648445370423e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.46727500240948333,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 357,
            "classifier:CustomMLPClassifier:tol": 0.0007404657833577356,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011957788526653572,
            "feature_preprocessor:select_rates_classification:alpha": 0.0764509070734719,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1217951774597168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5678168497429074e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003954963701480439,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.0016258549093582156,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006948330899257844,
            "feature_preprocessor:select_rates_classification:alpha": 0.46300693115306946,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.5079989433288574,
        "additional_info": {
            "duration": 0.4979078769683838,
            "num_run": 82,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2767373509734494e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.40223473377662533,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.008523137634852393,
            "feature_preprocessor:select_rates_classification:alpha": 0.19878070938935288,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09502696990966797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.0697684537212444e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8463612786275075,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 0.0009063839267949179,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06722404994404624,
            "feature_preprocessor:select_rates_classification:alpha": 0.10632517782311363,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.31417202949523926,
        "additional_info": {
            "duration": 0.30099916458129883,
            "num_run": 84,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.625712367476224e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002497441652947302,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 8.252204406453031e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23976906592947117,
            "feature_preprocessor:select_rates_classification:alpha": 0.11852884190522815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09480500221252441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00237408545731124,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005866428734882309,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.00040222494233975876,
            "feature_preprocessor:select_rates_classification:alpha": 0.15535725544806267,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09389066696166992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012321598611766712,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014472978009689318,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.0024178435975156045,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000326323033312203,
            "feature_preprocessor:select_rates_classification:alpha": 0.06002682489741776,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10127997398376465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0026742172267718582,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012910662792329364,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 7.250014963101387e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007868712269400929,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1589,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 83.35275225949627,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1999379074144736,
        "time": 2.057971239089966,
        "additional_info": {
            "duration": 2.0458691120147705,
            "num_run": 88,
            "train_loss": 1.1581624917956561,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011112562768535493,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010796320771849572,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.0017425958802469628,
            "feature_preprocessor:select_rates_classification:alpha": 0.24687221452333943,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10047483444213867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005461960870458288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3764977968576585,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 7.655091511741468e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010520535548007056,
            "feature_preprocessor:select_rates_classification:alpha": 0.31002625435362996,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.7125201225280762,
        "additional_info": {
            "duration": 0.6937289237976074,
            "num_run": 90,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.751856181510738e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6862930684140801,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 2.989161655269174e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.045768788783914084,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1151,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.23424232063628972,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.244324412232277,
        "time": 0.36705613136291504,
        "additional_info": {
            "duration": 0.34800291061401367,
            "num_run": 91,
            "train_loss": 1.229880728086561,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012633262939694574,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8806219147583817,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.005187655330418873,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17494078874226993,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.75,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_rates_classification:alpha": 0.4210622528085364,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1964682175246433,
        "time": 0.23593688011169434,
        "additional_info": {
            "duration": 0.2253248691558838,
            "num_run": 92,
            "train_loss": 1.2071482306662147,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.6202578387468606e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022216004990233706,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 2.3453764222614957e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4879384317214563,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12713384628295898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.026623607078672867,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9549999931990147,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 465,
            "classifier:CustomMLPClassifier:tol": 0.0028345511283662376,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14380310453028222,
            "feature_preprocessor:select_rates_classification:alpha": 0.2574745497864112,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10057592391967773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.425149728819571e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9826205490558056,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 0.0009668947474721354,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011957788526653572,
            "feature_preprocessor:select_rates_classification:alpha": 0.048672214124851045,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09515905380249023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009702735293010774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00028685524783947185,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.0015716159852658315,
            "feature_preprocessor:select_percentile_classification:percentile": 53.06225792151051,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1964543460114427,
        "time": 0.6094636917114258,
        "additional_info": {
            "duration": 0.5990519523620605,
            "num_run": 96,
            "train_loss": 1.1667162280856516,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.060151986231656344,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008683451670878792,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 0.00424516905086754,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09896604188799435,
            "feature_preprocessor:select_rates_classification:alpha": 0.07027827728357283,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10071873664855957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1241414668681478e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4368442725608124,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.0002090489007175967,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001705663325290884,
            "feature_preprocessor:select_rates_classification:alpha": 0.2758984481887042,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1266942024230957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5648698979334915e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013053356150623035,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.0005688453847717359,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013831436033708952,
            "feature_preprocessor:select_rates_classification:alpha": 0.42388714007032646,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.223365024702358,
        "time": 2.116590976715088,
        "additional_info": {
            "duration": 2.1022300720214844,
            "num_run": 99,
            "train_loss": 1.1862088317976494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006589479540859727,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10990899273408451,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.00170504549504803,
            "feature_preprocessor:select_rates_classification:alpha": 0.4199617850929922,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09521293640136719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005055568471197389,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027845861101480964,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.008862770780115015,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06695958435767771,
            "feature_preprocessor:select_rates_classification:alpha": 0.0882003628475959,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12232089042663574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008565601208845584,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3208088819985063,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 2.2737176376204246e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.40396737229438684,
            "feature_preprocessor:select_rates_classification:alpha": 0.014316885684348732,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09596800804138184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6426666511904135e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010180173155389912,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.00011402103236446538,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001147923850021868,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.997722054040463,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2768864151432287,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4765836540554853,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2513091356504962,
        "time": 0.939298152923584,
        "additional_info": {
            "duration": 0.9267172813415527,
            "num_run": 103,
            "train_loss": 1.066406710774917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1433285280028439e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03250580474633068,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.00025710331998440237,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15382129016221993,
            "feature_preprocessor:select_rates_classification:alpha": 0.1964074220478413,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12740397453308105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08174353146176006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002833845448637702,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 3.8745368632153546e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03760642409071854,
            "feature_preprocessor:select_rates_classification:alpha": 0.010770072887128699,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09479308128356934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00013434234666900703,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6767183522579102,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 0.0009820734697542847,
            "feature_preprocessor:select_rates_classification:alpha": 0.11189952144117574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0999898910522461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00041784716905173957,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7026343865169866,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.0005983766335297306,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05543549290609589,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7683125172062336,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2500442391031739,
        "time": 0.6703948974609375,
        "additional_info": {
            "duration": 0.6590852737426758,
            "num_run": 107,
            "train_loss": 1.1615110837832792,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7320081333051257e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19124323566331924,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.003395405274187095,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016393598850821797,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17936101464029452,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.264143915326053,
        "time": 0.6592669486999512,
        "additional_info": {
            "duration": 0.6462099552154541,
            "num_run": 108,
            "train_loss": 1.1015433936115508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00021042175143589162,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0245305170361303,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 117,
            "classifier:CustomMLPClassifier:tol": 1.1128347088566781e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7883431778369767,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13312076483004434,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.33708766381279964,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2852485225205201,
        "time": 1.0112807750701904,
        "additional_info": {
            "duration": 0.9993321895599365,
            "num_run": 109,
            "train_loss": 1.1135785304274775,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0025791629065113147,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006842178453559926,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 0.007191610677643209,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022708833299027947,
            "feature_preprocessor:select_rates_classification:alpha": 0.32210635518042613,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09624028205871582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8117272918781926e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5666066860676038,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 2.4615581603258976e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.2226526936952542,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2636538822588363,
        "time": 0.380399227142334,
        "additional_info": {
            "duration": 0.3603241443634033,
            "num_run": 111,
            "train_loss": 1.1860167257170684,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.508722346001965e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036777078663376996,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.0007318948027889962,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9323572262489777,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16091988985938807,
            "feature_preprocessor:select_percentile_classification:percentile": 14.291750063930452,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2378370014082996,
        "time": 1.1296658515930176,
        "additional_info": {
            "duration": 1.1204729080200195,
            "num_run": 112,
            "train_loss": 1.2033424053223392,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002640589774906309,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020073338674708605,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 1.519434059548009e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12466438479878475,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1274728775024414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011497569542018226,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 1.8017457832441006e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.48849822267473897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0960550308227539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00013377497281306933,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005091068628139828,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.0015717814556701658,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.33263740758555826,
            "feature_preprocessor:select_rates_classification:alpha": 0.44761936471568414,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13391613960266113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0978488720296081,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005362746351544665,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.0019055399490705838,
            "feature_preprocessor:select_rates_classification:alpha": 0.3661002438357838,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.5357050895690918,
        "additional_info": {
            "duration": 0.5245349407196045,
            "num_run": 116,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0034042225566157064,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015919691123076525,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.0020248046236073305,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12345263192947496,
            "feature_preprocessor:select_percentile_classification:percentile": 25.26032283522271,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2116753128098245,
        "time": 0.3576951026916504,
        "additional_info": {
            "duration": 0.34763002395629883,
            "num_run": 117,
            "train_loss": 1.1972005731061963,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02706972080580932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.996467235747022,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0012492264593576864,
            "feature_preprocessor:select_rates_classification:alpha": 0.2637760346080737,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0953378677368164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02706972080580932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8501435682530725,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0008812737001689602,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012129546351999176,
            "feature_preprocessor:select_rates_classification:alpha": 0.292546878429491,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09547209739685059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.657774653985029e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7926786489169265,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 2.616654559827649e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000682984117903923,
            "feature_preprocessor:select_percentile_classification:percentile": 81.05121112071521,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.295858781525723,
        "time": 0.64556884765625,
        "additional_info": {
            "duration": 0.6343309879302979,
            "num_run": 120,
            "train_loss": 1.198050429971849,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5307864006574928e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5579222294765216,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.0020314292810625864,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003430112500496732,
            "feature_preprocessor:select_rates_classification:alpha": 0.4417778456445416,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09623098373413086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010058934579554265,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010128392955994831,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.006726717814222997,
            "feature_preprocessor:select_percentile_classification:percentile": 72.48891478119444,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.41023802757263184,
        "additional_info": {
            "duration": 0.40006399154663086,
            "num_run": 122,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009193671059238663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8429891408525472,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 0.0016679908498322751,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9262487693164998,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.037929970441645,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17547847792919546,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2475889220867014,
        "time": 0.37868285179138184,
        "additional_info": {
            "duration": 0.3637208938598633,
            "num_run": 123,
            "train_loss": 1.227974073270708,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07952217992082149,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011156645182760503,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 0.00037236748402266897,
            "feature_preprocessor:select_percentile_classification:percentile": 79.89494475370476,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.335223913192749,
        "additional_info": {
            "duration": 0.32459402084350586,
            "num_run": 124,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.144291977579861e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012919384427113934,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 0.002785388441524011,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.826410917510787,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07965997299810795,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.34617212141440723,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2497929792576794,
        "time": 1.8852417469024658,
        "additional_info": {
            "duration": 1.8688879013061523,
            "num_run": 125,
            "train_loss": 1.0602943203595465,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.189756039002146e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1526538782315627,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.001024634587036968,
            "feature_preprocessor:select_rates_classification:alpha": 0.14681593736060453,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2000175781489861,
        "time": 0.8820919990539551,
        "additional_info": {
            "duration": 0.8724551200866699,
            "num_run": 126,
            "train_loss": 1.1559828477730512,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.038396522678879386,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12728660694221808,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 1.3616636674650061e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.033871179000052265,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12175321578979492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00023857429907890088,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003790714711861891,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.002546189089854105,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01735091307598046,
            "feature_preprocessor:select_percentile_classification:percentile": 89.05418006240926,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.241419948433282,
        "time": 0.5988249778747559,
        "additional_info": {
            "duration": 0.585360050201416,
            "num_run": 128,
            "train_loss": 1.1755628200600021,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.800952888969977e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.45478331585865295,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 7.080303998424503e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9834611636638672,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.7760679721832275,
        "additional_info": {
            "duration": 0.763991117477417,
            "num_run": 129,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0026255453239130426,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13350010569024895,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 439,
            "classifier:CustomMLPClassifier:tol": 0.0044375562099167685,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43347775778699255,
            "feature_preprocessor:select_rates_classification:alpha": 0.2740243677865984,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09574198722839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010375673094902327,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6213877827299941,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 1.5285355701284013e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.26749798404522246,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2310729522789845,
        "time": 0.22313475608825684,
        "additional_info": {
            "duration": 0.20772695541381836,
            "num_run": 131,
            "train_loss": 1.2272163150250177,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.096879470389247e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16345249708899887,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 2.3168129786359806e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009144497367604818,
            "feature_preprocessor:select_rates_classification:alpha": 0.28608244877239564,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12792301177978516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.502157941985781e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002309420704968855,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 212,
            "classifier:CustomMLPClassifier:tol": 0.000768552950851519,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008527712690012727,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3843042374916137,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.255166621407833,
        "time": 6.290454864501953,
        "additional_info": {
            "duration": 6.272276163101196,
            "num_run": 133,
            "train_loss": 1.0882458828147623,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00035316139582977586,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014143059528962478,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.002541370796451839,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002871661814880758,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4832141671057919,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.213670219602732,
        "time": 0.7574462890625,
        "additional_info": {
            "duration": 0.742495059967041,
            "num_run": 134,
            "train_loss": 1.185951820155795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0211841440278006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18597579762323524,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 1.726243164236703e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.021016827421072394,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09517216682434082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007966582188980099,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.049698514631808396,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 6.845323299544125e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024188334336747653,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6584660616091715,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.3219640254974365,
        "additional_info": {
            "duration": 0.31079697608947754,
            "num_run": 136,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.034353516961751346,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.056490238326740896,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.0011905984311429132,
            "feature_preprocessor:select_rates_classification:alpha": 0.49709135727860504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12695717811584473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08781750036784501,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013716129752366185,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 9.346734922622464e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005582908195854543,
            "feature_preprocessor:select_percentile_classification:percentile": 84.55039667072074,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.49541497230529785,
        "additional_info": {
            "duration": 0.48224782943725586,
            "num_run": 138,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.078743331008091e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018693160048599557,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 0.00867897564187548,
            "feature_preprocessor:select_rates_classification:alpha": 0.2897658642159502,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12138819694519043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.259719322512631e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3744718166293197,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.004114078734248688,
            "feature_preprocessor:select_rates_classification:alpha": 0.2954566349908359,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1223750114440918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.8459017723345586e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12267969391190271,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 327,
            "classifier:CustomMLPClassifier:tol": 6.704155652218973e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3293145513811696,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10018610954284668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0024710562597768616,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01300909474752135,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.0008914523529464293,
            "feature_preprocessor:select_rates_classification:alpha": 0.46336524121585726,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0950782299041748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04082896797821224,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2707952060571346,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 300,
            "classifier:CustomMLPClassifier:tol": 0.0002050967990573142,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08676631953616808,
            "feature_preprocessor:select_rates_classification:alpha": 0.016816174103037797,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09555983543395996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008513349131185631,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02496466382090267,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 2.3388653462609456e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9534784439213695,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 2.553399085998535,
        "additional_info": {
            "duration": 2.539640188217163,
            "num_run": 144,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.119401936599409e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008547521342979085,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 289,
            "classifier:CustomMLPClassifier:tol": 0.0005514709180021387,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009874732949889779,
            "feature_preprocessor:select_percentile_classification:percentile": 14.00659578063962,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2431051039600596,
        "time": 0.3321800231933594,
        "additional_info": {
            "duration": 0.3216269016265869,
            "num_run": 145,
            "train_loss": 1.2243292150585559,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.598573591479322e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020372638421590496,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.0028327251026377975,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.3283468087932895,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09980916976928711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.2299156148848827e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013215716557468893,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.0006261170014993811,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023745508743247858,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20983769496542581,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2283010598140671,
        "time": 0.428145170211792,
        "additional_info": {
            "duration": 0.4038670063018799,
            "num_run": 147,
            "train_loss": 1.2065085063873944,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001758720099318862,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1321800541770917,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.0004810194059310093,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007862345864534967,
            "feature_preprocessor:select_rates_classification:alpha": 0.027094685835201936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12122917175292969,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.404912475574491e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004053543533009014,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0005495944146629524,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016316867472720376,
            "feature_preprocessor:select_rates_classification:alpha": 0.10783899707742471,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.229996919631958,
        "additional_info": {
            "duration": 0.21924400329589844,
            "num_run": 149,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00030193577527040595,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018138033986847264,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.005563119949947027,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20283675877390062,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8631650549051954,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.029000643770362978,
            "feature_preprocessor:select_rates_classification:alpha": 0.21441297470582668,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.27768874168395996,
        "additional_info": {
            "duration": 0.26468801498413086,
            "num_run": 150,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.995457780969458e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5578167985763818,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.0021618646876266517,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03493148193653164,
            "feature_preprocessor:select_rates_classification:alpha": 0.08604072694554256,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.20123815536499023,
        "additional_info": {
            "duration": 0.18903493881225586,
            "num_run": 151,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.270265129811824e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001991886844096999,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 439,
            "classifier:CustomMLPClassifier:tol": 0.006516997811804223,
            "feature_preprocessor:select_percentile_classification:percentile": 11.073227463312875,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.26010584831237793,
        "additional_info": {
            "duration": 0.24910402297973633,
            "num_run": 152,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.588495481613353e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.537593298602906,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 0.002098939698924893,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.192143777578927,
            "feature_preprocessor:select_rates_classification:alpha": 0.2865432314696384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09671998023986816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.700647046188191e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005354470023658406,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 0.0006476002658512248,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.25754767045239946,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.6856839656829834,
        "additional_info": {
            "duration": 0.6702280044555664,
            "num_run": 154,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.541675615999138e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7781367597144205,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.00017589806701875368,
            "feature_preprocessor:select_rates_classification:alpha": 0.2548271598032743,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2347661522022317,
        "time": 0.25574588775634766,
        "additional_info": {
            "duration": 0.19767498970031738,
            "num_run": 155,
            "train_loss": 1.2248364265134892,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01626037711233058,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9268989290066793,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 7.249867673416671e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032857741237583404,
            "feature_preprocessor:select_rates_classification:alpha": 0.20142917857838472,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10083818435668945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.341228431309361e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8088224136518557,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 5.6354003801170204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.24458562036049317,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09480786323547363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06984213262072117,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004808547167128819,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 0.00031024512772891453,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03928999555792163,
            "feature_preprocessor:select_rates_classification:alpha": 0.2995883556853914,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10055780410766602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.928651918433959e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023038613106769949,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.0002854115370543677,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06359992356653381,
            "feature_preprocessor:select_rates_classification:alpha": 0.019884800296948835,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.16193008422851562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.92371799292213e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5816481959262214,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.00011881403574856916,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017336997967299227,
            "feature_preprocessor:select_rates_classification:alpha": 0.3279680264323998,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2678594257684908,
        "time": 0.7017331123352051,
        "additional_info": {
            "duration": 0.6898257732391357,
            "num_run": 160,
            "train_loss": 1.1862321727853207,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012131043548710713,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017633180949433178,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 0.000736871307696508,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003438943955555629,
            "feature_preprocessor:select_rates_classification:alpha": 0.35618581977167135,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.15474581718444824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.036111746749629e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03532875254797474,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 8.798555669679003e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3769039026203445,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09532403945922852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.412139178914725e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017359698523196517,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 1.104753914440567e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019659786181381654,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9374539926731431,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28957600992344945,
            "feature_preprocessor:select_percentile_classification:percentile": 84.03895679586113,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2248475901707505,
        "time": 9.62903904914856,
        "additional_info": {
            "duration": 9.617965936660767,
            "num_run": 163,
            "train_loss": 1.0059403926248072,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.04080379173232388,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011496316919630217,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0007260962414359611,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1990,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.390986305537551,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2071414433994831,
        "time": 0.5135879516601562,
        "additional_info": {
            "duration": 0.499439001083374,
            "num_run": 164,
            "train_loss": 1.1860159152503371,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.059262888539271856,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017778159381540382,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.00019224101382028764,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013760180014048677,
            "feature_preprocessor:select_percentile_classification:percentile": 94.67907125796896,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2331954747314444,
        "time": 3.1508450508117676,
        "additional_info": {
            "duration": 3.140084981918335,
            "num_run": 165,
            "train_loss": 1.2356826165933248,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002279567161737389,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003571394582030102,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.00016552611803497436,
            "feature_preprocessor:select_rates_classification:alpha": 0.3949506383891605,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10050082206726074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06286758876891149,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6170737354339622,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 182,
            "classifier:CustomMLPClassifier:tol": 0.0026726105547889762,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8885578342062301,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 1.5796208381652832,
        "additional_info": {
            "duration": 1.5684788227081299,
            "num_run": 167,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0018944608663157743,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8569682211293089,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.006857168128718367,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0075852288975563195,
            "feature_preprocessor:select_rates_classification:alpha": 0.4511754693884044,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.3059370517730713,
        "additional_info": {
            "duration": 0.2945821285247803,
            "num_run": 168,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04010721964145775,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002977567523883125,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 7.805455908640923e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00083829939767427,
            "feature_preprocessor:select_rates_classification:alpha": 0.3629375122189151,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12668585777282715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019210708401426297,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027380432738678847,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 0.0005591735084399735,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18577018186599337,
            "feature_preprocessor:select_rates_classification:alpha": 0.20738086829683963,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2270791615648284,
        "time": 0.2563440799713135,
        "additional_info": {
            "duration": 0.2401289939880371,
            "num_run": 170,
            "train_loss": 1.2379148308970063,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0510203383568146e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014559298463403205,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 5.6200168626950576e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1998199954426827,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12248706817626953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02582291586628249,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06624715592917921,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 0.0018763534295577532,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9188639395424265,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03501655028157509,
            "feature_preprocessor:select_percentile_classification:percentile": 48.251426264305294,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1929146340044674,
        "time": 1.4639418125152588,
        "additional_info": {
            "duration": 1.4537880420684814,
            "num_run": 172,
            "train_loss": 1.1018220968188825,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.304086128603325e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004039832558351847,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 346,
            "classifier:CustomMLPClassifier:tol": 0.0005825292728080324,
            "feature_preprocessor:select_percentile_classification:percentile": 72.49503235644926,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2240814001546663,
        "time": 1.2641100883483887,
        "additional_info": {
            "duration": 1.2536439895629883,
            "num_run": 173,
            "train_loss": 1.1736705516425405,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00028754601795138817,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001570495124361244,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 0.00016184339149555324,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7120683775963216,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04930014584088185,
            "feature_preprocessor:select_rates_classification:alpha": 0.2875716259406206,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.4854319095611572,
        "additional_info": {
            "duration": 0.47567319869995117,
            "num_run": 174,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.716850990757768e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9681218031491371,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.0012160292744192132,
            "feature_preprocessor:select_rates_classification:alpha": 0.05401411920308721,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12141609191894531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005672780721400991,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.258991932826566,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 257,
            "classifier:CustomMLPClassifier:tol": 0.0020274049122380737,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5027389831815167,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.382152795791626,
        "additional_info": {
            "duration": 0.3644750118255615,
            "num_run": 176,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005090864568854775,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24519839334743984,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 4.742475863201634e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01985460658633427,
            "feature_preprocessor:select_rates_classification:alpha": 0.05474388121695176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0947561264038086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0014727860857830103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029045282565279138,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 1.4011793267527185e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 21.55283280628615,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2801242536129345,
        "time": 0.5094401836395264,
        "additional_info": {
            "duration": 0.4983999729156494,
            "num_run": 178,
            "train_loss": 1.2152747357020905,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00013312041748763528,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5963437778706642,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 4.024625505470112e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030395624636176066,
            "feature_preprocessor:select_rates_classification:alpha": 0.38164602420200266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09529495239257812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.994675574458881e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6862930684140801,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 2.566066457570731e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.055691511018854875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1258,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.20854083871847065,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.3245871067047119,
        "additional_info": {
            "duration": 0.3078620433807373,
            "num_run": 180,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06050677707058982,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.32195197232237427,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 0.005142087940824471,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.41487977368989465,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1223139762878418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07724138761107693,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018150609225596741,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.0020937983649196162,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017034931600237873,
            "feature_preprocessor:select_rates_classification:alpha": 0.46494931714241167,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12275290489196777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006467872578291792,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015498898681286103,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 0.00011550658015867089,
            "feature_preprocessor:select_rates_classification:alpha": 0.05208624493575954,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09451413154602051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0094947180628898e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2718887063861265,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 5.795030717750961e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3846676967456526,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12248706817626953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008497919116133465,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013634076251943882,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 1.9152804200857846e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.28682939480876674,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09531307220458984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.990155344330609e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5159715534561896,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 5.5884794095291126e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.44095241831441173,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10022807121276855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011637842673278317,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5619114949421418,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0030102933660747506,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010829882206105654,
            "feature_preprocessor:select_percentile_classification:percentile": 91.5441754803854,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.45102405548095703,
        "additional_info": {
            "duration": 0.44112682342529297,
            "num_run": 187,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003504337568741866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35933033567232747,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 0.0004873779585749191,
            "feature_preprocessor:select_percentile_classification:percentile": 97.10576645159507,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.47263598442077637,
        "additional_info": {
            "duration": 0.45925402641296387,
            "num_run": 188,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09384921397534972,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6577024986245417,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 4.6203845764646094e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021890117110275737,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 831,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 92.2987597046095,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3454930782318115,
        "additional_info": {
            "duration": 0.32773399353027344,
            "num_run": 189,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0019214608827546613,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07097494303194185,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 1.2668366018027288e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038594820880233055,
            "feature_preprocessor:select_rates_classification:alpha": 0.05024373536049912,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.291866375700995,
        "time": 0.5622620582580566,
        "additional_info": {
            "duration": 0.5473358631134033,
            "num_run": 190,
            "train_loss": 1.2238883645005667,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0007872590572198575,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046825465762744006,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.007565657942002076,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016961295313114978,
            "feature_preprocessor:select_rates_classification:alpha": 0.410060802706724,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12587475776672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004114258486413085,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011754898036791534,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 0.0004142891083577958,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1672,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 96.92074407624638,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2105472048376833,
        "time": 4.595529317855835,
        "additional_info": {
            "duration": 4.584503889083862,
            "num_run": 192,
            "train_loss": 1.0765404112604187,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.04015099330172e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0880612858262125,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 1.415568156621793e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030754691783150736,
            "feature_preprocessor:select_rates_classification:alpha": 0.10732608025131501,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12188076972961426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.99400294372545e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013976525641304841,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.00038400277231613996,
            "feature_preprocessor:select_rates_classification:alpha": 0.41949955309638215,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2304026521129805,
        "time": 2.218898057937622,
        "additional_info": {
            "duration": 2.207859992980957,
            "num_run": 194,
            "train_loss": 1.0880731328131554,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09550819729491912,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004795917740493198,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.00043490095283320676,
            "feature_preprocessor:select_rates_classification:alpha": 0.11822851856537425,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2046936641179344,
        "time": 0.3449540138244629,
        "additional_info": {
            "duration": 0.3346102237701416,
            "num_run": 195,
            "train_loss": 1.1892395541002108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017424878195148872,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6683731615002871,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 1.8936106717424776e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00029499544742070714,
            "feature_preprocessor:select_rates_classification:alpha": 0.22747051767747772,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.52846973519349,
        "time": 0.2743239402770996,
        "additional_info": {
            "duration": 0.26135706901550293,
            "num_run": 196,
            "train_loss": 1.5293339850053105,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4444773871399276e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9263883149283694,
            "classifier:CustomMLPClassifier:max_iter": 461,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 1.0563107748366399e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003135784923573822,
            "feature_preprocessor:select_rates_classification:alpha": 0.4246896234927386,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.232878415664638,
        "time": 0.3693220615386963,
        "additional_info": {
            "duration": 0.3550708293914795,
            "num_run": 197,
            "train_loss": 1.1864634659413165,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03627686298586426,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006817579961229413,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 4.19547512851295e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017603231556053173,
            "feature_preprocessor:select_percentile_classification:percentile": 17.368011598821703,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.214165197035013,
        "time": 0.6535720825195312,
        "additional_info": {
            "duration": 0.6418030261993408,
            "num_run": 198,
            "train_loss": 1.2165467901713856,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.1371201619882884e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10520978156717006,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0001916855180927071,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06027184908925725,
            "feature_preprocessor:select_percentile_classification:percentile": 47.299073952696475,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.329801082611084,
        "additional_info": {
            "duration": 0.31813716888427734,
            "num_run": 199,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.375478109584154e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6862930684140801,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 1.1220389140723731e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03159037737422446,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1052,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.24199044923754323,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2057667809650963,
        "time": 0.6035470962524414,
        "additional_info": {
            "duration": 0.5895049571990967,
            "num_run": 200,
            "train_loss": 1.1734714006281322,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07360788506973945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02171539673814267,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 7.202260777267736e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3413039097071968,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09547901153564453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.02394597265221e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004012902374044426,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.0010875626831655565,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014669603850348793,
            "feature_preprocessor:select_rates_classification:alpha": 0.2744824942038991,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.7709019184112549,
        "additional_info": {
            "duration": 0.7599010467529297,
            "num_run": 202,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.725740614023078e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3923143975156904,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.00017042594274503875,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025459119645185936,
            "feature_preprocessor:select_rates_classification:alpha": 0.04566690699349518,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12165403366088867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06381051300930943,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06962486477808186,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 4.753467511414184e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027068086324882296,
            "feature_preprocessor:select_rates_classification:alpha": 0.45410050477985264,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12264132499694824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.016853592788481954,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018669662029572038,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 0.0011187517419802347,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1300,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 27.044675718734194,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2156402225065897,
        "time": 1.103370189666748,
        "additional_info": {
            "duration": 1.0914249420166016,
            "num_run": 205,
            "train_loss": 1.1810998805428814,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002389535263128147,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012405925043434268,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 6.10745631950805e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06405115673479057,
            "feature_preprocessor:select_percentile_classification:percentile": 23.472819505714746,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2538871284852409,
        "time": 0.4276893138885498,
        "additional_info": {
            "duration": 0.4142611026763916,
            "num_run": 206,
            "train_loss": 1.1933343405015298,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.917271463201743e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1771884362272556,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 9.591311783148986e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1492,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4156460707892309,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2301641212659125,
        "time": 1.529320240020752,
        "additional_info": {
            "duration": 1.51910400390625,
            "num_run": 207,
            "train_loss": 1.1967178587228182,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006924019786915999,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001942417997275438,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00406841830462267,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08482665045934958,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4480943753765678,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2469209797015792,
        "time": 0.3778188228607178,
        "additional_info": {
            "duration": 0.36550211906433105,
            "num_run": 208,
            "train_loss": 1.2339494525617092,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0014521418376802005,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027444864601795065,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.00020911234281562548,
            "feature_preprocessor:select_rates_classification:alpha": 0.44375244245359047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09574604034423828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0029313254672035643,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016098815390589213,
            "classifier:CustomMLPClassifier:max_iter": 274,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 1.2584548330472841e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0844463041494197,
            "feature_preprocessor:select_rates_classification:alpha": 0.40373658469806445,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12328600883483887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004764110764342487,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007995724932875259,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 0.0006503527989813342,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2503268867851608,
            "feature_preprocessor:select_rates_classification:alpha": 0.4516750457229566,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12272810935974121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.512509550845517e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20299997053098012,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 0.008877410071673305,
            "feature_preprocessor:select_rates_classification:alpha": 0.12910891030592075,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12301993370056152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.502482345859476e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026814871073912424,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 0.00017122840664707395,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9835733573003336,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.043270768416484806,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17601130890554129,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.243364805073436,
        "time": 4.442300796508789,
        "additional_info": {
            "duration": 4.428494930267334,
            "num_run": 213,
            "train_loss": 1.061689033675457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.243140488766595e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006896364179278644,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 272,
            "classifier:CustomMLPClassifier:tol": 1.4983956184546543e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013367229804131726,
            "feature_preprocessor:select_rates_classification:alpha": 0.0958409113843856,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12738394737243652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003709129562655465,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6624937900368538,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 1.851569350039933e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9596234328850528,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1210563948404274,
            "feature_preprocessor:select_rates_classification:alpha": 0.3834015366432086,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2299767977886706,
        "time": 0.3939967155456543,
        "additional_info": {
            "duration": 0.3811211585998535,
            "num_run": 215,
            "train_loss": 1.21602773541404,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04662173558953976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.32195197232237427,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 0.002697714020173491,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012235541983192105,
            "feature_preprocessor:select_rates_classification:alpha": 0.4115038257761803,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12193989753723145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00019738417154682483,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1597312289366521,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 185,
            "classifier:CustomMLPClassifier:tol": 0.0003494467314251631,
            "feature_preprocessor:select_rates_classification:alpha": 0.4021272754414874,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.29100513458251953,
        "additional_info": {
            "duration": 0.26369476318359375,
            "num_run": 217,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002099508105079556,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007078481417241381,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.0025438821683818344,
            "feature_preprocessor:select_rates_classification:alpha": 0.1373125279658254,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12151885032653809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0211841440278006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8120526207005245,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 1.3405867791368047e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007432029096532306,
            "feature_preprocessor:select_rates_classification:alpha": 0.021016827421072394,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.318282335167528,
        "time": 0.5106699466705322,
        "additional_info": {
            "duration": 0.4997119903564453,
            "num_run": 219,
            "train_loss": 1.2608934841497312,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001537333775773434,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6928812837993826,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.00017448012707714435,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009992611266364524,
            "feature_preprocessor:select_rates_classification:alpha": 0.3579281937025075,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09523606300354004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08783727238489139,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008224165488296292,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 1.3086107112726486e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.31833112529717095,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12401485443115234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.786800779731544e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0193028814819064,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 6.709136185437978e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19233857687448952,
            "feature_preprocessor:select_rates_classification:alpha": 0.46033636991050514,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12155795097351074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001204652493468459,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000864727016319425,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 128,
            "classifier:CustomMLPClassifier:tol": 0.007645065824075376,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007566089392786758,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 230,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3162093919289414,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2315829301678871,
        "time": 0.47235107421875,
        "additional_info": {
            "duration": 0.4594743251800537,
            "num_run": 223,
            "train_loss": 1.1878361876236476,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08174353146176006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003907882996882498,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 3.948361444109823e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012640092153692497,
            "feature_preprocessor:select_rates_classification:alpha": 0.010770072887128699,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10088610649108887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003417941331042602,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.43798597644415793,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.008349314095893325,
            "feature_preprocessor:select_rates_classification:alpha": 0.09870163530513489,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12848997116088867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1617212526491434e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017119213329878855,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.0008894982673774095,
            "feature_preprocessor:select_percentile_classification:percentile": 38.12892285426984,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2147215061562266,
        "time": 1.2121257781982422,
        "additional_info": {
            "duration": 1.2000041007995605,
            "num_run": 226,
            "train_loss": 1.1877315824114898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00016407370715475805,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4121491034562495,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 143,
            "classifier:CustomMLPClassifier:tol": 1.4100391990023583e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003691223847183828,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8035286074060024,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2638680893323613,
            "feature_preprocessor:select_rates_classification:alpha": 0.18964012473485378,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.20737409591674805,
        "additional_info": {
            "duration": 0.19285202026367188,
            "num_run": 227,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.458003482681874e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008792107156254862,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 0.0055525420777076066,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010742768166309073,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.38958276664303515,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.188838095567578,
        "time": 0.35759782791137695,
        "additional_info": {
            "duration": 0.339627742767334,
            "num_run": 228,
            "train_loss": 1.1776129110164781,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.72961167532459e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09659531066711396,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 5.9208187730686193e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.027960216470003116,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.49849534034729004,
        "additional_info": {
            "duration": 0.48837780952453613,
            "num_run": 229,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00014339179776704208,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023245208651804954,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0017983895169924272,
            "feature_preprocessor:select_rates_classification:alpha": 0.26709037807518493,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2092181306784007,
        "time": 0.4760251045227051,
        "additional_info": {
            "duration": 0.4645261764526367,
            "num_run": 230,
            "train_loss": 1.162623391174629,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.013685916847967751,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.39675524484035063,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 141,
            "classifier:CustomMLPClassifier:tol": 0.0016418555710013046,
            "feature_preprocessor:select_percentile_classification:percentile": 76.48294195058486,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2417487715236837,
        "time": 0.6248068809509277,
        "additional_info": {
            "duration": 0.6113319396972656,
            "num_run": 231,
            "train_loss": 1.1674180090474575,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01386586552361361,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003202911003080731,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.0004048823751030472,
            "feature_preprocessor:select_percentile_classification:percentile": 98.05225266897844,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.41411805152893066,
        "additional_info": {
            "duration": 0.4016139507293701,
            "num_run": 232,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.431072849677675e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5070256727240102,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 1.2452031687917793e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.05714040469031995,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.52846973519349,
        "time": 0.546928882598877,
        "additional_info": {
            "duration": 0.5365889072418213,
            "num_run": 233,
            "train_loss": 1.5286158020080816,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0085463134601607e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02547394280408425,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 3.240679796244478e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019336907254647735,
            "feature_preprocessor:select_rates_classification:alpha": 0.16579892790237344,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09618997573852539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0784517003502442e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005284396247879873,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 4.692872671299898e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2781172170727592,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12343502044677734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002429457508006473,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010621075462070275,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 0.0011385056960804291,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05041647323280803,
            "feature_preprocessor:select_rates_classification:alpha": 0.18231286026798227,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.29122424125671387,
        "additional_info": {
            "duration": 0.27460360527038574,
            "num_run": 236,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00018443935574355796,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012788135220352312,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.0001648911136997471,
            "feature_preprocessor:select_rates_classification:alpha": 0.4440945059285549,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10020899772644043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00023397028688907924,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6930301097221445,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.00011497367692379887,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004575415901574619,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9013486009893649,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28585154832609555,
            "feature_preprocessor:select_percentile_classification:percentile": 24.699757942122478,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2277746000779137,
        "time": 0.6439697742462158,
        "additional_info": {
            "duration": 0.6342921257019043,
            "num_run": 238,
            "train_loss": 1.1452452920025957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.21304940512728e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006981019739356481,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 1.027213168720653e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8123445670888934,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26011128671247796,
            "feature_preprocessor:select_rates_classification:alpha": 0.3273213421726377,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2140328748612654,
        "time": 2.8959641456604004,
        "additional_info": {
            "duration": 2.883632183074951,
            "num_run": 239,
            "train_loss": 1.2076025739488103,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002818895053108235,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020750918264682085,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.00046955318268908705,
            "feature_preprocessor:select_rates_classification:alpha": 0.24789002211656727,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12220478057861328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.014724940674489746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023624655459566975,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 250,
            "classifier:CustomMLPClassifier:tol": 0.009267549103895911,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07103023728056346,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.36994004249572754,
        "additional_info": {
            "duration": 0.35166311264038086,
            "num_run": 241,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.045339219854254334,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006440956119953948,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.00013633318571095167,
            "feature_preprocessor:select_rates_classification:alpha": 0.1806011127869564,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12191009521484375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.990844906859676e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7377137070536548,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.00015096214935869087,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00034589517207288565,
            "feature_preprocessor:select_rates_classification:alpha": 0.1551215852353386,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12721991539001465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0014704679961037e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011342085814639933,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 8.754070868150158e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4951065115625027,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10048604011535645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004544496458585635,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0634386413478056,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 2.2070400669254953e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.48853423930738404,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.2938108444213867,
        "additional_info": {
            "duration": 0.28090405464172363,
            "num_run": 245,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1800963209095454e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004888882721211724,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 6.607340353809782e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.19237972640848738,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10041594505310059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00017876858751392146,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0056072596530670005,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.00021387043527425288,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0053553680323120195,
            "feature_preprocessor:select_rates_classification:alpha": 0.047790553842666346,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12777400016784668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010967339337709665,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14844085556045536,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.003494154454424186,
            "feature_preprocessor:select_rates_classification:alpha": 0.4962178975893088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12278294563293457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002679083958985588,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 1.8017457832441006e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48849822267473897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09543800354003906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001069669130028615,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017968806806784197,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.0035324268901789227,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013944666100736995,
            "feature_preprocessor:select_percentile_classification:percentile": 75.24803029260677,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2168202615796808,
        "time": 0.31470417976379395,
        "additional_info": {
            "duration": 0.2984788417816162,
            "num_run": 250,
            "train_loss": 1.1661234240572225,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0828337867472608,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10197974251963272,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 3.793958273104314e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22895938393208393,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12241411209106445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0843582825536445,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9253570005062574,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 0.008383506135698096,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023785148825675702,
            "feature_preprocessor:select_rates_classification:alpha": 0.34023658141659746,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12907195091247559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.481165990080107e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04555683037625566,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.0013325591275785045,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12394897808882029,
            "feature_preprocessor:select_rates_classification:alpha": 0.26607533461809024,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2214098650722085,
        "time": 4.784503936767578,
        "additional_info": {
            "duration": 4.772706747055054,
            "num_run": 253,
            "train_loss": 1.0447655962749651,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09668764865333607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8645488285536023,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.008383506135698096,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000993319608354022,
            "feature_preprocessor:select_rates_classification:alpha": 0.293543758608539,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12781214714050293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0168242799502209e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0049972788769229335,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.0013542918997326377,
            "feature_preprocessor:select_rates_classification:alpha": 0.08753164128862964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12221622467041016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011741344908411546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11595098982645598,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 0.003866281203021981,
            "feature_preprocessor:select_rates_classification:alpha": 0.33126301297768973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09600400924682617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.6837938502209884e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020682294463107817,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 0.004684724116137632,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021645355716705573,
            "feature_preprocessor:select_rates_classification:alpha": 0.4862532736128735,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12183594703674316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00045769851653253347,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14502376908325834,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.006717757476891587,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011069954775715016,
            "feature_preprocessor:select_rates_classification:alpha": 0.25995376282345395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12810897827148438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.618191738481665e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003207239159365658,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 0.0006204004885576269,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010132347515893921,
            "feature_preprocessor:select_rates_classification:alpha": 0.4873514155673082,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.5912668704986572,
        "additional_info": {
            "duration": 0.5792238712310791,
            "num_run": 259,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004677143550132086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005699790869583126,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.006201984551048485,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.08683489648939424,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.4323439598083496,
        "additional_info": {
            "duration": 0.4202420711517334,
            "num_run": 260,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008251835753815305,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015170096553324212,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 0.00032352053258183496,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020837945478128058,
            "feature_preprocessor:select_rates_classification:alpha": 0.21106955143291942,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2229391726399403,
        "time": 0.821281909942627,
        "additional_info": {
            "duration": 0.8089630603790283,
            "num_run": 261,
            "train_loss": 1.177073322138065,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.937219304196722e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003343350282299253,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.0016660353609039276,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017274641262928127,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1011,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5758604551187667,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2153344438450167,
        "time": 0.6402311325073242,
        "additional_info": {
            "duration": 0.620795726776123,
            "num_run": 262,
            "train_loss": 1.1924854881891318,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003638448679079244,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5423982823859741,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.009259798773736434,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02502100571090537,
            "feature_preprocessor:select_rates_classification:alpha": 0.37962227006385235,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09543418884277344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.274794328808152e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006591303533921992,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.00016493742641137118,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015996916728063422,
            "feature_preprocessor:select_percentile_classification:percentile": 87.46929773209793,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2833224874133615,
        "time": 0.2908151149749756,
        "additional_info": {
            "duration": 0.2783839702606201,
            "num_run": 264,
            "train_loss": 1.2826588657231237,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.039736292936245275,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003939131871232861,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 2.7699965236890396e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07212703630886662,
            "feature_preprocessor:select_rates_classification:alpha": 0.15743094369032995,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12791776657104492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4254022776621991e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6478191479554558,
            "classifier:CustomMLPClassifier:max_iter": 398,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 8.20069496917564e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00046778221600914116,
            "feature_preprocessor:select_rates_classification:alpha": 0.05327985395294763,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12769269943237305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.050837627959181994,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06051148694023403,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 0.007182474548061592,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000952798431077595,
            "feature_preprocessor:select_rates_classification:alpha": 0.23958948861211402,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1277170181274414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.8269181421641222e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003090680143153833,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 1.4046021862153663e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 33.614542142674324,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.3707939348508935,
        "time": 0.9974730014801025,
        "additional_info": {
            "duration": 0.9876651763916016,
            "num_run": 268,
            "train_loss": 1.3684708698907728,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.732811319786374e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022105381309558102,
            "classifier:CustomMLPClassifier:max_iter": 229,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 9.562563504460304e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000340101211183915,
            "feature_preprocessor:select_percentile_classification:percentile": 39.11506787939867,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.248737476594028,
        "time": 1.409656047821045,
        "additional_info": {
            "duration": 1.3953731060028076,
            "num_run": 269,
            "train_loss": 1.183298154745308,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.669078224089363e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003516122252615811,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 5.47740914643149e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009253248350387076,
            "feature_preprocessor:select_percentile_classification:percentile": 57.104645897450844,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.230795155625628,
        "time": 6.607534170150757,
        "additional_info": {
            "duration": 6.5972580909729,
            "num_run": 270,
            "train_loss": 1.1661553301006018,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.1841893061712575e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013854880769430438,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.0001673949254360089,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19931256393504398,
            "feature_preprocessor:select_percentile_classification:percentile": 87.44015293063882,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.6008079051971436,
        "additional_info": {
            "duration": 0.581329345703125,
            "num_run": 271,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.095188458313988e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038558154118336495,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 0.0030988834157699,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9826416976511325,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26220896594527454,
            "feature_preprocessor:select_percentile_classification:percentile": 69.88084784516997,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2178854162535377,
        "time": 1.7276930809020996,
        "additional_info": {
            "duration": 1.714827060699463,
            "num_run": 272,
            "train_loss": 1.1647816016881751,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.467410615155505e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3211420939928268,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 0.0006682244017731879,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006857867830265227,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8266776397764579,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10367635684873386,
            "feature_preprocessor:select_rates_classification:alpha": 0.2659022528671855,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2420533303953647,
        "time": 0.8580360412597656,
        "additional_info": {
            "duration": 0.8463900089263916,
            "num_run": 273,
            "train_loss": 1.1790618895847098,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.8808097329300866e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03640039513926475,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.005632317875335035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011288909368663664,
            "feature_preprocessor:select_rates_classification:alpha": 0.49060157850900377,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13652992248535156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09396130258234103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007013868829438012,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.002839502495103315,
            "feature_preprocessor:select_rates_classification:alpha": 0.49106642996108857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12375783920288086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.561433836726849e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026770328002679342,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.005632317875335035,
            "feature_preprocessor:select_rates_classification:alpha": 0.4864225561748959,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09612584114074707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4210108298287815e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0477251054046929,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 2.8681482586276216e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.0852931937296004,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10039186477661133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.025984596677400197,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010114523739484337,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0005043069416315243,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007639361581803584,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7016414342725225,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2436399947855805,
        "time": 1.6476428508758545,
        "additional_info": {
            "duration": 1.6360549926757812,
            "num_run": 278,
            "train_loss": 1.1977051056343146,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001286686843871388,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02932289120586941,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.00020522497156819273,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.010257089588953328,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.3007049560546875,
        "additional_info": {
            "duration": 0.2822451591491699,
            "num_run": 279,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.809074701996099e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007940003421778752,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.00017433874516976976,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.313908454024875,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.211107976967492,
        "time": 1.248445987701416,
        "additional_info": {
            "duration": 1.235077142715454,
            "num_run": 280,
            "train_loss": 1.1888826260958383,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.034353516961751346,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10586317122965701,
            "classifier:CustomMLPClassifier:max_iter": 395,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.001103820741330333,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007127482418041979,
            "feature_preprocessor:select_rates_classification:alpha": 0.49709135727860504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0958108901977539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0014259620979902008,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1937132817857347,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.00019603619226541642,
            "feature_preprocessor:select_rates_classification:alpha": 0.35092716858223194,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09612393379211426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09038624608106137,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2707952060571346,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.00045107936319730617,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08676631953616808,
            "feature_preprocessor:select_rates_classification:alpha": 0.035975107071965384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12386083602905273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010968638043342839,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013767860143229027,
            "classifier:CustomMLPClassifier:max_iter": 175,
            "classifier:CustomMLPClassifier:num_units": 272,
            "classifier:CustomMLPClassifier:tol": 0.002338854173551308,
            "feature_preprocessor:select_percentile_classification:percentile": 24.285331990723538,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2419036511150598,
        "time": 0.21946120262145996,
        "additional_info": {
            "duration": 0.20438599586486816,
            "num_run": 284,
            "train_loss": 1.2031354856517915,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003976647851858652,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016846254551243595,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 1.365203309124685e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7118134490954938,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17988265844574586,
            "feature_preprocessor:select_rates_classification:alpha": 0.03176544797956764,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2254584237627733,
        "time": 0.824876070022583,
        "additional_info": {
            "duration": 0.8127920627593994,
            "num_run": 285,
            "train_loss": 1.2310840897097748,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.4891903894477245e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008288774704197025,
            "classifier:CustomMLPClassifier:max_iter": 109,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 5.180316717075003e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015308912566577122,
            "feature_preprocessor:select_rates_classification:alpha": 0.31235960503165294,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12293577194213867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.237417077588608e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.41869635581042436,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 3.480254779937295e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.24086913690077283,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09555196762084961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09404457745544914,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.44334423509574844,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.003233276316860728,
            "feature_preprocessor:select_rates_classification:alpha": 0.4880232496057912,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12715697288513184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00026164458352644104,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17954063546914242,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 7.359986627499844e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 66.85637123972484,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2377067923788876,
        "time": 0.2291557788848877,
        "additional_info": {
            "duration": 0.2183699607849121,
            "num_run": 289,
            "train_loss": 1.1721511624824577,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1484394248466486e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002319394969828242,
            "classifier:CustomMLPClassifier:max_iter": 353,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 1.3557266256254121e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.338614871814835,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12305188179016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012906641847512324,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016678894223485007,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 8.7098828031662e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03817311112613091,
            "feature_preprocessor:select_percentile_classification:percentile": 43.98258607009389,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2147215061562266,
        "time": 2.092210054397583,
        "additional_info": {
            "duration": 2.080918073654175,
            "num_run": 291,
            "train_loss": 1.1893383173720007,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9239408303650845e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014818834542317473,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 1.1291637223460554e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09125518145436988,
            "feature_preprocessor:select_rates_classification:alpha": 0.3357261899539676,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.3550426959991455,
        "additional_info": {
            "duration": 0.34397101402282715,
            "num_run": 292,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.8318660958040767e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1650936818184437,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.00011853093052873922,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06862837675630212,
            "feature_preprocessor:select_rates_classification:alpha": 0.3454351011725681,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09557509422302246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0085463134601607e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03515124346715161,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 4.90890497986003e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019336907254647735,
            "feature_preprocessor:select_rates_classification:alpha": 0.19437737729458449,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09600090980529785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008001497673226351,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04072725923105375,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 8.96681726289858e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2016430638906557,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12762904167175293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0015819629958296502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8278213941268923,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 0.0006190512846292057,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7240213863213733,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0543052572560874,
            "feature_preprocessor:select_rates_classification:alpha": 0.1621539871367452,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2207346250649243,
        "time": 0.6707439422607422,
        "additional_info": {
            "duration": 0.6536011695861816,
            "num_run": 296,
            "train_loss": 1.199749972391156,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00042282695874434466,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016693613608034904,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.00048024318202676453,
            "feature_preprocessor:select_rates_classification:alpha": 0.2433282161670437,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1225748062133789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.179923295571904e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006731967381187483,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 0.004945439100477539,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0721735594375162,
            "feature_preprocessor:select_rates_classification:alpha": 0.27745870019916835,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12339496612548828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002855423572644921,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015250750477628988,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.005218491310980963,
            "feature_preprocessor:select_rates_classification:alpha": 0.0522630055478778,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2168534348514002,
        "time": 0.4651463031768799,
        "additional_info": {
            "duration": 0.4381697177886963,
            "num_run": 299,
            "train_loss": 1.2063268544202894,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.015147456217882195,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042169767319628806,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 299,
            "classifier:CustomMLPClassifier:tol": 1.0554637041780036e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026304023341892037,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4030272222731952,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1924081462327059,
        "time": 6.45044207572937,
        "additional_info": {
            "duration": 6.438697099685669,
            "num_run": 300,
            "train_loss": 1.1312057608894406,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004326020538198746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011946000739288332,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.00018290386210926423,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 453,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 28.19622636913568,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2645244124404516,
        "time": 1.311082124710083,
        "additional_info": {
            "duration": 1.2908618450164795,
            "num_run": 301,
            "train_loss": 1.1072581908369385,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0085463134601607e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02547394280408425,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 3.240679796244478e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013664951971845595,
            "feature_preprocessor:select_rates_classification:alpha": 0.1631608337567864,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09596800804138184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.8642573543090665e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004421342460798285,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 1.3362138337541971e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002755048664270293,
            "feature_preprocessor:select_rates_classification:alpha": 0.22974632861046104,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1230771541595459,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006264179164004868,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.38834453070555774,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.0003644723006802611,
            "feature_preprocessor:select_rates_classification:alpha": 0.10079954901730417,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12195873260498047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.710184791787259e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13029663793132598,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.0057011105695367135,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021046857558844383,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5430749987150836,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2492667664199641,
        "time": 0.4877908229827881,
        "additional_info": {
            "duration": 0.47547388076782227,
            "num_run": 305,
            "train_loss": 1.2000137709104202,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07985971920333886,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008224165488296292,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 1.4088451287224032e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018040893994938453,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.31833112529717095,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.1996984127235202,
        "time": 2.485408067703247,
        "additional_info": {
            "duration": 2.4736623764038086,
            "num_run": 306,
            "train_loss": 1.0436778726995901,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003897225650619835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01673110329803897,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.00024490069868751766,
            "feature_preprocessor:select_rates_classification:alpha": 0.4229301912535904,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0948481559753418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005232673751148781,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02563494674038323,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 97,
            "classifier:CustomMLPClassifier:tol": 8.062901192225487e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 4.6700954605846565,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.2771580219268799,
        "additional_info": {
            "duration": 0.26620984077453613,
            "num_run": 308,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009091521541397769,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.042913551811991746,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 5.459339014082756e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022000651863322024,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4902073419538,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2348479270335115,
        "time": 0.3639223575592041,
        "additional_info": {
            "duration": 0.35089993476867676,
            "num_run": 309,
            "train_loss": 1.1729613196972262,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02169043193275909,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09263020989499986,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 0.0004026492572235244,
            "feature_preprocessor:select_rates_classification:alpha": 0.15805687312556077,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1009378433227539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1534961101245864e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5760505394762119,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 1.3111654958905567e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25726718417997785,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.243355635550646,
        "time": 4.115957975387573,
        "additional_info": {
            "duration": 4.105201244354248,
            "num_run": 311,
            "train_loss": 1.1662669184535333,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004506357568856978,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002345972487550266,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 0.0030223727765665348,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.13970606968647503,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.41129112243652344,
        "additional_info": {
            "duration": 0.3483741283416748,
            "num_run": 312,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.2692790921042813e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05242559822382793,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0005025882829024799,
            "feature_preprocessor:select_percentile_classification:percentile": 17.689901321809366,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2150065959079608,
        "time": 0.6666083335876465,
        "additional_info": {
            "duration": 0.655134916305542,
            "num_run": 313,
            "train_loss": 1.2229737300134291,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009883050362511708,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8284795102382025,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 439,
            "classifier:CustomMLPClassifier:tol": 0.00010103127229854821,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20950318535532442,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2180995200442415,
        "time": 0.5699367523193359,
        "additional_info": {
            "duration": 0.5547988414764404,
            "num_run": 314,
            "train_loss": 1.1879267043286759,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00012989734283028602,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008716116445061019,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 1.2007140690787298e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002086733393143172,
            "feature_preprocessor:select_rates_classification:alpha": 0.3097809066001424,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12400984764099121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001848016617101662,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002814101170796915,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 3.2376738759961066e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7472565237811336,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2417687310476688,
        "time": 5.4354047775268555,
        "additional_info": {
            "duration": 5.4143078327178955,
            "num_run": 316,
            "train_loss": 1.1860486545349729,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03545002221195374,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26204725584609057,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 465,
            "classifier:CustomMLPClassifier:tol": 3.1566072610225906e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003033913546054992,
            "feature_preprocessor:select_rates_classification:alpha": 0.40731364938888936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1607990264892578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.5726218635659048e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2742761415799281,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 1.9356579412965638e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.052651909464724055,
            "feature_preprocessor:select_percentile_classification:percentile": 18.726628749450768,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2444454573936294,
        "time": 2.5023200511932373,
        "additional_info": {
            "duration": 2.4914681911468506,
            "num_run": 318,
            "train_loss": 1.2195090329515483,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005937421380603888,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009303005189017914,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 1.0450525201092433e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034545196148799986,
            "feature_preprocessor:select_rates_classification:alpha": 0.1032697586533227,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10141611099243164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.906382764840931e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.42452018364878064,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 5.363123873020829e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2741969897804779,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0968790054321289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00792437477670606,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04013731136892593,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0003642031353545241,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08402028124475694,
            "feature_preprocessor:select_rates_classification:alpha": 0.2904461289348753,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12309002876281738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6647472297267012e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008995137382818855,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.004785810473302885,
            "feature_preprocessor:select_rates_classification:alpha": 0.11667515235911823,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.25232887268066406,
        "additional_info": {
            "duration": 0.23204493522644043,
            "num_run": 322,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09668764865333607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7303342414204812,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.008383506135698096,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004852995768423573,
            "feature_preprocessor:select_rates_classification:alpha": 0.293543758608539,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09648275375366211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001902397097229421,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004228648694829437,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 0.007205408524794825,
            "feature_preprocessor:select_rates_classification:alpha": 0.2581761063655379,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09580683708190918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004009578510583432,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00494847944691353,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 0.0002383403773168613,
            "feature_preprocessor:select_rates_classification:alpha": 0.31875534533850924,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5451889038085938,
        "additional_info": {
            "duration": 0.5326731204986572,
            "num_run": 325,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03662080241058731,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1252914017701095,
            "classifier:CustomMLPClassifier:max_iter": 368,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 6.54022313913995e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.0816252356756422,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12289690971374512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.362114139228217e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6047816237691814,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 1.3482544567164973e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04715263324755527,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1151,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.20490037539163095,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.9160950183868408,
        "additional_info": {
            "duration": 0.9047050476074219,
            "num_run": 327,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002469049338599668,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8765522453279532,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.0001433620249750311,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003047987514152301,
            "feature_preprocessor:select_rates_classification:alpha": 0.36946512044309104,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09639716148376465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.9480509357942465e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00163439557498626,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 1.4615605497525447e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.19961282765283583,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2294226040736846,
        "time": 3.40775990486145,
        "additional_info": {
            "duration": 3.3959250450134277,
            "num_run": 329,
            "train_loss": 1.2292765521358204,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.27679081373709e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026463911221901795,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 0.0010104433477852695,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008827453454509998,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1480,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.10072318601013745,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.25181587484448,
        "time": 1.5001740455627441,
        "additional_info": {
            "duration": 1.489104986190796,
            "num_run": 330,
            "train_loss": 1.0172294239482975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00588484314648261,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013959385498658987,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.0008302805574251201,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00034253380263014654,
            "feature_preprocessor:select_rates_classification:alpha": 0.32385573088860115,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12810111045837402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.038335340083746686,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001892872968960554,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.0074924768210540395,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.95615453898659,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11768850238384933,
            "feature_preprocessor:select_percentile_classification:percentile": 55.36995474102219,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2071414467923214,
        "time": 0.4629049301147461,
        "additional_info": {
            "duration": 0.4511830806732178,
            "num_run": 332,
            "train_loss": 1.191322644574581,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.795440006000365e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016713952899938237,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.00018424329402702853,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006763065884787527,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9295522271832477,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1964792510314386,
        "time": 2.319591999053955,
        "additional_info": {
            "duration": 2.305020809173584,
            "num_run": 333,
            "train_loss": 1.1856791367313515,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.4109045404889884e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.360224805663475,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.002681261196160756,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5938257343684996,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2809628246579916,
        "time": 0.8102848529815674,
        "additional_info": {
            "duration": 0.787315845489502,
            "num_run": 334,
            "train_loss": 1.1541312217666748,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08890840027002772,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2943228156082466,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 0.0026298927332799845,
            "feature_preprocessor:select_rates_classification:alpha": 0.08972015066089518,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09531283378601074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.4277023160863542e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022216004990233706,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 1.0867034640645701e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005229202335038375,
            "feature_preprocessor:select_rates_classification:alpha": 0.49330517430740795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12808680534362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005227254253975372,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001916099052945271,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 0.0003461327111167493,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28822342785385724,
            "feature_preprocessor:select_rates_classification:alpha": 0.04505753611850961,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09508872032165527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.543604710286178e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011206719029557687,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.0001373012656165408,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 713,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 63.425625369248564,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2094869945288909,
        "time": 7.8322789669036865,
        "additional_info": {
            "duration": 7.8219194412231445,
            "num_run": 338,
            "train_loss": 1.0161417003729225,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.04015099330172e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0880612858262125,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 1.415568156621793e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030754691783150736,
            "feature_preprocessor:select_rates_classification:alpha": 0.11849143741602866,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09552311897277832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006939917835010826,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024296706121123196,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 1.2412741673248662e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7671792196678057,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23959011978813577,
            "feature_preprocessor:select_rates_classification:alpha": 0.2090006803190119,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.23339223861694336,
        "additional_info": {
            "duration": 0.22202706336975098,
            "num_run": 340,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013005280817229213,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01495812253699886,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 2.4131598096140868e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.27343435320212545,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12345409393310547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.940834110869816e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018359098127851293,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 0.0003644873784650412,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00480982406723107,
            "feature_preprocessor:select_rates_classification:alpha": 0.27146790606740695,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10147690773010254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.0888225836106287e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002902602423725392,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 129,
            "classifier:CustomMLPClassifier:tol": 0.0012885890512470191,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011568596055437468,
            "feature_preprocessor:select_rates_classification:alpha": 0.3941451740969321,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.217272478564748,
        "time": 0.2371981143951416,
        "additional_info": {
            "duration": 0.22356486320495605,
            "num_run": 343,
            "train_loss": 1.1977820485845239,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06002509482115895,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.33554188044573896,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.00012304303702211382,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27056434279251274,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.6975259780883789,
        "additional_info": {
            "duration": 0.684722900390625,
            "num_run": 344,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0710486705219844e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0691729328269459,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 5.1391910076541576e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2286151771766934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12304925918579102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012150485189065705,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08461272015033452,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0011479203790839207,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03053506011075822,
            "feature_preprocessor:select_percentile_classification:percentile": 92.21716856709062,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.5996942520141602,
        "additional_info": {
            "duration": 0.5810689926147461,
            "num_run": 346,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010499674394091963,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.053927806584535935,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.00039492535225277265,
            "feature_preprocessor:select_percentile_classification:percentile": 39.72343093007539,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2101942004584094,
        "time": 0.3609018325805664,
        "additional_info": {
            "duration": 0.35074877738952637,
            "num_run": 347,
            "train_loss": 1.1780764164978301,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.463873851851034e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015217679267806875,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.0021216530559852063,
            "feature_preprocessor:select_percentile_classification:percentile": 86.86125269934243,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.217992592163582,
        "time": 0.49881482124328613,
        "additional_info": {
            "duration": 0.48599696159362793,
            "num_run": 348,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.027527690200157575,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1380302263043753,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 3.9695820664420296e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09491998251012188,
            "feature_preprocessor:select_rates_classification:alpha": 0.31969195761402913,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10103702545166016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001539722040889227,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03886717787710286,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.002736580992134819,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023958103392489403,
            "feature_preprocessor:select_percentile_classification:percentile": 41.79663359033409,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2376598067739486,
        "time": 0.8845570087432861,
        "additional_info": {
            "duration": 0.8719558715820312,
            "num_run": 350,
            "train_loss": 1.0665851747771034,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.086836289253638e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6260812049153747,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 0.001574417227343715,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.659074860829376,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2946822370935573,
        "time": 0.7446305751800537,
        "additional_info": {
            "duration": 0.6683151721954346,
            "num_run": 351,
            "train_loss": 1.2642116048319612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.14429139591306e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01227713761988427,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 1.0194622071307666e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1027556074628642,
            "feature_preprocessor:select_rates_classification:alpha": 0.43251434765271835,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09659481048583984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4500500259363762e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03517724743949805,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 1.091005698592696e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4767460133643867,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12268996238708496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03883455244193515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5488237939420406,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.0002742844154379908,
            "feature_preprocessor:select_percentile_classification:percentile": 6.228434880664021,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.5441720485687256,
        "additional_info": {
            "duration": 0.5294477939605713,
            "num_run": 354,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.6588356910964074e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01365811054580748,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 72,
            "classifier:CustomMLPClassifier:tol": 0.0010564128658308294,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003358524687194672,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 797,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 18.386012771252748,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2272866903335475,
        "time": 0.939892053604126,
        "additional_info": {
            "duration": 0.9294610023498535,
            "num_run": 355,
            "train_loss": 1.1734386819411808,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008240165236067083,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009235355772101491,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.000690697812364365,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04200466042394176,
            "feature_preprocessor:select_rates_classification:alpha": 0.2954327162743542,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2462470531463623,
        "additional_info": {
            "duration": 0.23488187789916992,
            "num_run": 356,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.060512370318212216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024945811237398724,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 126,
            "classifier:CustomMLPClassifier:tol": 0.0010618600165888219,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3658627931382187,
            "feature_preprocessor:select_rates_classification:alpha": 0.4828500059534752,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12294507026672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.2405422427266825e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0044498130998582,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.0001746723907135247,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010881455923517461,
            "feature_preprocessor:select_rates_classification:alpha": 0.048536561506501624,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5853979587554932,
        "additional_info": {
            "duration": 0.5598101615905762,
            "num_run": 358,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0034411911236400653,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021269656855378,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 5.5694020587157696e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015616605219124988,
            "feature_preprocessor:select_rates_classification:alpha": 0.09911492643276305,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12245512008666992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.79178928280947e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12481203922843602,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.0002851710471563449,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010538147671879237,
            "feature_preprocessor:select_rates_classification:alpha": 0.05546945869306243,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1284191608428955,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006907199327686711,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3971216951988815,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 4.200715323781469e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002969226630071964,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.886502968591959,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.283269003286735,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7212443038995417,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2468711583521268,
        "time": 0.7490630149841309,
        "additional_info": {
            "duration": 0.730353832244873,
            "num_run": 361,
            "train_loss": 1.2132259962765473,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00015930210205176816,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010537421418390973,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.0015403446095654347,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.33263740758555826,
            "feature_preprocessor:select_rates_classification:alpha": 0.49052496642813903,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12790489196777344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005998310497618477,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01569437801272217,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 0.00013835072329960318,
            "feature_preprocessor:select_rates_classification:alpha": 0.17806527365611574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 1.1792528629302979,
        "additional_info": {
            "duration": 1.1625819206237793,
            "num_run": 363,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.660225598832714e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012405608093215683,
            "classifier:CustomMLPClassifier:max_iter": 152,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0002619321558835506,
            "feature_preprocessor:select_rates_classification:alpha": 0.15089495625320679,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12841200828552246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09668764865333607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4393535995308128,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.008383506135698096,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000993319608354022,
            "feature_preprocessor:select_rates_classification:alpha": 0.2582258071846668,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12699508666992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.041902937236881e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022871362892905394,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.0009369702570052593,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033946518147926,
            "feature_preprocessor:select_rates_classification:alpha": 0.18647750942388522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0964059829711914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008150426254718203,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024779506949373685,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 1.3679420381793594e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011027627674955133,
            "feature_preprocessor:select_rates_classification:alpha": 0.033269584421994784,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09620976448059082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.015667238150645073,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31044225334450565,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 1.3616636674650061e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.020313996290643885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2486152923107396,
        "time": 0.8644559383392334,
        "additional_info": {
            "duration": 0.8483121395111084,
            "num_run": 368,
            "train_loss": 1.1196147940735768,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011421471798542424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3563479246997705,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 1.6016249380262684e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3014093006234025,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12749385833740234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1284280111752606e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.41869635581042436,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 1.2304839183126088e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.2799888502047364,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2353541860019719,
        "time": 1.2277281284332275,
        "additional_info": {
            "duration": 1.216440200805664,
            "num_run": 370,
            "train_loss": 1.2329132491651051,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3401355706377184e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 1.1582260654747037e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3306980575694381,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10002374649047852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010457670288418408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34349563946349226,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.0020038686721610293,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09777236074187087,
            "feature_preprocessor:select_rates_classification:alpha": 0.03630552194423065,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09714794158935547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.430957351172086e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7912653619360985,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 0.0016042640003092214,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017170274073738086,
            "feature_preprocessor:select_rates_classification:alpha": 0.053636622516257025,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2378257153483356,
        "time": 0.6253471374511719,
        "additional_info": {
            "duration": 0.6123120784759521,
            "num_run": 373,
            "train_loss": 1.2057385031432921,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.189113350782964e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021796724606734657,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.00022291796124003063,
            "feature_preprocessor:select_rates_classification:alpha": 0.47685470293043913,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09702229499816895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3405379090674878e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.41869635581042436,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 1.2304839183126088e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.23657938932677286,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5226497650146484,
        "additional_info": {
            "duration": 0.5101990699768066,
            "num_run": 375,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004166405914201133,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04343499273720117,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.00035281222962752986,
            "feature_preprocessor:select_percentile_classification:percentile": 46.966657094133346,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.6671931743621826,
        "additional_info": {
            "duration": 0.6562108993530273,
            "num_run": 376,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002676207006134238,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015974041765422244,
            "classifier:CustomMLPClassifier:max_iter": 407,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 0.0026643987067775862,
            "feature_preprocessor:select_percentile_classification:percentile": 88.58876497303967,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2263905302698672,
        "time": 0.9054927825927734,
        "additional_info": {
            "duration": 0.890312910079956,
            "num_run": 377,
            "train_loss": 1.2265708517942522,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.057592559995835936,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03194874567458651,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.0053940536923546565,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30945858921121705,
            "feature_preprocessor:select_rates_classification:alpha": 0.39429243509990647,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12784886360168457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001691435255848444,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15472356668632922,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.0001593030811056457,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009097734769882158,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 221,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.22910118064033422,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2469186253135356,
        "time": 1.0157527923583984,
        "additional_info": {
            "duration": 1.00486421585083,
            "num_run": 379,
            "train_loss": 1.130271382150282,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4626945844787764e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.29118136243020826,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.009328606560811267,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.522822006545244,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2457446674655528,
        "time": 0.8365881443023682,
        "additional_info": {
            "duration": 0.8246288299560547,
            "num_run": 380,
            "train_loss": 1.2109858774858908,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007210262917980619,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009888397734963717,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 1.0450525201092433e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034545196148799986,
            "feature_preprocessor:select_rates_classification:alpha": 0.12368226347828894,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12395381927490234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09404457745544914,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6429343642308517,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.0035468974829291297,
            "feature_preprocessor:select_rates_classification:alpha": 0.4731432568665587,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09681487083435059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1105517785890968e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011353849577428701,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.0013542918997326377,
            "feature_preprocessor:select_rates_classification:alpha": 0.08753164128862964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09668993949890137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009489900121896485,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5158999336335954,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.0032934957705611496,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017685336607735607,
            "feature_preprocessor:select_rates_classification:alpha": 0.21828399103671833,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.33972620964050293,
        "additional_info": {
            "duration": 0.32891273498535156,
            "num_run": 384,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005499723283921683,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03354254675350074,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 1.0811260121234323e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004564616412167624,
            "feature_preprocessor:select_rates_classification:alpha": 0.06207861665311302,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.318282335167528,
        "time": 0.6662518978118896,
        "additional_info": {
            "duration": 0.6534490585327148,
            "num_run": 385,
            "train_loss": 1.2608934841497312,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0767775966932972,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006798145854521549,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.00010531571860192057,
            "feature_preprocessor:select_rates_classification:alpha": 0.07538962752707272,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09679293632507324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.347292979061151e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006563169736785542,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 133,
            "classifier:CustomMLPClassifier:tol": 0.005963924053189775,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12578509125091164,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222250541344979,
        "time": 0.32651782035827637,
        "additional_info": {
            "duration": 0.31313514709472656,
            "num_run": 387,
            "train_loss": 1.1888605910900494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00013702411403202131,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09579616766319866,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.00024263553630344054,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010538147671879237,
            "feature_preprocessor:select_rates_classification:alpha": 0.05546945869306243,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1242220401763916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010190231161239733,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07911835272599536,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 4.6407066157325215e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002496743426511647,
            "feature_preprocessor:select_rates_classification:alpha": 0.4380402268044601,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09744787216186523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7874072372995497e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020084265301040416,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.0001064436101786187,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020417454564805834,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.713059970422687,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.235508815302072,
        "time": 1.0447559356689453,
        "additional_info": {
            "duration": 1.0320990085601807,
            "num_run": 390,
            "train_loss": 1.1818715126114931,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00023119505655354268,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9264920752156686,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.00013767502423637872,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005942146819009761,
            "feature_preprocessor:select_rates_classification:alpha": 0.10800517120715122,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.123931884765625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.6975538767101646e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010461146289104395,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 103,
            "classifier:CustomMLPClassifier:tol": 0.0005471902564177022,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003632534507956524,
            "feature_preprocessor:select_rates_classification:alpha": 0.08251976378603353,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12338018417358398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02614879346812024,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010909225389350697,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.0001216819291883271,
            "feature_preprocessor:select_rates_classification:alpha": 0.021599843899911847,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0957489013671875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0014704679961037e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012774299179633356,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.00013986219570370198,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4951065115625027,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09629273414611816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0026429894334651033,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002193111243817243,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 6.351244527041614e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004658213741099266,
            "feature_preprocessor:select_rates_classification:alpha": 0.23531033465488463,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12305521965026855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010020403122883036,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36298178321984104,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 0.005673089058525464,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03970025662144081,
            "feature_preprocessor:select_rates_classification:alpha": 0.48345158898473295,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09602117538452148,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01146208409158416,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024594671979707133,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 2.299028788145745e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22858954656645877,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09584808349609375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.978144411140796e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006149378244713569,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.000363377178520002,
            "feature_preprocessor:select_rates_classification:alpha": 0.36660749684120425,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10155224800109863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.2611707073939074e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006100441520839074,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 4.514618555291127e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007768544329143436,
            "feature_preprocessor:select_rates_classification:alpha": 0.41018490585330847,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1270442008972168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00042249453350567273,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013023786113944372,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 8.17877741826016e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021940856139111256,
            "feature_preprocessor:select_percentile_classification:percentile": 18.98867753940957,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.204773334852447,
        "time": 3.2144927978515625,
        "additional_info": {
            "duration": 3.202955722808838,
            "num_run": 400,
            "train_loss": 1.1921562259840741,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02291439703443496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012200533132131176,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.0005409027358249812,
            "feature_preprocessor:select_rates_classification:alpha": 0.28434926488680096,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1275310516357422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007829523279672979,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025071307770847776,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 70,
            "classifier:CustomMLPClassifier:tol": 0.0050979257613724665,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003727527065267376,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8542836060891512,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2405402543836073,
        "time": 0.28841328620910645,
        "additional_info": {
            "duration": 0.27428603172302246,
            "num_run": 402,
            "train_loss": 1.1790618668101847,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4503178230080913e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008980550441739048,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 381,
            "classifier:CustomMLPClassifier:tol": 0.0001537159881362534,
            "feature_preprocessor:select_rates_classification:alpha": 0.4599682647707528,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1295318603515625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.026148324832577348,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09690379268134429,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.0013471132693476699,
            "feature_preprocessor:select_rates_classification:alpha": 0.49709135727860504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12289571762084961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017061058441283478,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042609853652960696,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 1.785739878300507e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 331,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.1867350048720483,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2186055298523717,
        "time": 0.4379580020904541,
        "additional_info": {
            "duration": 0.4251260757446289,
            "num_run": 405,
            "train_loss": 1.1667015586794767,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.034353516961751346,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.056490238326740896,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 0.0011905984311429132,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008289316036194884,
            "feature_preprocessor:select_rates_classification:alpha": 0.49709135727860504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10253190994262695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005586354502144876,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5931894014921649,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.00021417172669594185,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006011911047103855,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8820477200111406,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.008059012998108656,
            "feature_preprocessor:select_rates_classification:alpha": 0.04803586369397534,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.6068160533905029,
        "additional_info": {
            "duration": 0.5818250179290771,
            "num_run": 407,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.5548049347510467e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01948604820759405,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 0.00012324402799588995,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00463338757161263,
            "feature_preprocessor:select_rates_classification:alpha": 0.23506326291896168,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12847065925598145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.027696971814735443,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.056490238326740896,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 0.0011905984311429132,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004789534642021783,
            "feature_preprocessor:select_rates_classification:alpha": 0.48752555400228187,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12278318405151367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0026969780811376925,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22645341692903895,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 0.0013656612790564552,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010186840652201918,
            "feature_preprocessor:select_rates_classification:alpha": 0.16369712397070438,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12360787391662598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5796608068616794e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22105077562636805,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.008925303291495344,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1181,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 94.5165001264715,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1988732386208703,
        "time": 0.6934089660644531,
        "additional_info": {
            "duration": 0.6675131320953369,
            "num_run": 411,
            "train_loss": 1.1785517858792787,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.017649264191900424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005062984957766001,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 1.0422146893530486e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4934415725816031,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09600019454956055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005550859602054142,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018905660418734333,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.00010059439589802364,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.060536347181842975,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2129794864728958,
        "time": 1.0990409851074219,
        "additional_info": {
            "duration": 1.0877599716186523,
            "num_run": 413,
            "train_loss": 1.1960494426774282,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00032968618720431866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024626411104256677,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 5.0075383333420335e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2711592934569999,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12170910835266113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01946815233434271,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008550331728739869,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 135,
            "classifier:CustomMLPClassifier:tol": 5.6907807232520725e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.056310247055232944,
            "feature_preprocessor:select_rates_classification:alpha": 0.07521338307886655,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09619402885437012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007178392484827622,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013648642834743072,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 0.007523603020696313,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00461653213315253,
            "feature_preprocessor:select_rates_classification:alpha": 0.4878511159617783,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12378597259521484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.039826960921287e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8445876140121712,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 141,
            "classifier:CustomMLPClassifier:tol": 0.0005398271376662603,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039168217102889815,
            "feature_preprocessor:select_rates_classification:alpha": 0.4993112066932893,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1009819507598877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.1048929923818498e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006470560326914176,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.000649682696038254,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1811,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 38.16765170728539,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2431572729118787,
        "time": 2.022987127304077,
        "additional_info": {
            "duration": 2.008462905883789,
            "num_run": 418,
            "train_loss": 1.0564872543642083,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00040814478817950966,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.060108973950597645,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.002459195804977258,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45359225285500787,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6861055522709333,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.5257627964019775,
        "additional_info": {
            "duration": 0.5104529857635498,
            "num_run": 419,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05685107077941261,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024601432291358614,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 1.0347840517110826e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013990650745245717,
            "feature_preprocessor:select_rates_classification:alpha": 0.4408882196365491,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12265801429748535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06808299517172908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2232406845532426,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.00026748175883139797,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.046156074848046486,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9325141062390314,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2266530558182964,
        "time": 0.6464638710021973,
        "additional_info": {
            "duration": 0.6349470615386963,
            "num_run": 421,
            "train_loss": 1.0898175614249783,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.2916738333087666e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013321069918988037,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.0007880206843171061,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1261,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2908695438369098,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.6051731109619141,
        "additional_info": {
            "duration": 0.5948927402496338,
            "num_run": 422,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00026407756412668833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009687044983095959,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.004774044182951078,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06535242071567607,
            "feature_preprocessor:select_rates_classification:alpha": 0.4686595177296785,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12791824340820312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0038090381823689544,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017572784143525877,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 1.1174792555269641e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001890581031838345,
            "feature_preprocessor:select_rates_classification:alpha": 0.41692132201627935,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09607505798339844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09872032092610215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005374060175485571,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 3.9204757018872636e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03760642409071854,
            "feature_preprocessor:select_rates_classification:alpha": 0.06949074671662388,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1285407543182373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009313753130464145,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004566408741669679,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 7.530434350344865e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06323195324809278,
            "feature_preprocessor:select_rates_classification:alpha": 0.21727163715244963,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.5970649719238281,
        "additional_info": {
            "duration": 0.5784378051757812,
            "num_run": 426,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002154436698484941,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00945699708499419,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 1.3630470444179387e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00090886570286699,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.659443908612471,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2332981808472172,
        "time": 1.5030620098114014,
        "additional_info": {
            "duration": 1.4907629489898682,
            "num_run": 427,
            "train_loss": 1.0449553454550433,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002224251329345228,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036581147530671484,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 0.0007552247262334013,
            "feature_preprocessor:select_rates_classification:alpha": 0.4985397683491685,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12322306632995605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.049915312321091296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00043389563666735626,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.000165717168268181,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005661952403908229,
            "feature_preprocessor:select_rates_classification:alpha": 0.03429774040658867,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2099683405607329,
        "time": 2.6500601768493652,
        "additional_info": {
            "duration": 2.6356759071350098,
            "num_run": 429,
            "train_loss": 1.192506710551349,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.437826551584117e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020858960325190488,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.0027425268299769525,
            "feature_preprocessor:select_percentile_classification:percentile": 70.39115616621726,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.22945691646734,
        "time": 0.573065996170044,
        "additional_info": {
            "duration": 0.5624959468841553,
            "num_run": 430,
            "train_loss": 1.1689461310378806,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.787753741131082e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001235814036707891,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 0.004027682386057042,
            "feature_preprocessor:select_rates_classification:alpha": 0.07138071536818488,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09760880470275879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021692414063929541,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6113672330408845,
            "classifier:CustomMLPClassifier:max_iter": 124,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 1.1458187968539416e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.23060642037575546,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09704303741455078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001768684856413992,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011041159952037308,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 1.1903457080879715e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.21428291282381176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.3829488754272461,
        "additional_info": {
            "duration": 0.3662388324737549,
            "num_run": 433,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0036620635620912387,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18905039678476018,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 337,
            "classifier:CustomMLPClassifier:tol": 0.003722672666291951,
            "feature_preprocessor:select_rates_classification:alpha": 0.28733624618121384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1244509220123291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2534278200804343e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03741312963856111,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 0.00014040010439933103,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010167096055145905,
            "feature_preprocessor:select_rates_classification:alpha": 0.2655244718667829,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2432921873245395,
        "time": 5.9919538497924805,
        "additional_info": {
            "duration": 5.980844974517822,
            "num_run": 435,
            "train_loss": 1.035708076130529,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00015376911855202255,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35920374292038276,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 0.0016108277203809476,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00433559569698365,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4542539262066717,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.221233817476416,
        "time": 0.47888779640197754,
        "additional_info": {
            "duration": 0.464550256729126,
            "num_run": 436,
            "train_loss": 1.1979619245501711,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01813114722054774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7262062401571635,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 5.4424132857257835e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035356586556893686,
            "feature_preprocessor:select_rates_classification:alpha": 0.45981292535003115,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09574198722839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2620568481688492e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06608713321775149,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.001541088062540448,
            "feature_preprocessor:select_rates_classification:alpha": 0.18964810551072653,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2833831310272217,
        "additional_info": {
            "duration": 0.2707860469818115,
            "num_run": 438,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00026462815912541184,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015203010593216545,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.004176634543403899,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025391593725488516,
            "feature_preprocessor:select_rates_classification:alpha": 0.16806454436753795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1233830451965332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.209499502563675e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022439308589987713,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 364,
            "classifier:CustomMLPClassifier:tol": 0.00028627706007807087,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003110805218009287,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7334090445075099,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07155041571855345,
            "feature_preprocessor:select_percentile_classification:percentile": 98.17132026271966,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2330697151392749,
        "time": 2.79069185256958,
        "additional_info": {
            "duration": 2.778316020965576,
            "num_run": 440,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005618942394849288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8104748301145289,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 9.123222292727474e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00035388927301449396,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9494711460908493,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0109913200272099,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.15106210191473113,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2196812332837161,
        "time": 0.43111586570739746,
        "additional_info": {
            "duration": 0.41655802726745605,
            "num_run": 441,
            "train_loss": 1.2143399517295663,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.48164743870837e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0077155301467645545,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0014214162682094865,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015046798706557034,
            "feature_preprocessor:select_rates_classification:alpha": 0.491589371287781,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10169601440429688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005480884593432268,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10002498082832134,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 0.0036656734911153445,
            "feature_preprocessor:select_rates_classification:alpha": 0.07877339295417458,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2464375205254012,
        "time": 0.3710620403289795,
        "additional_info": {
            "duration": 0.3609619140625,
            "num_run": 443,
            "train_loss": 1.2093754774661538,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2651756321669382e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12183651264881189,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 0.0001618008095472556,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0328261262260177,
            "feature_preprocessor:select_rates_classification:alpha": 0.34911425737080226,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10166597366333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0020101085880573277,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004454903829263758,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 8.010500710909143e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 25.198052345257306,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5889368057250977,
        "additional_info": {
            "duration": 0.5649600028991699,
            "num_run": 445,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006340806469082843,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7241558661570655,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 378,
            "classifier:CustomMLPClassifier:tol": 2.361243824646465e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06432133877838382,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10131216049194336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0004151056959673202,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06630643062533148,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.00012757289112561197,
            "feature_preprocessor:select_rates_classification:alpha": 0.47455431282896543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1282958984375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011024792643547009,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00034008003146827274,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 1.3111121545230093e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02854170112729002,
            "feature_preprocessor:select_rates_classification:alpha": 0.08116127337785378,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12310600280761719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002526693579062268,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22647256850330247,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 167,
            "classifier:CustomMLPClassifier:tol": 0.0005647820080693314,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1823,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 41.139649371139626,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.235103165138293,
        "time": 1.2935059070587158,
        "additional_info": {
            "duration": 1.2273190021514893,
            "num_run": 449,
            "train_loss": 1.1796025925353226,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00022625168346935963,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14566838867725038,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.0018842842022174758,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14058617103800242,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4540268556272772,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.41348695755004883,
        "additional_info": {
            "duration": 0.39811205863952637,
            "num_run": 450,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018569206605478273,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24267491943833866,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 2.1422187891294916e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003506774911364478,
            "feature_preprocessor:select_rates_classification:alpha": 0.32662025147703305,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2513010501861572,
        "additional_info": {
            "duration": 0.23754429817199707,
            "num_run": 451,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.216067579748054e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013519863415261353,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 127,
            "classifier:CustomMLPClassifier:tol": 0.00015160789610967567,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008128543678994143,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6247474354815042,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2002049004952817,
        "time": 1.4691760540008545,
        "additional_info": {
            "duration": 1.4575061798095703,
            "num_run": 452,
            "train_loss": 1.18937906712519,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00037970950460824006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9696707200569847,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 1.5003920458697862e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3582734720590641,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.26825881004333496,
        "additional_info": {
            "duration": 0.24835610389709473,
            "num_run": 453,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.01787360816285e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001897995063658533,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 0.005092474632434884,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1181565084559741,
            "feature_preprocessor:select_rates_classification:alpha": 0.37844942930720804,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1289060115814209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.593609256243085e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.62336232841672,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.0016533136977744229,
            "feature_preprocessor:select_rates_classification:alpha": 0.4728026108306712,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12755489349365234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04660964614179865,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07639310644611254,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.0020584351650066186,
            "feature_preprocessor:select_rates_classification:alpha": 0.3927022898573768,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09652304649353027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08649793081038643,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013764743020945123,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 97,
            "classifier:CustomMLPClassifier:tol": 0.0008098932978226317,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1774,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9081420954596773,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2343348619778733,
        "time": 2.83703875541687,
        "additional_info": {
            "duration": 2.8207509517669678,
            "num_run": 457,
            "train_loss": 1.0659821562707719,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0168242799502209e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0049972788769229335,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.0014867059587603886,
            "feature_preprocessor:select_rates_classification:alpha": 0.08753164128862964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10962796211242676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.581018061349997e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035555344832473956,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.0008377801377968819,
            "feature_preprocessor:select_rates_classification:alpha": 0.15415122042626223,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12285399436950684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.698021660820153e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22171969042285058,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0034893635863192355,
            "feature_preprocessor:select_rates_classification:alpha": 0.1084330908126328,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09630107879638672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001206588590482264,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007423384188183857,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 392,
            "classifier:CustomMLPClassifier:tol": 5.548931608076029e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8042858242901334,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05419605961340353,
            "feature_preprocessor:select_percentile_classification:percentile": 44.035127526284114,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2486053956639882,
        "time": 3.480847120285034,
        "additional_info": {
            "duration": 3.4698641300201416,
            "num_run": 461,
            "train_loss": 1.0227790536327412,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.57084026396036e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003180075107998045,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 7.160874819582432e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008482833855326728,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6025213790962237,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231503506331813,
        "time": 1.3836798667907715,
        "additional_info": {
            "duration": 1.3716309070587158,
            "num_run": 462,
            "train_loss": 1.1718617961916487,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.161411053458416e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024988388592098548,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.00015245308624185061,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02351863662167551,
            "feature_preprocessor:select_rates_classification:alpha": 0.423903543701343,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.4285891056060791,
        "additional_info": {
            "duration": 0.4129979610443115,
            "num_run": 463,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.837642544603522e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022431836375583533,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 2.984904711135205e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14525022844283805,
            "feature_preprocessor:select_percentile_classification:percentile": 88.29231350884398,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.43747806549072266,
        "additional_info": {
            "duration": 0.4268031120300293,
            "num_run": 464,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.325968798436306e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27359170932329235,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.009532953409712538,
            "feature_preprocessor:select_rates_classification:alpha": 0.3326063131281211,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12456607818603516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.444262430287676e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09557209458133524,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 304,
            "classifier:CustomMLPClassifier:tol": 1.077190655837758e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19589071974619784,
            "feature_preprocessor:select_rates_classification:alpha": 0.3522783312501727,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12421822547912598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009617594282001436,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01875724985740183,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.003158586502224871,
            "feature_preprocessor:select_rates_classification:alpha": 0.4252696037760633,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12368011474609375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.5049346942231563e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9996039761341552,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.005361979076782034,
            "feature_preprocessor:select_rates_classification:alpha": 0.36277472280094775,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.3485579490661621,
        "additional_info": {
            "duration": 0.3355231285095215,
            "num_run": 468,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.4192942766727452e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009335252128006878,
            "classifier:CustomMLPClassifier:max_iter": 195,
            "classifier:CustomMLPClassifier:num_units": 141,
            "classifier:CustomMLPClassifier:tol": 0.00012741025608637381,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10829903595623562,
            "feature_preprocessor:select_percentile_classification:percentile": 70.97090185667018,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.211720914656282,
        "time": 3.6565539836883545,
        "additional_info": {
            "duration": 3.6462368965148926,
            "num_run": 469,
            "train_loss": 1.1515149240579352,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006429379883153683,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012813880898229392,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.0005030363179162362,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1298,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6343460442852206,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2708393260967046,
        "time": 0.7405350208282471,
        "additional_info": {
            "duration": 0.727039098739624,
            "num_run": 470,
            "train_loss": 1.1546944538777024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010542804184733474,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10093559724501294,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 0.0003323470606937041,
            "feature_preprocessor:select_percentile_classification:percentile": 3.4972088629026317,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.34053468704223633,
        "additional_info": {
            "duration": 0.32759571075439453,
            "num_run": 471,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.552270418516874e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07802884010039618,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.00017546139560496574,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005350852169661752,
            "feature_preprocessor:select_rates_classification:alpha": 0.25488744542741043,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13838720321655273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.2013146157079596e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013303272297450798,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 0.006709435279930362,
            "feature_preprocessor:select_rates_classification:alpha": 0.3361559382149765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09646224975585938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.4968378876208078e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02026116889774726,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.002369631606461513,
            "feature_preprocessor:select_percentile_classification:percentile": 2.8022824647016678,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.19632816314697266,
        "additional_info": {
            "duration": 0.18543410301208496,
            "num_run": 474,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08385750030099626,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05690051856819358,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 291,
            "classifier:CustomMLPClassifier:tol": 0.0016549801456287427,
            "feature_preprocessor:select_rates_classification:alpha": 0.049327297805006734,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12299585342407227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011868590269638382,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35555497661455604,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 7.360106611414927e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 78.05073736753,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.6512987613677979,
        "additional_info": {
            "duration": 0.6291131973266602,
            "num_run": 476,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005779463059200214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.49590924073093107,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 182,
            "classifier:CustomMLPClassifier:tol": 7.424909675511907e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3006397169886634,
            "feature_preprocessor:select_rates_classification:alpha": 0.0910865705151146,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12329983711242676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011551169331758314,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.71157258870575,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 235,
            "classifier:CustomMLPClassifier:tol": 5.2821946702819824e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22296772658826577,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1285388469696045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004391209848517035,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02045152848299121,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 103,
            "classifier:CustomMLPClassifier:tol": 0.00043161518753591485,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4470643213383046,
            "feature_preprocessor:select_rates_classification:alpha": 0.4956067541324712,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12423491477966309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.6500580422313746e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005242990008414063,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 421,
            "classifier:CustomMLPClassifier:tol": 4.882732897658912e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037114108368592425,
            "feature_preprocessor:select_rates_classification:alpha": 0.02558970586450552,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1286332607269287,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.698545858045429e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015533052300034209,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 1.758542438521152e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00998026156658523,
            "feature_preprocessor:select_rates_classification:alpha": 0.4829230596596357,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2178539339496655,
        "time": 2.0320918560028076,
        "additional_info": {
            "duration": 2.013033866882324,
            "num_run": 481,
            "train_loss": 1.2046222577528205,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.575940060162943e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0030928566664395448,
            "classifier:CustomMLPClassifier:max_iter": 334,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.0008067475717082878,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00042718109145968965,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9669543035248177,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2652875198135844,
        "time": 0.4965839385986328,
        "additional_info": {
            "duration": 0.4793221950531006,
            "num_run": 482,
            "train_loss": 1.184304248697675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03111102374928624,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07459104882590957,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.0021967835897900166,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11345662800128556,
            "feature_preprocessor:select_rates_classification:alpha": 0.18957353675513944,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13010096549987793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012382079316525458,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20513787810560227,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.0006947257022280952,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008092821517605549,
            "feature_preprocessor:select_rates_classification:alpha": 0.08156946036970347,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2083591210147808,
        "time": 0.550757884979248,
        "additional_info": {
            "duration": 0.5374071598052979,
            "num_run": 484,
            "train_loss": 1.1963325986361917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008158104804691793,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031421576453920317,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 2.0694589020070236e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3443619291179579,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 1.0858161449432373,
        "additional_info": {
            "duration": 1.0740978717803955,
            "num_run": 485,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.342177111470465e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021512858510176706,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.0010287577095509513,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009458620050254517,
            "feature_preprocessor:select_rates_classification:alpha": 0.14666089005552627,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3580441474914551,
        "additional_info": {
            "duration": 0.3477778434753418,
            "num_run": 486,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.761623777662906e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0051177938198860295,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 137,
            "classifier:CustomMLPClassifier:tol": 0.0011323092086274735,
            "feature_preprocessor:select_rates_classification:alpha": 0.3961192445821945,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1280841827392578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03378907899311559,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021619568867084485,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 0.00018726764343730097,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002160228029868704,
            "feature_preprocessor:select_rates_classification:alpha": 0.38696912195573174,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.27135586738586426,
        "additional_info": {
            "duration": 0.2506380081176758,
            "num_run": 488,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0784517003502442e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003676710917787055,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 2.954296256235529e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01300443279101174,
            "feature_preprocessor:select_rates_classification:alpha": 0.2781172170727592,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12349390983581543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015406775214427812,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 0.00038530379978989396,
            "feature_preprocessor:select_rates_classification:alpha": 0.0997299509958211,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12821078300476074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3718127184101875e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012766274090027983,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 166,
            "classifier:CustomMLPClassifier:tol": 5.0181665875485955e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026637520146009463,
            "feature_preprocessor:select_rates_classification:alpha": 0.324012863695322,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09641575813293457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3827438100710962e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9740966520117051,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.001625312863805659,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011832394976627276,
            "feature_preprocessor:select_rates_classification:alpha": 0.15979901734430219,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09540605545043945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09668764865333607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9676749324430224,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.00627385374527055,
            "feature_preprocessor:select_rates_classification:alpha": 0.2565989032348474,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09847903251647949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0231347396571647e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09524600112776412,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 127,
            "classifier:CustomMLPClassifier:tol": 0.0034728579425659257,
            "feature_preprocessor:select_percentile_classification:percentile": 63.335859033531904,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2290919158683316,
        "time": 0.44149208068847656,
        "additional_info": {
            "duration": 0.4304208755493164,
            "num_run": 494,
            "train_loss": 1.1774468028921738,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.0501270006275616e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012814875156846883,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 0.0037626584373969202,
            "feature_preprocessor:select_rates_classification:alpha": 0.258201457792347,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3262910842895508,
        "additional_info": {
            "duration": 0.30478405952453613,
            "num_run": 495,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.498168673897312e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012459341725512949,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.00010080903535788648,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.738932279863082,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2266774012498311,
            "feature_preprocessor:select_rates_classification:alpha": 0.03455607143952363,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2023610206578423,
        "time": 0.2402811050415039,
        "additional_info": {
            "duration": 0.23022103309631348,
            "num_run": 496,
            "train_loss": 1.1907976383579228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1475541052564052e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4742058965233949,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 1.1582260654747037e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.3306980575694381,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10174274444580078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.749245869474016e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.043958970188900444,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.0002184020249879759,
            "feature_preprocessor:select_rates_classification:alpha": 0.03312737234469558,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12836623191833496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.848624692500314e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7578908711877153,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 0.005210405860324215,
            "feature_preprocessor:select_percentile_classification:percentile": 4.718283592783696,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3002438545227051,
        "additional_info": {
            "duration": 0.2830181121826172,
            "num_run": 499,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01146208409158416,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024594671979707133,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 1.0858615076068955e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2448879088020436,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09634685516357422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.0902810779242684e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07749054075945601,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0023877469561701726,
            "feature_preprocessor:select_rates_classification:alpha": 0.37024048642363133,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0971829891204834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.018715701754544393,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012139711816929538,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.007198145938780978,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8686154354160114,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2246193724921925,
        "time": 0.5095081329345703,
        "additional_info": {
            "duration": 0.49581003189086914,
            "num_run": 502,
            "train_loss": 1.1768102495179533,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011353801797607292,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06955587856824424,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.000495392855223113,
            "feature_preprocessor:select_rates_classification:alpha": 0.2945731792195471,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10185909271240234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.142036341759881e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004800238852660827,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 0.0008817711202934752,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9886562231468975,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22340831847198828,
            "feature_preprocessor:select_rates_classification:alpha": 0.39895981321543844,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.34356117248535156,
        "additional_info": {
            "duration": 0.3292069435119629,
            "num_run": 504,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05707200374594779,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020624034486570558,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.00010778948314559872,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031569622248344155,
            "feature_preprocessor:select_rates_classification:alpha": 0.34901914290250424,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09659290313720703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.8577550332929766e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007739970727324515,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 272,
            "classifier:CustomMLPClassifier:tol": 3.8088369476475116e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008567195000050301,
            "feature_preprocessor:select_rates_classification:alpha": 0.4971960835708974,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09755611419677734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0035480449949956533,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26275146388927073,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.0002577733564730618,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05297385529448249,
            "feature_preprocessor:select_percentile_classification:percentile": 13.389947150862591,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2373852770891625,
        "time": 0.5049028396606445,
        "additional_info": {
            "duration": 0.48416781425476074,
            "num_run": 507,
            "train_loss": 1.214285171724935,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0294955915337174e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8803691206613188,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 2.605720998306486e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.33739472065289905,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12262988090515137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0329851587011483e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032753226713097564,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 1.0157974706676102e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.34361584701721704,
            "feature_preprocessor:select_percentile_classification:percentile": 83.26649687420768,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2210173660833452,
        "time": 0.8942410945892334,
        "additional_info": {
            "duration": 0.8817191123962402,
            "num_run": 509,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.8115709893091443e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031277786674171215,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.0018117109991655275,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00026635765035284715,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7422128417208861,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.35265111923217773,
        "additional_info": {
            "duration": 0.33980703353881836,
            "num_run": 510,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005765425008656511,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2594834328393314,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.0007906438108331578,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003976437926718274,
            "feature_preprocessor:select_rates_classification:alpha": 0.275511353962697,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12518906593322754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005771489257365115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1152735684819054,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 0.0008802771263300628,
            "feature_preprocessor:select_percentile_classification:percentile": 76.20265931450733,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.236249850006884,
        "time": 1.22458815574646,
        "additional_info": {
            "duration": 1.2138690948486328,
            "num_run": 512,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.917665151475109e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014167833959778547,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0012993165544769644,
            "feature_preprocessor:select_rates_classification:alpha": 0.2978103039154522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10049676895141602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00043473070162628147,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0046553188034089785,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.0028710071201111997,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.014920680474819648,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.245012794366908,
        "time": 0.3620920181274414,
        "additional_info": {
            "duration": 0.3422999382019043,
            "num_run": 514,
            "train_loss": 1.2192853244330564,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.2976896376224795e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007364357570827177,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 1.0530555361681472e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008876695927958896,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7329776375841869,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2611461505230526,
        "time": 1.2627320289611816,
        "additional_info": {
            "duration": 1.2494020462036133,
            "num_run": 515,
            "train_loss": 1.1929194857229763,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.613013544013484e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021814569918331738,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.0013350447125182652,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02458060743296013,
            "feature_preprocessor:select_rates_classification:alpha": 0.4412154448618208,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12291717529296875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2015394997023413e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006018250308138425,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 137,
            "classifier:CustomMLPClassifier:tol": 0.003315250529465738,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000625106279013135,
            "feature_preprocessor:select_rates_classification:alpha": 0.1522085989440684,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12285590171813965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.867737698003412e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003999825963205215,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 1.2798268474061642e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21356394604803774,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9817633572638569,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17075292682581222,
            "feature_preprocessor:select_rates_classification:alpha": 0.35716741300119087,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2098585735427219,
        "time": 0.36986780166625977,
        "additional_info": {
            "duration": 0.36013221740722656,
            "num_run": 518,
            "train_loss": 1.1575707378695324,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3401355706377184e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 1.2931712549290995e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3283596661451386,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12877726554870605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002576620754565924,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009602533607347216,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.002108350740946138,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7448578734763056,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.23627476068161,
        "time": 0.44519877433776855,
        "additional_info": {
            "duration": 0.43243908882141113,
            "num_run": 520,
            "train_loss": 1.2008667347107786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.8290667658079505e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002500836864007627,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 0.00015828884297351854,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005127011081536042,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8265043539915623,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27522882144539906,
            "feature_preprocessor:select_rates_classification:alpha": 0.484925721816154,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.24383091926574707,
        "additional_info": {
            "duration": 0.23225903511047363,
            "num_run": 521,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.017182370023503347,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.30797654270978553,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 8.305473243677297e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00414770369077873,
            "feature_preprocessor:select_rates_classification:alpha": 0.30476429492035917,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0956110954284668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.218388185912459e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002232880024410763,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 259,
            "classifier:CustomMLPClassifier:tol": 7.391443569703346e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.47234120712764804,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09585189819335938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1044215723516717e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04510808857059954,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 0.0012576306741588176,
            "feature_preprocessor:select_rates_classification:alpha": 0.35323850318757155,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09604406356811523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0353137606509652e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001669109131910314,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.0018351004225236056,
            "feature_preprocessor:select_rates_classification:alpha": 0.0834984979681062,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10059785842895508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.509322517100639e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9723425966730473,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 1.1820483828085244e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.26912241777620266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2761093039419307,
        "time": 0.4234771728515625,
        "additional_info": {
            "duration": 0.4052317142486572,
            "num_run": 526,
            "train_loss": 1.2381562303724847,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.545525506038362e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7953371152450953,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 0.001010789063743247,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013143586730586826,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6950584218485452,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2380581604465113,
        "time": 0.7289218902587891,
        "additional_info": {
            "duration": 0.7170522212982178,
            "num_run": 527,
            "train_loss": 1.0818197556162907,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00033583830184202943,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017819217067694037,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 3.17326655624154e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06724901526653572,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09632301330566406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0882442018098019e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001272148978487434,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 282,
            "classifier:CustomMLPClassifier:tol": 0.0004771479410221029,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.685165799160804,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2117376207830495,
        "time": 0.9801120758056641,
        "additional_info": {
            "duration": 0.9666428565979004,
            "num_run": 529,
            "train_loss": 1.1865675791756891,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.013262051743148666,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004438824613091797,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.0007705923156384276,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24193509949488975,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4764979204498082,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.218947735182882,
        "time": 0.7977871894836426,
        "additional_info": {
            "duration": 0.7833290100097656,
            "num_run": 530,
            "train_loss": 1.1830474401799187,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000126379535438756,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07305333541446693,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.006393337371163231,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9647104814181502,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11708180856047423,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9437909713354975,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2232813779704506,
        "time": 0.3797571659088135,
        "additional_info": {
            "duration": 0.36439085006713867,
            "num_run": 531,
            "train_loss": 1.1792829660859625,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.674085407446297e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3138958107464779,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 1.1305412812416345e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25726718417997785,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2480972772353067,
        "time": 0.9776020050048828,
        "additional_info": {
            "duration": 0.9578008651733398,
            "num_run": 532,
            "train_loss": 1.0438783717075653,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009134033570621208,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.035882454226049576,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 134,
            "classifier:CustomMLPClassifier:tol": 0.005378769276754924,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29513859531000114,
            "feature_preprocessor:select_rates_classification:alpha": 0.3210452814031224,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10136914253234863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005937645075508233,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00043534562125097624,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 144,
            "classifier:CustomMLPClassifier:tol": 0.004611606645284946,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01586010700141369,
            "feature_preprocessor:select_rates_classification:alpha": 0.3730789118144294,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.156904935836792,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010331930283146721,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.054660601016789157,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.0030944624069151904,
            "feature_preprocessor:select_rates_classification:alpha": 0.45968374280985563,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12347698211669922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00014367460527453405,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00030821596196688346,
            "classifier:CustomMLPClassifier:max_iter": 368,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 0.00366820671368466,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7853566609030991,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2975472874729462,
            "feature_preprocessor:select_rates_classification:alpha": 0.26324818829774416,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.41420602798461914,
        "additional_info": {
            "duration": 0.40287303924560547,
            "num_run": 536,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.5094978351404945e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023266870846481454,
            "classifier:CustomMLPClassifier:max_iter": 241,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.0001849255383703402,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00989668080654862,
            "feature_preprocessor:select_rates_classification:alpha": 0.15178741192717063,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.9020140171051025,
        "additional_info": {
            "duration": 0.8919999599456787,
            "num_run": 537,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004354959014003666,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02351729444102913,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 2.8476272498261528e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11456588914203293,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12776684761047363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.9801201946787906e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000752057635157213,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 272,
            "classifier:CustomMLPClassifier:tol": 0.0009722561485600411,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007033815687323946,
            "feature_preprocessor:select_percentile_classification:percentile": 55.04960486243616,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 1.2520780563354492,
        "additional_info": {
            "duration": 1.2412049770355225,
            "num_run": 539,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0027853285732872836,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.85607604723973,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.00021951486885777536,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00059011709730481,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1526,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.47470420979288885,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.4512674907311007,
        "time": 0.6682732105255127,
        "additional_info": {
            "duration": 0.6570539474487305,
            "num_run": 540,
            "train_loss": 1.4787616435993092,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.852497636167351e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0030914035432979088,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.0022332644735117858,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010116659029187047,
            "feature_preprocessor:select_rates_classification:alpha": 0.3207369471310128,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12821698188781738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.7238672009914064e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014607064138032961,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 3.808769373216695e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07090811343214377,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09609484672546387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.020579814946336986,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8871640110844716,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 0.002211807648992396,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003447584421448852,
            "feature_preprocessor:select_percentile_classification:percentile": 72.03514306048716,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.237976620073263,
        "time": 1.6595399379730225,
        "additional_info": {
            "duration": 1.6488430500030518,
            "num_run": 543,
            "train_loss": 1.1494161390264508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3691475856151006e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000440598730254569,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 4.3661710434183556e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03493940255099663,
            "feature_preprocessor:select_rates_classification:alpha": 0.27651897092172845,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1223301887512207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05757072874735249,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012012439155575627,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 0.005162580819644499,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009589625225149037,
            "feature_preprocessor:select_percentile_classification:percentile": 95.24700846023126,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3181891441345215,
        "additional_info": {
            "duration": 0.29906797409057617,
            "num_run": 545,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.810793261481661e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002151021689632252,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.0003842114203297574,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015465313171902735,
            "feature_preprocessor:select_rates_classification:alpha": 0.26186965746983076,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2388899061783076,
        "time": 7.630935907363892,
        "additional_info": {
            "duration": 7.619355916976929,
            "num_run": 546,
            "train_loss": 1.0746581006249667,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.898099719203649e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04808763684614542,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 5.0371673102377224e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013275730179394807,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.78720519746355,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.46111488342285156,
        "additional_info": {
            "duration": 0.4423527717590332,
            "num_run": 547,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002478087368022467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00438044914060679,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.0040616164093355885,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005319973327525712,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8704785058398394,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2203491756688385,
        "time": 0.4163401126861572,
        "additional_info": {
            "duration": 0.40465307235717773,
            "num_run": 548,
            "train_loss": 1.1900760277602016,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006264179164004868,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.38834453070555774,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.00037991067799398866,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.14828297685052325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12304568290710449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.241487614155117e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03010349376504347,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 1.2404090779993894e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2705931400987275,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12811803817749023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.0914739877069428e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012656796190811333,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 310,
            "classifier:CustomMLPClassifier:tol": 2.3316574732951987e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028998765372923753,
            "feature_preprocessor:select_rates_classification:alpha": 0.4952775173890713,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12377190589904785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000140872430095794,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2944328130012286,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.008463664096615444,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8711717475820544,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12298960776585147,
            "feature_preprocessor:select_rates_classification:alpha": 0.34676329913376297,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2231377753914694,
        "time": 0.2760298252105713,
        "additional_info": {
            "duration": 0.2640950679779053,
            "num_run": 552,
            "train_loss": 1.161078628329525,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012345427615222692,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04533296484564163,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.000630876684196427,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05227704919858178,
            "feature_preprocessor:select_rates_classification:alpha": 0.4918734428294415,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1008598804473877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06953849546716191,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010365255202746923,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 6.159793422897246e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005435853800292102,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14619873680805562,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.232805075315564,
        "time": 7.027790307998657,
        "additional_info": {
            "duration": 7.00848388671875,
            "num_run": 554,
            "train_loss": 1.1792942946360643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03499443313923418,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008880154797417384,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 212,
            "classifier:CustomMLPClassifier:tol": 0.0009335442078262217,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017081774596150557,
            "feature_preprocessor:select_rates_classification:alpha": 0.06802585263564723,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09560704231262207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010513939791018054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9881600006818109,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.00898401170244913,
            "feature_preprocessor:select_rates_classification:alpha": 0.2565321303579566,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09507393836975098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02706972080580932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.996467235747022,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0042153399061200395,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006827434477994088,
            "feature_preprocessor:select_rates_classification:alpha": 0.2637760346080737,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09650921821594238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.288639564769694e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014239909797539088,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 2.1594407662191653e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007806155220481144,
            "feature_preprocessor:select_rates_classification:alpha": 0.04734078004037448,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 1.0954909324645996,
        "additional_info": {
            "duration": 1.0846672058105469,
            "num_run": 558,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.028733067690916898,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17776677986221998,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.00013769717679022508,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1927336918903637,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.223707474669414,
        "time": 1.0508930683135986,
        "additional_info": {
            "duration": 1.0387179851531982,
            "num_run": 559,
            "train_loss": 1.1159441157476682,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00030658264720119857,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22690063541742578,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 272,
            "classifier:CustomMLPClassifier:tol": 0.0008814246667207585,
            "feature_preprocessor:select_rates_classification:alpha": 0.01591594625266843,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2427767701427497,
        "time": 0.36887502670288086,
        "additional_info": {
            "duration": 0.3545417785644531,
            "num_run": 560,
            "train_loss": 1.2202478574119489,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005193623300325494,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002090489184327756,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 3.511593875484409e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006510717653426038,
            "feature_preprocessor:select_rates_classification:alpha": 0.25962955112358144,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09588193893432617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.3025264820649778e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003972292302822217,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 2.2881875277226664e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3992154565010493,
            "feature_preprocessor:select_rates_classification:alpha": 0.4872086277186816,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09743309020996094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014808294190300945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06702861997232337,
            "classifier:CustomMLPClassifier:max_iter": 327,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.005273945709364031,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001417568822643555,
            "feature_preprocessor:select_rates_classification:alpha": 0.38604434374379193,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12300395965576172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08094834138374259,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009753653905493102,
            "classifier:CustomMLPClassifier:max_iter": 234,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.0004258401930293911,
            "feature_preprocessor:select_rates_classification:alpha": 0.3217281331380076,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1257929801940918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09668764865333607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6970383279352125,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.008383506135698096,
            "feature_preprocessor:select_rates_classification:alpha": 0.24167269597771054,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1022179126739502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008065482863768854,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027993636626760066,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 363,
            "classifier:CustomMLPClassifier:tol": 0.00013161286080821572,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004185524678295363,
            "feature_preprocessor:select_percentile_classification:percentile": 13.108944100677856,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2347661522022317,
        "time": 1.7725577354431152,
        "additional_info": {
            "duration": 1.7548108100891113,
            "num_run": 566,
            "train_loss": 1.2243498792962528,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0617271399619341e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005248681014235506,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.0014513232093844313,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06917408942657133,
            "feature_preprocessor:select_rates_classification:alpha": 0.03350392426093781,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.220997160791868,
        "time": 0.4464600086212158,
        "additional_info": {
            "duration": 0.4356863498687744,
            "num_run": 567,
            "train_loss": 1.1715772694647932,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011919310925229935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.918557022035052,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 182,
            "classifier:CustomMLPClassifier:tol": 7.225822668247575e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09815621940799185,
            "feature_preprocessor:select_percentile_classification:percentile": 81.60568851368056,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2489234163127878,
        "time": 0.3175168037414551,
        "additional_info": {
            "duration": 0.3073546886444092,
            "num_run": 568,
            "train_loss": 1.2480832706043818,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.98093560815386e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006661616114132875,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0014147982018761678,
            "feature_preprocessor:select_rates_classification:alpha": 0.2190314322706736,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2104651808460734,
        "time": 1.0400760173797607,
        "additional_info": {
            "duration": 1.0297977924346924,
            "num_run": 569,
            "train_loss": 1.1841161077444222,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.530207928396215e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06651876118896884,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 1.2776171196549718e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0932452752675043,
            "feature_preprocessor:select_rates_classification:alpha": 0.28659478550293843,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2486401984616815,
        "time": 1.7345380783081055,
        "additional_info": {
            "duration": 1.7237870693206787,
            "num_run": 570,
            "train_loss": 1.0205481005782069,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.498505862078842e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03712675567410165,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 1.3116267727893528e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015120205455908814,
            "feature_preprocessor:select_rates_classification:alpha": 0.478964188204797,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2222646563637793,
        "time": 0.8280549049377441,
        "additional_info": {
            "duration": 0.8130030632019043,
            "num_run": 571,
            "train_loss": 1.2225020007398408,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00029583894537953885,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00038530379978989396,
            "feature_preprocessor:select_rates_classification:alpha": 0.036808080124715585,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12874817848205566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008582195382008296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036162488697334366,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 6.887042298080081e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024004570498661795,
            "feature_preprocessor:select_rates_classification:alpha": 0.2026481674767196,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09574604034423828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.167090497706544e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011991198459123864,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 1.565476144773194e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2590806937056129,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10856914520263672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0033209128203337164,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06792854651449867,
            "classifier:CustomMLPClassifier:max_iter": 109,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 1.0495730288488113e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7591701563387145,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06057566831293854,
            "feature_preprocessor:select_rates_classification:alpha": 0.2643956956307994,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2279976344095915,
        "time": 0.8321528434753418,
        "additional_info": {
            "duration": 0.812204122543335,
            "num_run": 575,
            "train_loss": 1.2206718104193643,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008098498631883459,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021185950675811033,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0002307875997039259,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015419495651455882,
            "feature_preprocessor:select_percentile_classification:percentile": 72.86555193446902,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2464346802571038,
        "time": 0.9010641574859619,
        "additional_info": {
            "duration": 0.8887519836425781,
            "num_run": 576,
            "train_loss": 1.1658805670692325,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003211502615594338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2838712336571373,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.00040886798836538605,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005016238589699221,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1497,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.20802947226636256,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3566648838137476,
        "time": 0.6427860260009766,
        "additional_info": {
            "duration": 0.6275880336761475,
            "num_run": 577,
            "train_loss": 1.2939871231405573,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009400871214210908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024737681460074336,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 300,
            "classifier:CustomMLPClassifier:tol": 0.00026415446973849046,
            "feature_preprocessor:select_rates_classification:alpha": 0.17743297138496564,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09987592697143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.985913079632897e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2739066110810785,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 3.6801355527957594e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016499072930009786,
            "feature_preprocessor:select_rates_classification:alpha": 0.09895686374051853,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2094801793941445,
        "time": 0.3824930191040039,
        "additional_info": {
            "duration": 0.3640561103820801,
            "num_run": 579,
            "train_loss": 1.1938291733040562,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.602097560935232e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34852746531887757,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 1.281401382462862e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7958474851056279,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3122139443070309,
        "time": 0.909196138381958,
        "additional_info": {
            "duration": 0.8863399028778076,
            "num_run": 580,
            "train_loss": 1.1940184738785589,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2992037413239637e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7306561724530761,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.00011752212988047128,
            "feature_preprocessor:select_rates_classification:alpha": 0.2511843495219651,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09603500366210938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.687699888637276e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.304074347082786,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 0.000371876487762459,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6025479065900502,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.8816871643066406,
        "additional_info": {
            "duration": 0.8696987628936768,
            "num_run": 582,
            "train_loss": 1.228156364392546,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.59084007178165e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000329851313764125,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 3.781030612291829e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026124345288750395,
            "feature_preprocessor:select_rates_classification:alpha": 0.2961856443061755,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.6502261161804199,
        "additional_info": {
            "duration": 0.6373398303985596,
            "num_run": 583,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00015207200641557925,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036581147530671484,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 0.0007552247262334013,
            "feature_preprocessor:select_rates_classification:alpha": 0.4985397683491685,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12959671020507812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0038620648824181105,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01597270881379039,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 1.3676423599322766e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1672082057146776,
            "feature_preprocessor:select_percentile_classification:percentile": 26.652025525395505,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2292855742547961,
        "time": 1.7506790161132812,
        "additional_info": {
            "duration": 1.738990068435669,
            "num_run": 585,
            "train_loss": 1.1306057213780265,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.417596144557994e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00809227054459313,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.00022873096812970486,
            "feature_preprocessor:select_rates_classification:alpha": 0.49896301629332396,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.3980221748352051,
        "additional_info": {
            "duration": 0.3804957866668701,
            "num_run": 586,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016358742723385298,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00035638023818543866,
            "feature_preprocessor:select_rates_classification:alpha": 0.03991082260780848,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12841010093688965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.712090865454544e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026758220562984752,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 175,
            "classifier:CustomMLPClassifier:tol": 0.0037668922921997644,
            "feature_preprocessor:select_rates_classification:alpha": 0.01783303889283318,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10030579566955566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.039405776073421e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3869201934821311,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.00017448629537688195,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00031545939748529357,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 530,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 33.56705882619972,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2111467523697421,
        "time": 0.5194010734558105,
        "additional_info": {
            "duration": 0.5089359283447266,
            "num_run": 589,
            "train_loss": 1.1871789941467805,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006277286137342035,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12906902039477472,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 0.0001994347006084061,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07141844689611676,
            "feature_preprocessor:select_rates_classification:alpha": 0.11061395433699439,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12203001976013184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.027696971814735443,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08535877672861975,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.0011905984311429132,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48752555400228187,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12571406364440918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.150230049984975e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015423323213082742,
            "classifier:CustomMLPClassifier:max_iter": 315,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 0.00020068708390186195,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5510588374582094,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.38123393058776855,
        "additional_info": {
            "duration": 0.3606228828430176,
            "num_run": 592,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.015603565628931204,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20173129370746548,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.00042533958470498316,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035058415600878995,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9663923937918086,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2264059675051808,
            "feature_preprocessor:select_percentile_classification:percentile": 72.01242984181079,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2405127559937523,
        "time": 0.6692507266998291,
        "additional_info": {
            "duration": 0.6589579582214355,
            "num_run": 593,
            "train_loss": 1.1410618324049664,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.36274103389924e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010913961924807558,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.0009607541530617299,
            "feature_preprocessor:select_rates_classification:alpha": 0.14320980152304003,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09621715545654297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0013821544531937551,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7230438595724817,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.002306492885584796,
            "feature_preprocessor:select_rates_classification:alpha": 0.05102923810854396,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12919974327087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00965323524160957,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00846016552702314,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.00038451040955617003,
            "feature_preprocessor:select_rates_classification:alpha": 0.03129742423600861,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09642910957336426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00012125256962682474,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015408701277004265,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.0030238126460163956,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01078593226542159,
            "feature_preprocessor:select_rates_classification:alpha": 0.2622884392822918,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12374377250671387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00017073065706284363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003815806182824944,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 8.45013717542489e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1250519743576349,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12280392646789551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7483487094632106e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11830630927748848,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 6.259405720992067e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014026235562691872,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9726982045700806,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.546422004699707,
        "additional_info": {
            "duration": 0.5322690010070801,
            "num_run": 599,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.639479997174194e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000381434309163558,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 0.004402596040192938,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1334525848497753,
            "feature_preprocessor:select_rates_classification:alpha": 0.2379935791739361,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12332010269165039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009592222593431692,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020669155468185785,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.0007615400925895403,
            "feature_preprocessor:select_rates_classification:alpha": 0.09143801472390052,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2103878633686582,
        "time": 1.8633410930633545,
        "additional_info": {
            "duration": 1.8520729541778564,
            "num_run": 601,
            "train_loss": 1.1846233191993556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010449213184409083,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01988619847483353,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0016325256548262643,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5059432930530162,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.221697062313548,
        "time": 0.338759183883667,
        "additional_info": {
            "duration": 0.32732439041137695,
            "num_run": 602,
            "train_loss": 1.181701935691327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.407465156905645e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002579190653523781,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 2.7453344030177233e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30930148358894494,
            "feature_preprocessor:select_rates_classification:alpha": 0.48786739896079934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2098585735427219,
        "time": 4.505885124206543,
        "additional_info": {
            "duration": 4.494074821472168,
            "num_run": 603,
            "train_loss": 1.1275555562520716,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.139562175948281e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018370968683869252,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.006016356310871397,
            "feature_preprocessor:select_rates_classification:alpha": 0.3779216353726134,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1287679672241211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08411043078242209,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009727164760214123,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 2.5024356566689657e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019017279035973802,
            "feature_preprocessor:select_rates_classification:alpha": 0.4143480590741562,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.6540830135345459,
        "additional_info": {
            "duration": 0.638786792755127,
            "num_run": 605,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.564509138219946e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09097521146232598,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.004364064255688436,
            "feature_preprocessor:select_rates_classification:alpha": 0.02539686831089758,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12275576591491699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011623577964702172,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9954682168433806,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 0.003302082767901229,
            "feature_preprocessor:select_rates_classification:alpha": 0.2208033963918023,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.15729165077209473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.020653517908428433,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005508441331121448,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 1.0006611605569206e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012743575921061472,
            "feature_preprocessor:select_rates_classification:alpha": 0.07076012987128846,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12453079223632812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.068729862539918e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016385276133084857,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 3.425509032220781e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008426994653840181,
            "feature_preprocessor:select_rates_classification:alpha": 0.11244586997395664,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13132333755493164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.52686892142739e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007972914950160168,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.0054003439132552095,
            "feature_preprocessor:select_rates_classification:alpha": 0.39078925786230884,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15602517127990723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004648456491455272,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002211329865909161,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.0008688278733998674,
            "feature_preprocessor:select_rates_classification:alpha": 0.013729176540915693,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09484982490539551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.500466050998849e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8794392117508596,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 0.00020346156843311814,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38913294920324726,
            "feature_preprocessor:select_rates_classification:alpha": 0.44684567946166615,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.8883240222930908,
        "additional_info": {
            "duration": 0.878119945526123,
            "num_run": 612,
            "train_loss": 1.2243511405454002,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01047385720680959,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.891196263374235,
            "classifier:CustomMLPClassifier:max_iter": 175,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 1.3066400654337366e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.020313996290643885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2261352932960317,
        "time": 0.3891880512237549,
        "additional_info": {
            "duration": 0.37779903411865234,
            "num_run": 613,
            "train_loss": 1.1916862109188897,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2094392836504703e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025005898230137857,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 1.5507135673011036e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 34.432216290530455,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 1.1925477981567383,
        "additional_info": {
            "duration": 1.1746230125427246,
            "num_run": 614,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.031408688788167244,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7132704303869261,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 7.724723558313374e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007909348179681399,
            "feature_preprocessor:select_rates_classification:alpha": 0.2563077782659043,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1241142749786377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00020741969855708165,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026696664361904744,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.004240032144276756,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01234815122768127,
            "feature_preprocessor:select_rates_classification:alpha": 0.33071922765700085,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10129690170288086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.025751256129944274,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.43340872630320765,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 1.1944389873920958e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008431360565718962,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7032232302315038,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08060440274043934,
            "feature_preprocessor:select_rates_classification:alpha": 0.340262833521724,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.199442933375031,
        "time": 0.24264287948608398,
        "additional_info": {
            "duration": 0.23106884956359863,
            "num_run": 617,
            "train_loss": 1.17402157155981,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002738429770910129,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009675292124800795,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 299,
            "classifier:CustomMLPClassifier:tol": 0.0003642990316827497,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004144328548038283,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1277,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.703047170155397,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2236508404471076,
        "time": 0.44995594024658203,
        "additional_info": {
            "duration": 0.4354257583618164,
            "num_run": 618,
            "train_loss": 1.1915545142759405,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.05282757053402725,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001230201350510875,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 0.00011621361878275195,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015580484236558508,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11120274489269144,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2599350513225778,
        "time": 2.74971604347229,
        "additional_info": {
            "duration": 2.7357537746429443,
            "num_run": 619,
            "train_loss": 1.1808986520983877,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.309307822742333e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8996459468002778,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 0.0017019882482194346,
            "feature_preprocessor:select_rates_classification:alpha": 0.2768264411037497,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10162878036499023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02973299046496661,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021049488880649402,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 0.00012966164372562195,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03720622125364022,
            "feature_preprocessor:select_rates_classification:alpha": 0.3241869572776074,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12295293807983398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.561433836726849e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026770328002679342,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 135,
            "classifier:CustomMLPClassifier:tol": 0.006571220349855364,
            "feature_preprocessor:select_rates_classification:alpha": 0.4599518957996915,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12294697761535645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0036896499675534004,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03192985460606628,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0017256702146617215,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003887813585119328,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1639,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.14942828694330207,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.29581165313720703,
        "additional_info": {
            "duration": 0.28464508056640625,
            "num_run": 623,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0363457063667167e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03260569780493817,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 0.003982569046548946,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013897217887164862,
            "feature_preprocessor:select_rates_classification:alpha": 0.26784783211166935,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10138869285583496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.3937740970218324e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4762419971605468,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 2.8911461351331193e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4742699161208974,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.218044757722563,
        "time": 0.7378251552581787,
        "additional_info": {
            "duration": 0.7245988845825195,
            "num_run": 625,
            "train_loss": 1.1005831492095857,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06672803877467505,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027735019609055494,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.00019688304261970255,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002345975995782209,
            "feature_preprocessor:select_rates_classification:alpha": 0.4114680553747308,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3195779323577881,
        "additional_info": {
            "duration": 0.30858492851257324,
            "num_run": 626,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007607761159945866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08910688461010163,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 0.0019591347681279497,
            "feature_preprocessor:select_percentile_classification:percentile": 59.74858983351225,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.233258919564713,
        "time": 0.2966470718383789,
        "additional_info": {
            "duration": 0.28516697883605957,
            "num_run": 627,
            "train_loss": 1.0422195584437632,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.550139712332743e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06677529540545928,
            "classifier:CustomMLPClassifier:max_iter": 195,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 1.84505080830451e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024064175553280918,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9158786027207056,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2612258291741876,
        "time": 1.5570969581604004,
        "additional_info": {
            "duration": 1.5445330142974854,
            "num_run": 628,
            "train_loss": 1.144336631749296,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.328016840669921e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006973711315123368,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 0.0004407297806129624,
            "feature_preprocessor:select_rates_classification:alpha": 0.24888916636655775,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 1.6340000629425049,
        "additional_info": {
            "duration": 1.6228511333465576,
            "num_run": 629,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0055999913459450846,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02027222586746658,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 2.4438630108932247e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3106421637711227,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.755689042879564,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2729225850047685,
        "time": 2.612717866897583,
        "additional_info": {
            "duration": 2.597288131713867,
            "num_run": 630,
            "train_loss": 1.1530505658996524,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07817473409278941,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026197196746453946,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.00505791134830777,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00038005987124079194,
            "feature_preprocessor:select_percentile_classification:percentile": 59.92041809099512,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.230277384055795,
        "time": 0.6526961326599121,
        "additional_info": {
            "duration": 0.6406168937683105,
            "num_run": 631,
            "train_loss": 1.1668120123625243,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.857351857884398e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04816929651104835,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.0038925128959590703,
            "feature_preprocessor:select_rates_classification:alpha": 0.26484396855480674,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10129380226135254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.53821895029685e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020653574845872714,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.000683476713296481,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00933909900065278,
            "feature_preprocessor:select_rates_classification:alpha": 0.016966444235562147,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12360382080078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009860673474867878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03394222203235683,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 1.1223775426058078e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4192083024926113,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09659409523010254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3257332184756358e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5477360483112294,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.0009589562471288296,
            "feature_preprocessor:select_rates_classification:alpha": 0.42642788167872864,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2314762446618814,
        "time": 0.29338598251342773,
        "additional_info": {
            "duration": 0.28318190574645996,
            "num_run": 635,
            "train_loss": 1.1881926670224445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0579869759135455e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031300890537512234,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 1.819531427745049e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.020954898086165907,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12729692459106445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.569626411596523e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.030297445381201098,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 1.122992894651461e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034047660686831577,
            "feature_preprocessor:select_rates_classification:alpha": 0.2887969882140489,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12299132347106934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.145041438920124e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05048916084383139,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.0022043338616338577,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1983540245802261,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7763491583117986,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2749370571150217,
            "feature_preprocessor:select_rates_classification:alpha": 0.4658181848038958,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2176506246839414,
        "time": 0.27188777923583984,
        "additional_info": {
            "duration": 0.2621297836303711,
            "num_run": 638,
            "train_loss": 1.2069050551892786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.455850467963441e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31364316172087814,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.00613789483739751,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005301001029500978,
            "feature_preprocessor:select_rates_classification:alpha": 0.15726892632224007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2489614770314832,
        "time": 0.3108561038970947,
        "additional_info": {
            "duration": 0.29996705055236816,
            "num_run": 639,
            "train_loss": 1.1595319615431745,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9291648390487252e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27708635250529445,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.001141506200640453,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0226954747279686,
            "feature_preprocessor:select_rates_classification:alpha": 0.483458703531143,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09599995613098145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007221068835858572,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021427413309453713,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.00021260487081269707,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05036208808877452,
            "feature_preprocessor:select_rates_classification:alpha": 0.2647582006165369,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12264490127563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001114685017560569,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003647893463528296,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 3.758906940024274e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.39983330834533193,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2143019833483015,
        "time": 1.746042013168335,
        "additional_info": {
            "duration": 1.7338619232177734,
            "num_run": 642,
            "train_loss": 1.1785019983297553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007739253641323163,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029934014821825835,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 9.216912786239989e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004929287784892477,
            "feature_preprocessor:select_rates_classification:alpha": 0.02089055362567291,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.23636293411254883,
        "additional_info": {
            "duration": 0.22588229179382324,
            "num_run": 643,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.085028962648696e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5313481010489781,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 116,
            "classifier:CustomMLPClassifier:tol": 4.3128985255885684e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1460,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24231691319500503,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2572571903784655,
        "time": 0.4498708248138428,
        "additional_info": {
            "duration": 0.4375569820404053,
            "num_run": 644,
            "train_loss": 1.2313449753808565,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.022286364041405e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02586674126534729,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 0.007246707534671378,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001525954988337883,
            "feature_preprocessor:select_rates_classification:alpha": 0.26942686475810923,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09644198417663574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00022227914529753188,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04438853373945702,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.00010261644664001921,
            "feature_preprocessor:select_rates_classification:alpha": 0.3972782143235897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12215709686279297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0006539081851234444,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023301999329997766,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.0002298427739634206,
            "feature_preprocessor:select_rates_classification:alpha": 0.2557823056232004,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09597992897033691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005819621374609428,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24145264804159258,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0005764241121290131,
            "feature_preprocessor:select_percentile_classification:percentile": 88.53601962761432,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2129703180810518,
        "time": 0.3578298091888428,
        "additional_info": {
            "duration": 0.3480072021484375,
            "num_run": 648,
            "train_loss": 1.1792202452968783,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007780298416930201,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005149152850028498,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.0015493512305896427,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26827585635612045,
            "feature_preprocessor:select_rates_classification:alpha": 0.26996060408399514,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10109281539916992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006447282487940973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011451170866852612,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 2.0262091322299607e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008795580229012497,
            "feature_preprocessor:select_rates_classification:alpha": 0.1728464884055865,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09672021865844727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005735685305609144,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013356478742098435,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 2.2162765447583636e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003693221675432098,
            "feature_preprocessor:select_percentile_classification:percentile": 31.447951751320822,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3322629928588867,
        "additional_info": {
            "duration": 0.3216288089752197,
            "num_run": 651,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.44290952586274e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3922491913578055,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 0.0001946420158768377,
            "feature_preprocessor:select_rates_classification:alpha": 0.13745354329499052,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12733697891235352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010042432387999296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002466036346268419,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.007540042752748317,
            "feature_preprocessor:select_rates_classification:alpha": 0.027324232617447486,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10083675384521484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.4696167855216055e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07310913794918418,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.0002320535546722301,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000894185862447497,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8202710258215237,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09479645765139968,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9205955144309531,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2772341630406387,
        "time": 3.7270493507385254,
        "additional_info": {
            "duration": 3.714776039123535,
            "num_run": 654,
            "train_loss": 1.089055395160591,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.78238457302195e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04724197830239864,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0001339013926156337,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.39637388162586434,
            "feature_preprocessor:select_rates_classification:alpha": 0.06338937307884543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0958552360534668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.057614391787939555,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014905380875085148,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00012237733191007035,
            "feature_preprocessor:select_rates_classification:alpha": 0.05526439618923102,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2140810632919055,
        "time": 0.9354476928710938,
        "additional_info": {
            "duration": 0.9253687858581543,
            "num_run": 656,
            "train_loss": 1.1883233363376138,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00013762107851782282,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3870195977640201,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.0011023514890009054,
            "feature_preprocessor:select_rates_classification:alpha": 0.39811409666884867,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1229250431060791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09872032092610215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009555320832344956,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 3.0271004083479884e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03760642409071854,
            "feature_preprocessor:select_rates_classification:alpha": 0.08160737966349664,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10021376609802246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004241721240957089,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041167932843776594,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.0009339770916639653,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007830248090779129,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1721,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 68.59772777925176,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2284465252461074,
        "time": 0.9581210613250732,
        "additional_info": {
            "duration": 0.9474921226501465,
            "num_run": 659,
            "train_loss": 1.1748540594947885,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004200922765504793,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04098232410114693,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 6.346292910839459e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11495970272578425,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1278371810913086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00016127205230592945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18876280082607524,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.0017338346025245197,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005228529603749643,
            "feature_preprocessor:select_rates_classification:alpha": 0.07762064737699244,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09547281265258789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.086136353831792,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6984496343640186,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 1.4865623693453902e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8956966270831503,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21948494430865875,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9685208287101025,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3694239710140792,
        "time": 0.5201218128204346,
        "additional_info": {
            "duration": 0.5055727958679199,
            "num_run": 662,
            "train_loss": 1.3363961087380862,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007505158805439682,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.744831906145999,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 3.168144320480848e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 80.61082916990014,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.6714849472045898,
        "additional_info": {
            "duration": 0.5867211818695068,
            "num_run": 663,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.32601299750356e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008293675850037284,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 226,
            "classifier:CustomMLPClassifier:tol": 0.0014664359382977271,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007935943140875422,
            "feature_preprocessor:select_percentile_classification:percentile": 73.52700257812315,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1931468344660967,
        "time": 0.2657320499420166,
        "additional_info": {
            "duration": 0.2548229694366455,
            "num_run": 664,
            "train_loss": 1.1710091359967583,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001373461102366456,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3337009451204929,
            "classifier:CustomMLPClassifier:max_iter": 133,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 8.672813104981313e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0059145523967001085,
            "feature_preprocessor:select_rates_classification:alpha": 0.22743335196907857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1012117862701416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003333999739629159,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1919496474270355,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 0.004759848026258804,
            "feature_preprocessor:select_rates_classification:alpha": 0.2534026389727775,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16314125061035156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010348013360553952,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.60498002789279,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.006126721346592421,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02330279916590746,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 675,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 97.09479261961597,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2456191626884436,
        "time": 0.4036569595336914,
        "additional_info": {
            "duration": 0.38759613037109375,
            "num_run": 667,
            "train_loss": 1.2296388138587722,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06290851263554006,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000700573585835913,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.0059459037351454426,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07121082305261502,
            "feature_preprocessor:select_rates_classification:alpha": 0.10324481960121448,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12845993041992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005952306659500573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5028951600325974,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 4.6820966063097014e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 148,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.26002058644936166,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3159128360763335,
        "time": 1.5769658088684082,
        "additional_info": {
            "duration": 1.563270092010498,
            "num_run": 669,
            "train_loss": 1.202372930398042,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.4582660298547263e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007353847181923207,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.00024178349056743699,
            "feature_preprocessor:select_rates_classification:alpha": 0.0843351840058967,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.15564703941345215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.531030037883188e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017459093708917955,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.0022249257984250847,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 146,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7377470148645513,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.263094987684386,
        "time": 0.43039727210998535,
        "additional_info": {
            "duration": 0.419144868850708,
            "num_run": 671,
            "train_loss": 1.2338525748103215,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.224085734594944e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.46251495299810713,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 3.839001657654972e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.029010225304635616,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.36527419090270996,
        "additional_info": {
            "duration": 0.35438013076782227,
            "num_run": 672,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09881985091168481,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010876605481654221,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 0.00013623785505628082,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.808805906877933,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0774769241511461,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6526793180985774,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2061888914881502,
        "time": 0.7039999961853027,
        "additional_info": {
            "duration": 0.6924011707305908,
            "num_run": 673,
            "train_loss": 1.1951066688340348,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00024337824173371848,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07491184813356928,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.0003051684743673611,
            "feature_preprocessor:select_rates_classification:alpha": 0.17328130547970355,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10042071342468262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011488903315300129,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.732650326622761,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 3.476359982949333e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07605513111761047,
            "feature_preprocessor:select_rates_classification:alpha": 0.47067280789334603,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09608316421508789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010902050839872669,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01341613393409276,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 305,
            "classifier:CustomMLPClassifier:tol": 0.00017688413476098268,
            "feature_preprocessor:select_rates_classification:alpha": 0.47952298449234465,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12343883514404297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.907782405118877e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07863651200099282,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 3.8622199669238944e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06077163018707092,
            "feature_preprocessor:select_rates_classification:alpha": 0.19872705719979994,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.9074068069458008,
        "additional_info": {
            "duration": 0.8944540023803711,
            "num_run": 677,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00039922241160575357,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006790479964513924,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 2.9156127621158355e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14179282562626483,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.6409859657287598,
        "additional_info": {
            "duration": 0.6283550262451172,
            "num_run": 678,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.5961418358740455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021554510507919827,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 1.4904667863769644e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4697992719391501,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09586405754089355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09837809478521108,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018433145315318665,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.00941844241272371,
            "feature_preprocessor:select_rates_classification:alpha": 0.0932695202203047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09631609916687012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013967948822044733,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8027468637445235,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.0008294065370414849,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014693572343987408,
            "feature_preprocessor:select_rates_classification:alpha": 0.13278891710903903,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.40703701972961426,
        "additional_info": {
            "duration": 0.39549708366394043,
            "num_run": 681,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008345027541787115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4193492762535112,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 324,
            "classifier:CustomMLPClassifier:tol": 0.00014449603103275444,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 73,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.029788204258485752,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.316763399948287,
        "time": 1.1467359066009521,
        "additional_info": {
            "duration": 1.1356298923492432,
            "num_run": 682,
            "train_loss": 1.2610316264066186,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.483575034466939e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6371233133894371,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.001819761621747867,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43636813536507335,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9410008810384635,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.242765728719332,
        "time": 0.4988260269165039,
        "additional_info": {
            "duration": 0.48683881759643555,
            "num_run": 683,
            "train_loss": 1.1880485071595095,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000645777154257471,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6511984225950569,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.0064956358465291025,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3389536960799688,
            "feature_preprocessor:select_rates_classification:alpha": 0.48138593345002817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10067296028137207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002395865489397328,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5480880505575303,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.00579975967613284,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23389281067897696,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7625338848747583,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23277108817184974,
            "feature_preprocessor:select_rates_classification:alpha": 0.46744884127261516,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2238599942180164,
        "time": 0.6600120067596436,
        "additional_info": {
            "duration": 0.6483969688415527,
            "num_run": 685,
            "train_loss": 1.1518101380033188,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.16518811530731e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03243377241545941,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.00046375618929865673,
            "feature_preprocessor:select_rates_classification:alpha": 0.3763787009609621,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09615397453308105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07595678184557658,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015212734185180949,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.0038109408571995107,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007180106359620424,
            "feature_preprocessor:select_rates_classification:alpha": 0.4377416389474675,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1222081184387207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.030280713217347e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015416336993768149,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.008691560086795468,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8754678195065635,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2036625896415933,
        "time": 0.4590919017791748,
        "additional_info": {
            "duration": 0.44600701332092285,
            "num_run": 688,
            "train_loss": 1.1917153136330314,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.63534023361944e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005724432348021229,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 1.1070314361812891e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4689157732885034,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2574529505998053,
        "time": 0.3561561107635498,
        "additional_info": {
            "duration": 0.3418707847595215,
            "num_run": 689,
            "train_loss": 1.1976978040045947,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00014978221882288993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018378413110329266,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 1.3362146567913507e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00037170960411815916,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2135843176420157,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.8404049873352051,
        "additional_info": {
            "duration": 0.8290197849273682,
            "num_run": 690,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.024820424163712107,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.49475012971374605,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.002214308673612972,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035458145072321375,
            "feature_preprocessor:select_rates_classification:alpha": 0.04941369799643551,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12904906272888184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0020190669293866973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09950274558622152,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.0034136935312552887,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1498957996865602,
            "feature_preprocessor:select_percentile_classification:percentile": 3.671037398149414,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3015861511230469,
        "additional_info": {
            "duration": 0.29105305671691895,
            "num_run": 692,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5499058247899109e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28199329657021815,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 9.358561850370507e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037578920441149966,
            "feature_preprocessor:select_percentile_classification:percentile": 40.51611789411538,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2294226040736846,
        "time": 0.8350880146026611,
        "additional_info": {
            "duration": 0.8217861652374268,
            "num_run": 693,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000716755765708077,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.43855132557461435,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 122,
            "classifier:CustomMLPClassifier:tol": 1.1116911519635814e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.057239460806067295,
            "feature_preprocessor:select_rates_classification:alpha": 0.16520170839897302,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12228608131408691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0750055561401851e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011888831695297734,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0012993165544769644,
            "feature_preprocessor:select_rates_classification:alpha": 0.2978103039154522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12328314781188965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3263101610346432e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 1.2931712549290995e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.31976809553363256,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09580588340759277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0033337097650621476,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.817760630516389,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 9.470648305151475e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 116,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 17.32753971222851,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.320393339363885,
        "time": 0.25777387619018555,
        "additional_info": {
            "duration": 0.24522972106933594,
            "num_run": 697,
            "train_loss": 1.231431465165503,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.549040561402668e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024142603783318392,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.009995855447786967,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.46085482314735227,
            "feature_preprocessor:select_rates_classification:alpha": 0.08347052485656518,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10126018524169922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.84685834989485e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08377283423549528,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.003699930113828926,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0204210344243903,
            "feature_preprocessor:select_percentile_classification:percentile": 90.63072999115631,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2114022305872856,
        "time": 0.6510980129241943,
        "additional_info": {
            "duration": 0.6335141658782959,
            "num_run": 699,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018438529453574192,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4571259803166586,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.003615344304930512,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017575527278454908,
            "feature_preprocessor:select_rates_classification:alpha": 0.498930923722091,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1255779266357422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005372457000340894,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005000941146156997,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.007113129544197127,
            "feature_preprocessor:select_rates_classification:alpha": 0.276517920755623,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12269425392150879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02773789301920141,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001409597518333252,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.0008015771527799918,
            "feature_preprocessor:select_rates_classification:alpha": 0.042165341996246754,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09527325630187988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011349846749365667,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021281739960462335,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0024011072848502367,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7079036943490181,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13140514364378214,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49696832207446195,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2413677828743008,
        "time": 0.5274569988250732,
        "additional_info": {
            "duration": 0.5140509605407715,
            "num_run": 703,
            "train_loss": 1.179704351046033,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.157636222007384e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07551285295871366,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 0.004709923978546253,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024487087160220415,
            "feature_preprocessor:select_rates_classification:alpha": 0.4004925336686752,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09591293334960938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.922407905598498e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.053952784774753765,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.0007956077865351546,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005637518665607433,
            "feature_preprocessor:select_rates_classification:alpha": 0.03277796673878868,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12261199951171875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011708353265424039,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36430279601245247,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 127,
            "classifier:CustomMLPClassifier:tol": 0.00039229560361099243,
            "feature_preprocessor:select_percentile_classification:percentile": 41.310030505491845,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2399068758143628,
        "time": 1.4513440132141113,
        "additional_info": {
            "duration": 1.434558391571045,
            "num_run": 706,
            "train_loss": 1.1157604069481626,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5878511545421466e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014756859730639799,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 211,
            "classifier:CustomMLPClassifier:tol": 0.007809058763666825,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032937584784052446,
            "feature_preprocessor:select_rates_classification:alpha": 0.22788769262389152,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2351717989731723,
        "time": 0.48680806159973145,
        "additional_info": {
            "duration": 0.47559332847595215,
            "num_run": 707,
            "train_loss": 1.193986458316235,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2506919219652683e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022693308475728172,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.00013002385802204854,
            "feature_preprocessor:select_rates_classification:alpha": 0.10346535476019088,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 1.0259771347045898,
        "additional_info": {
            "duration": 1.010408878326416,
            "num_run": 708,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06671093586878529,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002241373945429948,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 0.0009397506869637802,
            "feature_preprocessor:select_rates_classification:alpha": 0.44111160618050954,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12901091575622559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0016764130606579369,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9888374357940023,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.00031660952045903387,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17710518100821043,
            "feature_preprocessor:select_rates_classification:alpha": 0.17962763822392547,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0969080924987793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.209569938683593e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0632794146654001,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.0059095562677557905,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 973,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 2.2136817879831616,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3564720153808594,
        "additional_info": {
            "duration": 0.3374369144439697,
            "num_run": 711,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00022947333470663375,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027594873467192554,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 3.991000753345268e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4114691074733915,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12374997138977051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0019000498069218265,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012544596135652512,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 97,
            "classifier:CustomMLPClassifier:tol": 9.345279309682816e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.054600726772306415,
            "feature_preprocessor:select_rates_classification:alpha": 0.4100684022419458,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12807798385620117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004912931548542413,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6192126279491224,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.000817363954131316,
            "feature_preprocessor:select_rates_classification:alpha": 0.015084951111259879,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09565281867980957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.678015277969084e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007419137720451233,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 5.872712082228513e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1639481501820333,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12371301651000977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.015312505643082211,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.055522256097160425,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 0.00023352070733882713,
            "feature_preprocessor:select_rates_classification:alpha": 0.301198366283841,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09641885757446289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.9436841703922585e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17462363549914767,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.0003687262519074406,
            "feature_preprocessor:select_rates_classification:alpha": 0.051405132306127796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1277167797088623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025438597730208054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003102483543408407,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 5.874063271583422e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13555420304188215,
            "feature_preprocessor:select_rates_classification:alpha": 0.36396803701946107,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2309178269201162,
        "time": 4.559391021728516,
        "additional_info": {
            "duration": 4.548996925354004,
            "num_run": 718,
            "train_loss": 1.1673069319094704,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0015698292880835304,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017395498415650044,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 0.00021414166598841925,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02190373254615825,
            "feature_preprocessor:select_percentile_classification:percentile": 3.1648340856666195,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.8509559631347656,
        "additional_info": {
            "duration": 0.8405041694641113,
            "num_run": 719,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.8321541316190133e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042658654632738417,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.0025936803399778385,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13935766499689337,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6783117944901141,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.776843786239624,
        "additional_info": {
            "duration": 0.7648649215698242,
            "num_run": 720,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010141555947978875,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8214520431604082,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 392,
            "classifier:CustomMLPClassifier:tol": 0.00037379989455520825,
            "feature_preprocessor:select_percentile_classification:percentile": 28.029057311033444,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.5249135594344008,
        "time": 0.34751009941101074,
        "additional_info": {
            "duration": 0.322023868560791,
            "num_run": 721,
            "train_loss": 1.5439424850045975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05459364421951829,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025620063836957296,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 0.0006276817762469916,
            "feature_preprocessor:select_rates_classification:alpha": 0.13909465827982403,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2307241730574359,
        "time": 0.5424261093139648,
        "additional_info": {
            "duration": 0.5316431522369385,
            "num_run": 722,
            "train_loss": 1.2199216986042312,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3594530707076048e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00028714708890273735,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 256,
            "classifier:CustomMLPClassifier:tol": 0.0001639517987902257,
            "feature_preprocessor:select_rates_classification:alpha": 0.18656989645173142,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2263905302698672,
        "time": 0.8844211101531982,
        "additional_info": {
            "duration": 0.8725869655609131,
            "num_run": 723,
            "train_loss": 1.2200269053131187,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0435945439534506e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8755139297036941,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0035180173768488586,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022155735264789745,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1997,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 50.73331668265036,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2531061645539439,
        "time": 0.7715821266174316,
        "additional_info": {
            "duration": 0.7599728107452393,
            "num_run": 724,
            "train_loss": 1.215028728407185,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008361237309029902,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20081629728385753,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 90,
            "classifier:CustomMLPClassifier:tol": 0.00037479490489170764,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9242558860451304,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.370819091796875,
        "additional_info": {
            "duration": 0.35201168060302734,
            "num_run": 725,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2798024166729233e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16252449317564313,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 5.518170998656874e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037710074405996833,
            "feature_preprocessor:select_rates_classification:alpha": 0.46077494437954797,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12285184860229492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018457379884181382,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001775318749434916,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.0027560640997361567,
            "feature_preprocessor:select_rates_classification:alpha": 0.013553764899747366,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12404894828796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002877288223225118,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016694994020085446,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 335,
            "classifier:CustomMLPClassifier:tol": 0.007584118258922691,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006864413650561837,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.33678315333733433,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1963605557343455,
        "time": 0.3489830493927002,
        "additional_info": {
            "duration": 0.33692479133605957,
            "num_run": 728,
            "train_loss": 1.1909224819767277,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010473541640301062,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014890297292062045,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 9.608206526406168e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 21.378848814192352,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1981295992367385,
        "time": 4.256523847579956,
        "additional_info": {
            "duration": 4.2447309494018555,
            "num_run": 729,
            "train_loss": 1.176416405954775,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01487488314550879,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1720214168681454,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.009461965588382665,
            "feature_preprocessor:select_rates_classification:alpha": 0.18010204402053537,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10134196281433105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0013240910012003288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018774885103197785,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 3.709068888331213e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0897782305037276,
            "feature_preprocessor:select_rates_classification:alpha": 0.03129225369898409,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.4190239906311035,
        "additional_info": {
            "duration": 0.40851402282714844,
            "num_run": 731,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.645943222024236e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032544072785117546,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 1.5948992879184215e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01201704103456311,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1735337539523616,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.6622068881988525,
        "additional_info": {
            "duration": 0.6505615711212158,
            "num_run": 732,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.056325890883841e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011329411728775361,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.00046245523599924306,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010360004052672289,
            "feature_preprocessor:select_rates_classification:alpha": 0.48616699825223497,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12297916412353516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.679381931585384e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002121126487363371,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.009768861960383084,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7797405278229401,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.43096327781677246,
        "additional_info": {
            "duration": 0.4197869300842285,
            "num_run": 734,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00026828051343305445,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019501845158581872,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.0026745811229494207,
            "feature_preprocessor:select_rates_classification:alpha": 0.019990855814567325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12401771545410156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00036401472852006704,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.033431798415858256,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.0023401638712114577,
            "feature_preprocessor:select_rates_classification:alpha": 0.03793787141627402,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1277601718902588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0015961858114907294,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017395347837797245,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 0.001157780060527669,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8288370327824384,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07300411950588523,
            "feature_preprocessor:select_rates_classification:alpha": 0.25225397520092413,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.21700993831402,
        "time": 1.3730957508087158,
        "additional_info": {
            "duration": 1.3620660305023193,
            "num_run": 737,
            "train_loss": 1.1743243644284904,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03256832821119593,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006103364520354294,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 1.4038126750294947e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003112479282075978,
            "feature_preprocessor:select_rates_classification:alpha": 0.24868560194835138,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09599089622497559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012414174408355465,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03315828439693974,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.009452292840759179,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001439614089036409,
            "feature_preprocessor:select_percentile_classification:percentile": 97.34646520764133,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2107248796975578,
        "time": 0.29666996002197266,
        "additional_info": {
            "duration": 0.28648877143859863,
            "num_run": 739,
            "train_loss": 1.1611116278474192,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005317837566531942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3619773632810012,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 0.001251677391293288,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004805356423561726,
            "feature_preprocessor:select_rates_classification:alpha": 0.4989100024057574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12285685539245605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.8002310445262146e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005966522245134715,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 5.8297789740664216e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29552536555744363,
            "feature_preprocessor:select_rates_classification:alpha": 0.1760381109644652,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2281179428100586,
        "additional_info": {
            "duration": 0.21713495254516602,
            "num_run": 741,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002450985156141875,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008332147715687884,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 0.003483129990192719,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 621,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 51.561384590109974,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2011280787232936,
        "time": 1.5890390872955322,
        "additional_info": {
            "duration": 1.577199935913086,
            "num_run": 742,
            "train_loss": 1.080854454789323,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010286770960237523,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5488740919541576,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.0050572892775045414,
            "feature_preprocessor:select_percentile_classification:percentile": 88.60818426917726,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3030259609222412,
        "additional_info": {
            "duration": 0.2850790023803711,
            "num_run": 743,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.746600017681187e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010829394756188414,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.0002590740882860924,
            "feature_preprocessor:select_rates_classification:alpha": 0.3148986080887056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15916800498962402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6241248237874168e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00047128791905382754,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.00015933133443038505,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12877446524378344,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2203588231552598,
        "time": 2.722341775894165,
        "additional_info": {
            "duration": 2.710361957550049,
            "num_run": 745,
            "train_loss": 1.131142976130462,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3295988582260163e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012467493054730747,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.001485957475196324,
            "feature_preprocessor:select_rates_classification:alpha": 0.1543684902987813,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1015920639038086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.4799699236893045e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00210844484191574,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 0.00011029298011058338,
            "feature_preprocessor:select_rates_classification:alpha": 0.22211419521564504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09664201736450195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.301795823985991e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3673097352452426,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 1.5408297369964247e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3352378867154143,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.3465590005669168,
        "time": 0.6459708213806152,
        "additional_info": {
            "duration": 0.6232678890228271,
            "num_run": 748,
            "train_loss": 1.2371187657267335,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.4439412228997905e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022637017761224006,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.000776687113500118,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005078968610967079,
            "feature_preprocessor:select_rates_classification:alpha": 0.18306406000053554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09635305404663086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6275728901490512e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008287715356720493,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 313,
            "classifier:CustomMLPClassifier:tol": 5.841031312423419e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03071011440990338,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15970587730407715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.0172994465182727e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0716782748333418,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 439,
            "classifier:CustomMLPClassifier:tol": 1.0726292064900165e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2053216467048961,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10397791862487793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.324043731284953e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7350053143034764,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 0.0005968024393737328,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039642063914357696,
            "feature_preprocessor:select_rates_classification:alpha": 0.026426201622594694,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12975835800170898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005633940317831895,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010368860740409295,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 2.1307196522593637e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07689430653269946,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09729623794555664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07053936991727015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07571990510641297,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.00021276820302667886,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007023182394078489,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.08902983603015535,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2345588612843823,
        "time": 0.910275936126709,
        "additional_info": {
            "duration": 0.8911910057067871,
            "num_run": 754,
            "train_loss": 1.0949897474048256,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01096676709530669,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9832001365439802,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 0.0006288610641525947,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010964685377321825,
            "feature_preprocessor:select_rates_classification:alpha": 0.04997892940603623,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.318282335167528,
        "time": 0.2640812397003174,
        "additional_info": {
            "duration": 0.25292205810546875,
            "num_run": 755,
            "train_loss": 1.2608934841497312,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010942733108271168,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007675830935375927,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.000521437627520495,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7848930837955018,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2251528874758542,
        "time": 0.8307478427886963,
        "additional_info": {
            "duration": 0.8190169334411621,
            "num_run": 756,
            "train_loss": 1.1951818528431046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013464401668282546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15378108128148185,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 282,
            "classifier:CustomMLPClassifier:tol": 2.019464432101005e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06741170369198991,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.225088961286116,
        "time": 0.5875730514526367,
        "additional_info": {
            "duration": 0.5773758888244629,
            "num_run": 757,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.387756720569938e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13452464927458196,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 2.0374531336160117e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 960,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2837948541364408,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2142867190290507,
        "time": 0.9593138694763184,
        "additional_info": {
            "duration": 0.9418480396270752,
            "num_run": 758,
            "train_loss": 1.1105807208983907,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2767373509734494e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9875501548340406,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.008761850339098385,
            "feature_preprocessor:select_rates_classification:alpha": 0.2502609803585301,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12348794937133789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0687155583479968,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17860835533263486,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 0.008253584307292122,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.051741983465850655,
            "feature_preprocessor:select_rates_classification:alpha": 0.49851620233900473,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09644603729248047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04148579314347499,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011241012674011819,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 0.0011498490225121708,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009498021353144589,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.920460087832703,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0774571704147799,
            "feature_preprocessor:select_rates_classification:alpha": 0.02845092982233363,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2144068003465176,
        "time": 1.3868622779846191,
        "additional_info": {
            "duration": 1.3714492321014404,
            "num_run": 761,
            "train_loss": 1.1835774160771597,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011387552799449886,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7211749305757299,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 149,
            "classifier:CustomMLPClassifier:tol": 8.187289431448841e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05324423045695461,
            "feature_preprocessor:select_rates_classification:alpha": 0.28884616486328213,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10235381126403809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6658653054344346e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05367228022594496,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 2.8631567586859475e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.150556509932472,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12339472770690918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001968938793515462,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022988170444364673,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 6.173758010494028e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08179392169688346,
            "feature_preprocessor:select_rates_classification:alpha": 0.36438123303102027,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09730410575866699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.9625186338949057e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3375435262391686,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0071314847834164745,
            "feature_preprocessor:select_rates_classification:alpha": 0.4818904756496137,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.4837830066680908,
        "additional_info": {
            "duration": 0.4730381965637207,
            "num_run": 765,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006355860257116487,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00043641472994081026,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.00974953391972392,
            "feature_preprocessor:select_rates_classification:alpha": 0.22636035613199468,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1228790283203125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0013832104124897194,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006213551821104247,
            "classifier:CustomMLPClassifier:max_iter": 327,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.00026544337519713906,
            "feature_preprocessor:select_rates_classification:alpha": 0.035492554368738306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1997712683232864,
        "time": 7.192931175231934,
        "additional_info": {
            "duration": 7.181997060775757,
            "num_run": 767,
            "train_loss": 1.0772183158845583,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.107559194406168e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021878363394991268,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.0005870792861534813,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 397,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.04382902761660858,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2222672474717464,
        "time": 0.664348840713501,
        "additional_info": {
            "duration": 0.6532342433929443,
            "num_run": 768,
            "train_loss": 1.2051815475110452,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008046648034248133,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009467401543845609,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.0015361421125305646,
            "feature_preprocessor:select_rates_classification:alpha": 0.321775017553383,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12383294105529785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00011422086521051055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017871830186190207,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.0011485323405099226,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008626337200033118,
            "feature_preprocessor:select_rates_classification:alpha": 0.26407668335219525,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2654283046722412,
        "additional_info": {
            "duration": 0.2542128562927246,
            "num_run": 770,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002846949741914396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11730628645166633,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 9.284253730342687e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004986912358394304,
            "feature_preprocessor:select_percentile_classification:percentile": 20.82359800305833,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.221078698903224,
        "time": 0.5605471134185791,
        "additional_info": {
            "duration": 0.5496337413787842,
            "num_run": 771,
            "train_loss": 1.1919336074027311,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001697034719185506,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005516516784240675,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.002674226864156872,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019410007151014912,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 451,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.22268798691946937,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2217146764970581,
        "time": 0.5136418342590332,
        "additional_info": {
            "duration": 0.5015668869018555,
            "num_run": 772,
            "train_loss": 1.1681735562090676,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009388402499098604,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005885716659256894,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.0006662631646211303,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9186531156621938,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.009590558956218093,
            "feature_preprocessor:select_rates_classification:alpha": 0.06794268220127603,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2317136341251214,
        "time": 2.641605854034424,
        "additional_info": {
            "duration": 2.6301939487457275,
            "num_run": 773,
            "train_loss": 1.0587396637023267,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009198760916150206,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005285598708771028,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.0002357350469709484,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7789172840493658,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12272869667129672,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6618224957485691,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.223365024702358,
        "time": 1.193626880645752,
        "additional_info": {
            "duration": 1.1796510219573975,
            "num_run": 774,
            "train_loss": 1.1699061848906882,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010660374154000991,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027615464612221067,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 2.1998261419374895e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9218848076663834,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2332378387039476,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.767673059205686,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2439502375866947,
        "time": 2.0487060546875,
        "additional_info": {
            "duration": 2.0290989875793457,
            "num_run": 775,
            "train_loss": 1.1722431366999975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004520588288791162,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24765634964316324,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.004532623054448936,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023750726552700365,
            "feature_preprocessor:select_rates_classification:alpha": 0.22137521344103547,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12769627571105957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005317837566531942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5588035858574562,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.001916926116301206,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006040741648129497,
            "feature_preprocessor:select_rates_classification:alpha": 0.4989100024057574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09680294990539551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1563919859341601e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016238784870646777,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.000924317137877015,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022475002046453696,
            "feature_preprocessor:select_rates_classification:alpha": 0.26080103854439457,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10130715370178223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009805903400425637,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003488652191256283,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.00010394397013610854,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22411894061478896,
            "feature_preprocessor:select_rates_classification:alpha": 0.05456557278633487,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09698891639709473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002251430906055865,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014780670986318813,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.0004691317061765804,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9861581655813717,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2085342047666883,
        "time": 0.37831902503967285,
        "additional_info": {
            "duration": 0.36594104766845703,
            "num_run": 780,
            "train_loss": 1.1764932813977238,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00026470291396780727,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005717086269014781,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 397,
            "classifier:CustomMLPClassifier:tol": 0.001594468726486771,
            "feature_preprocessor:select_rates_classification:alpha": 0.4948095668630382,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12777400016784668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004140639387502093,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.35544891682026125,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 0.00011958595071095714,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002697311216286053,
            "feature_preprocessor:select_rates_classification:alpha": 0.30805861299102066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09610319137573242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2323754170515705e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012742023162869228,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.00019513821532001196,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011718139547328545,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9181630478520205,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23545276594826908,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.580065685297054,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.218947735182882,
        "time": 0.869163990020752,
        "additional_info": {
            "duration": 0.8555340766906738,
            "num_run": 783,
            "train_loss": 1.184337184245675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010313528874747527,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 1.8017457832441006e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49965439920575777,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1284940242767334,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.059943521092955164,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014336042345635618,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0010902307398435243,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4767452376867101,
            "feature_preprocessor:select_rates_classification:alpha": 0.22019709084254993,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09636497497558594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0045767142946211295,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04548532033338002,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.002832859110602014,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017000826261938867,
            "feature_preprocessor:select_rates_classification:alpha": 0.042605061233959476,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0972590446472168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0022447634416315446,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017044719774193084,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.004700994972612168,
            "feature_preprocessor:select_rates_classification:alpha": 0.493255645767106,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12842011451721191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010313528874747527,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 1.3668850436230576e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49965439920575777,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12811017036437988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004910518373499131,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002177489066850661,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0022118264434929573,
            "feature_preprocessor:select_rates_classification:alpha": 0.43852632642032713,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.351395845413208,
        "additional_info": {
            "duration": 0.33954596519470215,
            "num_run": 789,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 789,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.0408330423409286e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012283070846960984,
            "classifier:CustomMLPClassifier:max_iter": 357,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 6.68073316941087e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 80.00282190522994,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2193691242367046,
        "time": 1.7840070724487305,
        "additional_info": {
            "duration": 1.7729921340942383,
            "num_run": 790,
            "train_loss": 1.2294506729055192,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 790,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.076213795787808e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004464981891261513,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 1.316279196944445e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20063285103055922,
            "feature_preprocessor:select_rates_classification:alpha": 0.42416847973294763,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2179168985574105,
        "time": 4.552938938140869,
        "additional_info": {
            "duration": 4.542196989059448,
            "num_run": 791,
            "train_loss": 1.1517030877857133,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 791,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00024532978762549496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4405255905585081,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 283,
            "classifier:CustomMLPClassifier:tol": 8.83626199102691e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006361870985505508,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1550,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8081682729211255,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.243588311714015,
        "time": 0.7471470832824707,
        "additional_info": {
            "duration": 0.7275152206420898,
            "num_run": 792,
            "train_loss": 1.1685037817720108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 792,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.396405291103785e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003089060323866058,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.00021265503679538113,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3827347214076698,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2697965670121788,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2183072923185605,
        "time": 0.5678310394287109,
        "additional_info": {
            "duration": 0.5496530532836914,
            "num_run": 793,
            "train_loss": 1.1854573719889494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 793,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.697625768394856e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015567583745983293,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.004231053411976754,
            "feature_preprocessor:select_rates_classification:alpha": 0.0387332067425047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12300276756286621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 794,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022949689346211624,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008110622220047813,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 5.331184942649863e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8513774258926223,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12319697334278226,
            "feature_preprocessor:select_rates_classification:alpha": 0.39176321197022174,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2360975750948275,
        "time": 0.3600630760192871,
        "additional_info": {
            "duration": 0.3405759334564209,
            "num_run": 795,
            "train_loss": 1.224525453224782,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 795,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00037685690332549086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11164013936428471,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 4.2142513339968316e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 77.80381243095631,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 1.3293848037719727,
        "additional_info": {
            "duration": 1.3164989948272705,
            "num_run": 796,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 796,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.747648445370423e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7049697924699339,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.0007402330761863507,
            "feature_preprocessor:select_rates_classification:alpha": 0.11375748462663597,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 1.1490449905395508,
        "additional_info": {
            "duration": 1.1283037662506104,
            "num_run": 797,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 797,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001308385604640926,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0802874882497134,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 0.0018694377353917187,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012106162570412088,
            "feature_preprocessor:select_rates_classification:alpha": 0.13776321078321482,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12429094314575195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 798,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.020599679910982,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8213021700168321,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 1.9297377204683977e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7032232302315038,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05454632690642935,
            "feature_preprocessor:select_rates_classification:alpha": 0.340262833521724,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 2.4572231769561768,
        "additional_info": {
            "duration": 2.446160316467285,
            "num_run": 799,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 799,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.015580625022495754,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010545577920420523,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.00176130544964461,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01154031806653072,
            "feature_preprocessor:select_rates_classification:alpha": 0.3421215180796886,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.36017799377441406,
        "additional_info": {
            "duration": 0.3409152030944824,
            "num_run": 800,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 800,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.0072942543593446e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000632496429860568,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 0.0011113648784925503,
            "feature_preprocessor:select_rates_classification:alpha": 0.08184949998579842,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12392592430114746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 801,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.511140686151079e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020156861999531583,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.0022201016699910595,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016333749974683284,
            "feature_preprocessor:select_rates_classification:alpha": 0.3856589416115659,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12390708923339844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 802,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.017557820397263935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001645929598444457,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.0050702900780539885,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9180883174333815,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1924108490921317,
            "feature_preprocessor:select_percentile_classification:percentile": 15.84088214847027,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.4848592281341553,
        "additional_info": {
            "duration": 0.47191905975341797,
            "num_run": 803,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 803,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.8578997252339426e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015636830290079663,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.003623410756835994,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005115040108211079,
            "feature_preprocessor:select_rates_classification:alpha": 0.2352613433977521,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.224541818294854,
        "time": 0.4301791191101074,
        "additional_info": {
            "duration": 0.4199070930480957,
            "num_run": 804,
            "train_loss": 1.1831217909477323,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 804,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022130254083608344,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020176127252345935,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 3.9212814825994346e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010919280645482249,
            "feature_preprocessor:select_rates_classification:alpha": 0.1340812706915836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09646105766296387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 805,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00029991861386760745,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024554202800107748,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.00038627205333876033,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028194011414902107,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9146517907313829,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.277146463036218,
        "time": 1.2477850914001465,
        "additional_info": {
            "duration": 1.2331771850585938,
            "num_run": 806,
            "train_loss": 1.0510868146558108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 806,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009952488716106558,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0033198147048255017,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 1.4446724257446766e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006202747630131815,
            "feature_preprocessor:select_rates_classification:alpha": 0.1612090654825586,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10128998756408691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 807,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00016191663986959873,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04666403124070146,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.00043033687509870777,
            "feature_preprocessor:select_rates_classification:alpha": 0.3852635720822958,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2146714458249588,
        "time": 0.612278938293457,
        "additional_info": {
            "duration": 0.5999648571014404,
            "num_run": 808,
            "train_loss": 1.1541474104784146,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 808,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09872032092610215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008447469835712788,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 3.9204757018872636e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.06949074671662388,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1239619255065918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 809,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.73725069682229e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017603961650514731,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 0.0001124439553039108,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05601755856242856,
            "feature_preprocessor:select_rates_classification:alpha": 0.1108305310047216,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09685993194580078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 810,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007491588758982774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005972271213099656,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.0009451310094494023,
            "feature_preprocessor:select_rates_classification:alpha": 0.3330996445590206,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2212382816159568,
        "time": 0.6071040630340576,
        "additional_info": {
            "duration": 0.5947048664093018,
            "num_run": 811,
            "train_loss": 1.18081749385548,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 811,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005899338129116328,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2944843217085463,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 0.00021783791246073807,
            "feature_preprocessor:select_rates_classification:alpha": 0.33846640933374433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09545373916625977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 812,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005494704050541762,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 1.3668850436230576e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008630781762246699,
            "feature_preprocessor:select_rates_classification:alpha": 0.4886756786223046,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12798476219177246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 813,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015253013539810623,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5546148084410222,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 135,
            "classifier:CustomMLPClassifier:tol": 0.0001013546796178283,
            "feature_preprocessor:select_rates_classification:alpha": 0.4999358680885854,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09606814384460449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 814,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.027034065041551352,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08926685017395943,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.00676204470474198,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02774881425841093,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 342,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.36722382850955393,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2486578058595152,
        "time": 0.9987239837646484,
        "additional_info": {
            "duration": 0.9848341941833496,
            "num_run": 815,
            "train_loss": 1.1912300276649423,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 815,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002212907361440605,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.040759952989546155,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 185,
            "classifier:CustomMLPClassifier:tol": 1.528547886666714e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005153232557111766,
            "feature_preprocessor:select_rates_classification:alpha": 0.0815700373699593,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09720683097839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 816,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00012092315959030276,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007612383865462154,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 0.005158483502627879,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 838,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 77.29704676091585,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.228836436519842,
        "time": 0.5123958587646484,
        "additional_info": {
            "duration": 0.4983961582183838,
            "num_run": 817,
            "train_loss": 1.1706374518417917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 817,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009242684977039949,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013168687386287226,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 2.878141942238297e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.45337197912834576,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09713411331176758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 818,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.9557903577055448e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005598823060856931,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 2.5537878276742792e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03325707329048895,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0955808162689209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 819,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00015568384494863427,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3002217083373822,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 0.00037631238127523785,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016416053540037608,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6154672558792004,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2248038658796516,
        "time": 0.46462583541870117,
        "additional_info": {
            "duration": 0.45240306854248047,
            "num_run": 820,
            "train_loss": 1.211122988061317,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 820,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.4615435807261232e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.042482401906432946,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 0.00010485693788776429,
            "feature_preprocessor:select_percentile_classification:percentile": 38.42191663939978,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.233327311024938,
        "time": 0.9113399982452393,
        "additional_info": {
            "duration": 0.9005429744720459,
            "num_run": 821,
            "train_loss": 1.2149441859359946,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 821,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0013482221305545202,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012404157078275537,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 0.0023068844626649445,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039461981217329864,
            "feature_preprocessor:select_rates_classification:alpha": 0.45824968955429174,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.3886380195617676,
        "additional_info": {
            "duration": 0.3784797191619873,
            "num_run": 822,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 822,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3354320186100723e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007331970317551757,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.0004270756145500043,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006115522473329687,
            "feature_preprocessor:select_rates_classification:alpha": 0.3848010279913801,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2042167867494176,
        "time": 1.7906441688537598,
        "additional_info": {
            "duration": 1.7731802463531494,
            "num_run": 823,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 823,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0035498710497280845,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010375949894904674,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 137,
            "classifier:CustomMLPClassifier:tol": 2.3503038633601738e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.38561924433182554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1225438117980957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 824,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.641925374667209e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5375770638205848,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 0.00010240785935466693,
            "feature_preprocessor:select_rates_classification:alpha": 0.18128377503195955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09690999984741211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 825,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.105484276064175e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011332482313018383,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 0.0015634836226484665,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04444171897670529,
            "feature_preprocessor:select_rates_classification:alpha": 0.325033030328863,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09715819358825684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 826,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.107340661011097e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28150091736608435,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 346,
            "classifier:CustomMLPClassifier:tol": 3.374705687402484e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 61.28587124595376,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2346288800086893,
        "time": 1.206362247467041,
        "additional_info": {
            "duration": 1.1881582736968994,
            "num_run": 827,
            "train_loss": 1.224783790085678,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 827,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.230614669919125e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006132733697209406,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.001045222617306337,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023817781443794965,
            "feature_preprocessor:select_rates_classification:alpha": 0.44409535524908117,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.26764726638793945,
        "additional_info": {
            "duration": 0.24843692779541016,
            "num_run": 828,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 828,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1663189992650336e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016458969238757907,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.0001295286079111452,
            "feature_preprocessor:select_rates_classification:alpha": 0.10494053639353287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12358903884887695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 829,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.010177926650570775,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024118569710004887,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.0009651348106086771,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019697315105887833,
            "feature_preprocessor:select_percentile_classification:percentile": 53.69748078595301,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2394711293670857,
        "time": 0.6020920276641846,
        "additional_info": {
            "duration": 0.5878491401672363,
            "num_run": 830,
            "train_loss": 1.2203773671058682,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 830,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00048001311058666336,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014461692383915725,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 1.5668720092223042e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07147295519685155,
            "feature_preprocessor:select_rates_classification:alpha": 0.02471791081696582,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09684085845947266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 831,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.007352671251990467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008997244642924057,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 3.413521181672625e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 12.930160176078836,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.23606085777282715,
        "additional_info": {
            "duration": 0.21428871154785156,
            "num_run": 832,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 832,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.853483141922011e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000816473293387623,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.0012795947242321651,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004171422138418426,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9120593230687422,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13423715132156777,
            "feature_preprocessor:select_rates_classification:alpha": 0.38725427259276834,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5918750762939453,
        "additional_info": {
            "duration": 0.5818071365356445,
            "num_run": 833,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 833,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0036184339312301597,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5588035858574562,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.001916926116301206,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002006396333443845,
            "feature_preprocessor:select_rates_classification:alpha": 0.4989100024057574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09654998779296875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 834,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00030231936497872395,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14406633564997925,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 0.00014602877691232018,
            "feature_preprocessor:select_percentile_classification:percentile": 38.47447773479211,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2010319464985595,
        "time": 0.4167139530181885,
        "additional_info": {
            "duration": 0.3995058536529541,
            "num_run": 835,
            "train_loss": 1.1764932586231986,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 835,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02768497946563162,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001442437521602822,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 0.0002530681864215718,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001758500817742058,
            "feature_preprocessor:select_percentile_classification:percentile": 14.224011655810822,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2160712635706181,
        "time": 1.6301698684692383,
        "additional_info": {
            "duration": 1.6113648414611816,
            "num_run": 836,
            "train_loss": 1.2111638267357665,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 836,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004778871015838782,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002779924786232195,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 0.004790725602644445,
            "feature_preprocessor:select_rates_classification:alpha": 0.03961863645327042,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09732389450073242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 837,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.111816139709162e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03372118998672841,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 3.318848654988812e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 84.74465640807604,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.203190656638141,
        "time": 1.0785112380981445,
        "additional_info": {
            "duration": 1.057319164276123,
            "num_run": 838,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 838,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004894805948904272,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002501757178744965,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.0027855176872508478,
            "feature_preprocessor:select_rates_classification:alpha": 0.20818584705409163,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09685516357421875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 839,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018438529453574192,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6356918338855224,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.005181272594568272,
            "feature_preprocessor:select_rates_classification:alpha": 0.49907904540585263,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12525510787963867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 840,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0287973214132965e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009802205894055002,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.0006685908455809024,
            "feature_preprocessor:select_percentile_classification:percentile": 34.84877411751369,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226089700497143,
        "time": 1.1314771175384521,
        "additional_info": {
            "duration": 1.119926929473877,
            "num_run": 841,
            "train_loss": 1.0677799244350334,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 841,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004197978946036947,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005061105598041561,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 0.009815398738596623,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 38.27824857897243,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2326781799942967,
        "time": 0.35527992248535156,
        "additional_info": {
            "duration": 0.3415522575378418,
            "num_run": 842,
            "train_loss": 1.1905610534950324,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 842,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.479616225480993e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03247261385253884,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.0005499515395992417,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004233137583235973,
            "feature_preprocessor:select_rates_classification:alpha": 0.14074824894605367,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12392115592956543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 843,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001595031006501214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003472804234817586,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.004729333385253029,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010017558500423847,
            "feature_preprocessor:select_percentile_classification:percentile": 62.36883134035749,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2144867145866303,
        "time": 0.8686230182647705,
        "additional_info": {
            "duration": 0.8570520877838135,
            "num_run": 844,
            "train_loss": 1.165330121020818,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 844,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.3482745137621954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018889392230554572,
            "classifier:CustomMLPClassifier:max_iter": 297,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.0015377540003042884,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07231997894054615,
            "feature_preprocessor:select_rates_classification:alpha": 0.38295148730821543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12355899810791016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 845,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.367675352684916e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7487761512676155,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.0006830332383791346,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.615064569205422,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2281482933670267,
        "time": 0.5765447616577148,
        "additional_info": {
            "duration": 0.5638267993927002,
            "num_run": 846,
            "train_loss": 1.0680320097685145,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 846,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0016072029604890907,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01400613457885202,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 7.087361480026282e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005285173363492332,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21891180205870742,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2333134349879533,
        "time": 0.5811300277709961,
        "additional_info": {
            "duration": 0.5611581802368164,
            "num_run": 847,
            "train_loss": 1.1762504016352087,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 847,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2442411914459509e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0839802660432839,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 175,
            "classifier:CustomMLPClassifier:tol": 5.897302836162706e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028903884732322827,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7852841735738763,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16934024545871534,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9407045645529174,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2434169706324172,
        "time": 1.8889851570129395,
        "additional_info": {
            "duration": 1.8765780925750732,
            "num_run": 848,
            "train_loss": 1.1557507406129581,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 848,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.120314801956421e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07410478428086244,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 7.12043955665141e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5534528015265249,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.244727950382666,
        "time": 1.5424230098724365,
        "additional_info": {
            "duration": 1.5273127555847168,
            "num_run": 849,
            "train_loss": 1.1057802396711944,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 849,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06876456791522349,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003709209400909039,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 0.00012866475727195528,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00970811735575562,
            "feature_preprocessor:select_percentile_classification:percentile": 40.21154843377248,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.33504199981689453,
        "additional_info": {
            "duration": 0.32251501083374023,
            "num_run": 850,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 850,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0065053127421930805,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07708260481275556,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 3.797826051529581e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 24.905179013686013,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.219530817831881,
        "time": 1.3002851009368896,
        "additional_info": {
            "duration": 1.2845392227172852,
            "num_run": 851,
            "train_loss": 1.1705501060413634,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 851,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0014090972828081888,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001744660831666348,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 1.4009060052232651e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029817522852137852,
            "feature_preprocessor:select_rates_classification:alpha": 0.06578875344398945,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12368202209472656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 852,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08735999986606889,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20479046578270746,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 289,
            "classifier:CustomMLPClassifier:tol": 0.006920132218070824,
            "feature_preprocessor:select_rates_classification:alpha": 0.26670622358432516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2259437412682264,
        "time": 0.6943390369415283,
        "additional_info": {
            "duration": 0.6835048198699951,
            "num_run": 853,
            "train_loss": 1.1689555534698954,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 853,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002502600663345476,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012088307949863646,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 387,
            "classifier:CustomMLPClassifier:tol": 0.003334890496817939,
            "feature_preprocessor:select_rates_classification:alpha": 0.25617111030284234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2117622913450137,
        "time": 0.4493551254272461,
        "additional_info": {
            "duration": 0.43782925605773926,
            "num_run": 854,
            "train_loss": 1.1525903990975328,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 854,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00027562687002906226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7993839235602475,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 3.380776182022118e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017920730683279066,
            "feature_preprocessor:select_rates_classification:alpha": 0.08909953265350397,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09515905380249023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 855,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02683616269052384,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03905298454295411,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 9.850660953636224e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.224210468153156,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7117029109099201,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.216316605028648,
        "time": 1.183607816696167,
        "additional_info": {
            "duration": 1.161768913269043,
            "num_run": 856,
            "train_loss": 1.1809523386285041,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 856,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015313092164953225,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08266776423225099,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.00474429928916087,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00440524492867769,
            "feature_preprocessor:select_rates_classification:alpha": 0.1710430403624111,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10104799270629883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 857,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002518838147758546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011276443256180121,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 1.1038897550399296e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7480860365721486,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.215582624440398,
        "time": 1.1903080940246582,
        "additional_info": {
            "duration": 1.1785709857940674,
            "num_run": 858,
            "train_loss": 1.1732989542319934,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 858,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.6875117643814085e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002363346626030317,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 1.8017457832441006e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009733207145880806,
            "feature_preprocessor:select_rates_classification:alpha": 0.48849822267473897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12247681617736816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 859,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1117002503723944e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024507100119929226,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 3.58497350839134e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 78.12778368956197,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.42182302474975586,
        "additional_info": {
            "duration": 0.409501314163208,
            "num_run": 860,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 860,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018600210345511887,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.603904225810381,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.001954200347630337,
            "feature_preprocessor:select_rates_classification:alpha": 0.2686546040202819,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0950479507446289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 861,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00027524591743230517,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007009441792948952,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 1.5563174120628445e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49854137065207055,
            "feature_preprocessor:select_percentile_classification:percentile": 9.994452096745675,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.243417213007071,
        "time": 1.9010422229766846,
        "additional_info": {
            "duration": 1.889794111251831,
            "num_run": 862,
            "train_loss": 1.2232090273152814,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 862,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0018388751686553239,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006405370123210923,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 0.0010297730836457864,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025918373959706873,
            "feature_preprocessor:select_percentile_classification:percentile": 60.384292866441065,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3187429904937744,
        "additional_info": {
            "duration": 0.3034839630126953,
            "num_run": 863,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 863,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00036127609198661803,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02714509788072228,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 0.0018502457166531781,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.33376097027985296,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2382130434307257,
        "time": 0.668748140335083,
        "additional_info": {
            "duration": 0.6547420024871826,
            "num_run": 864,
            "train_loss": 1.060736369557314,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 864,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05485628440345986,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028012202688478018,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 3.14123286469294e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.37662383778936304,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12271714210510254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 865,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007065565611511165,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5204346691127723,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 0.00020924136574919695,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03537479371356693,
            "feature_preprocessor:select_rates_classification:alpha": 0.40012132229471176,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.4529399871826172,
        "additional_info": {
            "duration": 0.44203925132751465,
            "num_run": 866,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 866,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018220098460928848,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004138944827247256,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 5.2899969977986e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9066150167283866,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2671296635522897,
        "time": 1.99428391456604,
        "additional_info": {
            "duration": 1.979252815246582,
            "num_run": 867,
            "train_loss": 1.1992514105595093,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 867,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6778230650121125e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003513757806248724,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 2.001678223938923e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 531,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.40977505074890047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.207996232429162,
        "time": 0.5967130661010742,
        "additional_info": {
            "duration": 0.5824978351593018,
            "num_run": 868,
            "train_loss": 1.162390942751065,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 868,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.004911807308558e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021807335245097847,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 6.0003112754942876e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 56.618686006453515,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 1.1791279315948486,
        "additional_info": {
            "duration": 1.1684739589691162,
            "num_run": 869,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 869,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.047275320733292436,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023056590240635673,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 0.0016182165083268934,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007423247950094313,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7178995668796105,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2045033533926389,
            "feature_preprocessor:select_percentile_classification:percentile": 69.79703660676587,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.220997160791868,
        "time": 0.28672313690185547,
        "additional_info": {
            "duration": 0.2717268466949463,
            "num_run": 870,
            "train_loss": 1.1741042285105983,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 870,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5308560782708474e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0052901229661428024,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.002439456178379763,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.46871095454820755,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2132330905279192,
        "time": 0.3035910129547119,
        "additional_info": {
            "duration": 0.28977274894714355,
            "num_run": 871,
            "train_loss": 1.2130495855693957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 871,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00036856558384728655,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005380085350369562,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 382,
            "classifier:CustomMLPClassifier:tol": 0.0003004026206064792,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2977855801004564,
            "feature_preprocessor:select_percentile_classification:percentile": 56.794741300270324,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2191115385295557,
        "time": 6.080286979675293,
        "additional_info": {
            "duration": 6.069063901901245,
            "num_run": 872,
            "train_loss": 1.1404172501413483,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 872,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03241987097364303,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002618272290863099,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 1.02028330844102e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002901502062574173,
            "feature_preprocessor:select_rates_classification:alpha": 0.26080879765359793,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12539887428283691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 873,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00020033666769452398,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08395853374871393,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.00027668411858976515,
            "feature_preprocessor:select_rates_classification:alpha": 0.49146951369244307,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09556913375854492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 874,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.606446077496635e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 1.3233324941148555e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.29950989947449275,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09485530853271484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 875,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010768290124077591,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.108240015404795,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 2.1431235869049202e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003337774019604222,
            "feature_preprocessor:select_rates_classification:alpha": 0.44213021142380693,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12228608131408691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 876,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03407790280027308,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005383882927538554,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 3.169462266002069e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005018578213848408,
            "feature_preprocessor:select_rates_classification:alpha": 0.1326512425333309,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1261448860168457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 877,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005255730162017079,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 1.0619737913887188e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4886756786223046,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12746405601501465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 878,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1922779110800844e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003502221136027237,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 1.3867082050445985e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25274111214470424,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10051679611206055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 879,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010088682262376942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02495135873071653,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 246,
            "classifier:CustomMLPClassifier:tol": 0.0005361593414099217,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006999082079278936,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5465470537766515,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2373008907928866,
        "time": 0.7583761215209961,
        "additional_info": {
            "duration": 0.7461557388305664,
            "num_run": 880,
            "train_loss": 1.1862290715648216,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 880,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07703985346711228,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00568005661177332,
            "classifier:CustomMLPClassifier:max_iter": 421,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 1.4147583624683382e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001329182262531114,
            "feature_preprocessor:select_percentile_classification:percentile": 66.6851872732479,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2227798311709153,
        "time": 0.8592278957366943,
        "additional_info": {
            "duration": 0.8473060131072998,
            "num_run": 881,
            "train_loss": 1.171586691896808,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 881,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.0880556169880254e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019890044004680283,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 1.4664012786476377e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.43181904732097165,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12279391288757324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 882,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003617189896736115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05358215282795249,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 5.373228615727516e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029584820558535393,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7583633051500128,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2383129092782008,
        "time": 0.9375426769256592,
        "additional_info": {
            "duration": 0.9239370822906494,
            "num_run": 883,
            "train_loss": 1.128745917128464,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 883,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.040917647017020525,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00034163437149819923,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.008613581552786112,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017654729114466323,
            "feature_preprocessor:select_rates_classification:alpha": 0.17996253152823447,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09525799751281738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 884,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013655171914376616,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018772734910478563,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.0045002070719235695,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02144849599667686,
            "feature_preprocessor:select_rates_classification:alpha": 0.021746241895260976,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12184977531433105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 885,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014028339156532145,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 0.0003039754664771372,
            "feature_preprocessor:select_rates_classification:alpha": 0.11418133277288972,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12175226211547852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 886,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.042093494985030636,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000732388287858754,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.0009979439862388643,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7432608785866189,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.193337894958918,
        "time": 0.9675776958465576,
        "additional_info": {
            "duration": 0.9495317935943604,
            "num_run": 887,
            "train_loss": 1.1469355627042017,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 887,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.021157991890036854,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0162969446750316,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0006456206133036671,
            "feature_preprocessor:select_percentile_classification:percentile": 11.145535812795197,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2333202501226999,
        "time": 0.4474198818206787,
        "additional_info": {
            "duration": 0.4337759017944336,
            "num_run": 888,
            "train_loss": 1.2387016072892594,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 888,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011583833207417865,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00976747490579002,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 412,
            "classifier:CustomMLPClassifier:tol": 0.0011595428506348659,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011194931871902666,
            "feature_preprocessor:select_percentile_classification:percentile": 18.95949871181887,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2068455591227696,
        "time": 1.040844202041626,
        "additional_info": {
            "duration": 1.0238049030303955,
            "num_run": 889,
            "train_loss": 1.1995874198071328,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 889,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.11904470905625e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06647171015039778,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 138,
            "classifier:CustomMLPClassifier:tol": 1.0110569599249338e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.057481367524765646,
            "feature_preprocessor:select_rates_classification:alpha": 0.2628483646348276,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10137724876403809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 890,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011025348902955853,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09418605121786412,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.0001470648351325752,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00045264198645862615,
            "feature_preprocessor:select_rates_classification:alpha": 0.4158135513697954,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12694096565246582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 891,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00020545506190277786,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009804581127944864,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0001365591720229076,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 128,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.38734876628031034,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226504513398035,
        "time": 3.745659112930298,
        "additional_info": {
            "duration": 3.7336461544036865,
            "num_run": 892,
            "train_loss": 1.1667151779833462,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 892,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.919173130785848e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04737101801227519,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.0011511134869862144,
            "feature_preprocessor:select_percentile_classification:percentile": 2.437368113812105,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.452564001083374,
        "additional_info": {
            "duration": 0.44222211837768555,
            "num_run": 893,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 893,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.024428588889338333,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00029586404057096397,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.0013418733759670502,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020524326597548857,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8442013261733938,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1473144562346101,
            "feature_preprocessor:select_percentile_classification:percentile": 70.17944360884893,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.208477333824458,
        "time": 1.971620798110962,
        "additional_info": {
            "duration": 1.9592418670654297,
            "num_run": 894,
            "train_loss": 1.1762391598295263,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 894,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.2054003766927253e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08533486987749965,
            "classifier:CustomMLPClassifier:max_iter": 452,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.0033405145607270296,
            "feature_preprocessor:select_rates_classification:alpha": 0.40365947962873194,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09601688385009766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 895,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007608787068193281,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1409523865120743,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 0.0005185655840510287,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8984839519797898,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16136989879866415,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45382922373648815,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2454758070079008,
        "time": 3.3862881660461426,
        "additional_info": {
            "duration": 3.374192714691162,
            "num_run": 896,
            "train_loss": 1.0818472067313973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 896,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.837392501053219e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005330836760036842,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.0001135630259919261,
            "feature_preprocessor:select_percentile_classification:percentile": 69.39200777812633,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.5138231606158947,
        "time": 0.7203137874603271,
        "additional_info": {
            "duration": 0.7061419486999512,
            "num_run": 897,
            "train_loss": 1.528445433042028,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 897,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010692013867532537,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004671350228694129,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 103,
            "classifier:CustomMLPClassifier:tol": 0.0008608780074822564,
            "feature_preprocessor:select_percentile_classification:percentile": 88.5843806495006,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2197752625426292,
        "time": 0.5245511531829834,
        "additional_info": {
            "duration": 0.5096559524536133,
            "num_run": 898,
            "train_loss": 1.1561435376111973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 898,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012337852614378204,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007384147967436635,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 387,
            "classifier:CustomMLPClassifier:tol": 5.572271495997919e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.27763716975275754,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2340295714584462,
        "time": 11.570722103118896,
        "additional_info": {
            "duration": 11.560157060623169,
            "num_run": 899,
            "train_loss": 1.043065454535769,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 899,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014630921665769993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07352370373103014,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 0.0011937625320289978,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20327801292137662,
            "feature_preprocessor:select_rates_classification:alpha": 0.26038023115461373,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.232828356464316,
        "time": 0.6436638832092285,
        "additional_info": {
            "duration": 0.6325950622558594,
            "num_run": 900,
            "train_loss": 1.1579402784476789,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 900,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0750055561401851e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012099759151095669,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.0006495538125772001,
            "feature_preprocessor:select_rates_classification:alpha": 0.3125706436299343,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0961306095123291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 901,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02706972080580932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.996467235747022,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.0042153399061200395,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006827434477994088,
            "feature_preprocessor:select_rates_classification:alpha": 0.24944052570774036,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10910987854003906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 902,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005899785731236372,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36671568969012724,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.0008215559378001579,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013046131242585385,
            "feature_preprocessor:select_rates_classification:alpha": 0.17672357315618237,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12211894989013672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 903,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2757272720150906e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7004696306882802,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 364,
            "classifier:CustomMLPClassifier:tol": 0.0013801270347548846,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17710627872744666,
            "feature_preprocessor:select_rates_classification:alpha": 0.27534057976019877,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3526592254638672,
        "additional_info": {
            "duration": 0.3320810794830322,
            "num_run": 904,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 904,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009018628502303177,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001309986587341923,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.0006754074821849533,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00113542527437253,
            "feature_preprocessor:select_rates_classification:alpha": 0.1755759799156414,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12917804718017578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 905,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.023187419518367468,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004367288617093483,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 0.001657932458735722,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00038006937613758757,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6209923714471764,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2503537513874883,
        "time": 0.9068138599395752,
        "additional_info": {
            "duration": 0.8806712627410889,
            "num_run": 906,
            "train_loss": 1.0934738498151297,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 906,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.009388714205526e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18344102693679662,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 2.475183548656648e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 59.05367996797592,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2264521077262922,
        "time": 1.196523904800415,
        "additional_info": {
            "duration": 1.1855080127716064,
            "num_run": 907,
            "train_loss": 1.1383705846085241,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 907,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02633977612575406,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23765002616129854,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 3.734598586399636e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3698954707107986,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09556412696838379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 908,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.7810146918846195e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20157815195038392,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 2.6663006643166993e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2908978001000541,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12359333038330078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 909,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005032678452634332,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9509248154222986,
            "classifier:CustomMLPClassifier:max_iter": 234,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 0.00041806923256556086,
            "feature_preprocessor:select_rates_classification:alpha": 0.1343606182708348,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12292003631591797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 910,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.493372477803932e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5532562623122816,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.0008592207490482292,
            "feature_preprocessor:select_percentile_classification:percentile": 56.86023594916769,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2565387029127675,
        "time": 0.3262929916381836,
        "additional_info": {
            "duration": 0.30846118927001953,
            "num_run": 911,
            "train_loss": 1.1891451178169046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 911,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.829756072174999e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001757590703867432,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 5.4479258300272384e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7533352511483843,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16499206029821695,
            "feature_preprocessor:select_percentile_classification:percentile": 29.83151446569856,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2085570045589706,
        "time": 10.314038038253784,
        "additional_info": {
            "duration": 10.296415567398071,
            "num_run": 912,
            "train_loss": 1.0960107688197853,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 912,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008859996042020153,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031212032130041897,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.0006419810226067299,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012941714046284815,
            "feature_preprocessor:select_percentile_classification:percentile": 42.482987044801504,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2320280964292305,
        "time": 4.879223108291626,
        "additional_info": {
            "duration": 4.867594957351685,
            "num_run": 913,
            "train_loss": 1.0524197499428383,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 913,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0028519683060918115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020508935344230745,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 0.0006635168026025496,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002702070966660226,
            "feature_preprocessor:select_percentile_classification:percentile": 75.80516564244509,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.211160142526473,
        "time": 3.137709856033325,
        "additional_info": {
            "duration": 3.124791145324707,
            "num_run": 914,
            "train_loss": 1.1739021874225328,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 914,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07490896040991978,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00903313398626765,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 4.0224713879187914e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.38263240063493287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1284160614013672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 915,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7590963058632605e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003738513700216062,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 1.0480169606770388e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020037726443806494,
            "feature_preprocessor:select_rates_classification:alpha": 0.3827626281222575,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2017269070480134,
        "time": 1.1588988304138184,
        "additional_info": {
            "duration": 1.145777702331543,
            "num_run": 916,
            "train_loss": 1.1572980316705637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 916,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.020599679910982,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9738696449275307,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 1.5430261226473517e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7032232302315038,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07971992261275566,
            "feature_preprocessor:select_rates_classification:alpha": 0.281488652346127,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2249155014054522,
        "time": 0.3294217586517334,
        "additional_info": {
            "duration": 0.315762996673584,
            "num_run": 917,
            "train_loss": 1.2087860156543233,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 917,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00025478453096244543,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019066878198045166,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 0.0008389267703255679,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04035624150732546,
            "feature_preprocessor:select_rates_classification:alpha": 0.484473065588056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12365102767944336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 918,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011194676570123044,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009539340334462388,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 7.010536827615173e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39947237073259795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12263011932373047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 919,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.775871524701579e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001681849633193028,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 3.648132835883161e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002296486795687177,
            "feature_preprocessor:select_percentile_classification:percentile": 44.63114567168214,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.6370301246643066,
        "additional_info": {
            "duration": 0.6198241710662842,
            "num_run": 920,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 920,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0975087933263538e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016059212468353889,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 0.00021771262188892345,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023974203199230385,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9012946234037182,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27112849932189925,
            "feature_preprocessor:select_percentile_classification:percentile": 63.66832697526111,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2179789585012508,
        "time": 0.4682149887084961,
        "additional_info": {
            "duration": 0.4566168785095215,
            "num_run": 921,
            "train_loss": 1.1815445639347286,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 921,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006287501320593474,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009366434925882747,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 0.0004655870556691323,
            "feature_preprocessor:select_rates_classification:alpha": 0.2968312422415817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0958559513092041,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 922,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.688189375219921e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000926382106370788,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 2.7272895698990854e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014657413025869766,
            "feature_preprocessor:select_percentile_classification:percentile": 82.5599264286963,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 1.2600769996643066,
        "additional_info": {
            "duration": 1.2493669986724854,
            "num_run": 923,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 923,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.47210037797334e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009500012665654528,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 1.990534365351686e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08595773607662986,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07621456397224935,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2273503741486318,
        "time": 0.8148388862609863,
        "additional_info": {
            "duration": 0.8021728992462158,
            "num_run": 924,
            "train_loss": 1.1815026773348145,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 924,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5854467920320407e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09468754640481133,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 0.005910567977848237,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11920625734649318,
            "feature_preprocessor:select_rates_classification:alpha": 0.46335980234518487,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12892794609069824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 925,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09872032092610215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014681079615138821,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 3.0118501243056798e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02493342995694821,
            "feature_preprocessor:select_rates_classification:alpha": 0.08628799055133363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10159897804260254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 926,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03098910223831098,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020102072885543657,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 5.792120984866598e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026555015759795104,
            "feature_preprocessor:select_rates_classification:alpha": 0.2817563989582159,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.31000232696533203,
        "additional_info": {
            "duration": 0.29717111587524414,
            "num_run": 927,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 927,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.133145691250826e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007284654984072461,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.0007947127823720936,
            "feature_preprocessor:select_rates_classification:alpha": 0.3446571720401441,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2031018175117847,
        "time": 3.4482932090759277,
        "additional_info": {
            "duration": 3.434840202331543,
            "num_run": 928,
            "train_loss": 1.141903573636802,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 928,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0850475153149338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02813922448274311,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.0010614260445804668,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8306363264121401,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08661863706195137,
            "feature_preprocessor:select_percentile_classification:percentile": 70.12451702735973,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2421811940843017,
        "time": 0.9724421501159668,
        "additional_info": {
            "duration": 0.962043046951294,
            "num_run": 929,
            "train_loss": 1.0590684339295993,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 929,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01804526491203928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8690241232079905,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 5.5621470381607446e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2023600486872935,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09668278694152832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 930,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07109373491692664,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013796631792320926,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 0.0007550659592298398,
            "feature_preprocessor:select_rates_classification:alpha": 0.040038147992762556,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10158801078796387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 931,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.2619544192600705e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03498848093655133,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 0.0004140005267542466,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08453620038544606,
            "feature_preprocessor:select_rates_classification:alpha": 0.15302065674023627,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12952971458435059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 932,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1261579973070778e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014098872296838572,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.0003240290856886713,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10706565170819599,
            "feature_preprocessor:select_rates_classification:alpha": 0.18125301492137885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12416625022888184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 933,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001635407285679251,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28390994776553374,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.007719719660886963,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3737583688472368,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.39533305168151855,
        "additional_info": {
            "duration": 0.383145809173584,
            "num_run": 934,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 934,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0219072326160131,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004705529363008429,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.001286703729936696,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8057428104467846,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2421400620321157,
        "time": 0.4464759826660156,
        "additional_info": {
            "duration": 0.4311988353729248,
            "num_run": 935,
            "train_loss": 1.196979409860524,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 935,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.436152541824341e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029647363300198848,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 0.0003596807277039285,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028027541552833973,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1990,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.013737695273990661,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.36878108978271484,
        "additional_info": {
            "duration": 0.3569149971008301,
            "num_run": 936,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 936,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09963565117658835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010054342636831841,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.003517135773105913,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3927336948830014,
            "feature_preprocessor:select_rates_classification:alpha": 0.28646233872199167,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1229250431060791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 937,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09531589839654252,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012891891046738497,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 0.00017899811677071577,
            "feature_preprocessor:select_rates_classification:alpha": 0.4163785330451246,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10362696647644043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 938,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0020158286179487585,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005756947294396078,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.001060599226040345,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49309198579903746,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.246214009361038,
        "time": 0.38991808891296387,
        "additional_info": {
            "duration": 0.37692713737487793,
            "num_run": 939,
            "train_loss": 1.202984941967972,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 939,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013892827359946155,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002618234363268685,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 2.2900563147833678e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22615935074497442,
            "feature_preprocessor:select_rates_classification:alpha": 0.10041826099944107,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2005332343125914,
        "time": 6.095264911651611,
        "additional_info": {
            "duration": 6.081567049026489,
            "num_run": 940,
            "train_loss": 1.1936784184733946,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 940,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010122847897143652,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013026973936650525,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 2.4562730761702303e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.14561514330779196,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12298774719238281,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 941,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.795922133789906e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016921493190548504,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 1.750516893786176e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 16.51798344730812,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2061477628288026,
        "time": 1.1144793033599854,
        "additional_info": {
            "duration": 1.1027541160583496,
            "num_run": 942,
            "train_loss": 1.2109840353376982,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 942,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0020504629091617037,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014425752423037957,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 0.00019472086850297362,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1304,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.38815971689295337,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2295612532400326,
        "time": 3.058286190032959,
        "additional_info": {
            "duration": 3.046135902404785,
            "num_run": 943,
            "train_loss": 1.153465803137046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 943,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008913436508699146,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011355503192727923,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 6.395668978005585e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04793149820798685,
            "feature_preprocessor:select_rates_classification:alpha": 0.013819525561650815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12381100654602051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 944,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.515865841505661e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 1.2931712549290995e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.3283596661451386,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12382221221923828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 945,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.5085882596595084e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004476092845290663,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.00010138540705394137,
            "feature_preprocessor:select_rates_classification:alpha": 0.4505996465081321,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09659218788146973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 946,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.3714592008898353e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9620252695050019,
            "classifier:CustomMLPClassifier:max_iter": 207,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 1.693942504622453e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 4.935404333105918,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.2873351573944092,
        "additional_info": {
            "duration": 0.274716854095459,
            "num_run": 947,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 947,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00013408311219840726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026006365218699443,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.00029633872486251793,
            "feature_preprocessor:select_rates_classification:alpha": 0.050025352579112524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10133099555969238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 948,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9044518508853868e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014102212395165107,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 0.00042391572228919826,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09010388340938968,
            "feature_preprocessor:select_rates_classification:alpha": 0.017670016445691227,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1293339729309082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 949,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.674907006832036e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007394623418723124,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.0005499407797649354,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9423872578553061,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11339837175875869,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.26997702439661,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2261966283778025,
        "time": 0.9445178508758545,
        "additional_info": {
            "duration": 0.9319679737091064,
            "num_run": 950,
            "train_loss": 1.1908256248230245,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 950,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002539380025061659,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005590417977814536,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 0.0005337213772770006,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017947592713059987,
            "feature_preprocessor:select_percentile_classification:percentile": 36.881079194525775,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2326483317401824,
        "time": 3.3343589305877686,
        "additional_info": {
            "duration": 3.3236920833587646,
            "num_run": 951,
            "train_loss": 1.0844105495233796,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 951,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032646609942711414,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.0006171825401177704,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.06496564656307324,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10074973106384277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 952,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3834007188614363e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3232387515154263,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 2.1043849965594555e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02784709580780761,
            "feature_preprocessor:select_rates_classification:alpha": 0.010981741529338262,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12630510330200195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 953,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.028025538076953502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3811701430558138,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.0002805939279379391,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00043016906650009454,
            "feature_preprocessor:select_rates_classification:alpha": 0.11383402823804743,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09636712074279785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 954,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012344384891373838,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018106138507064364,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.0049726413326350955,
            "feature_preprocessor:select_rates_classification:alpha": 0.3292185058474624,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09617877006530762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 955,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.973642723928721e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.036852906362513864,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.009053242179776783,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8271043953471044,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15424864282101994,
            "feature_preprocessor:select_percentile_classification:percentile": 1.5426217935708257,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.19903206825256348,
        "additional_info": {
            "duration": 0.18755197525024414,
            "num_run": 956,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 956,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.606581734095996e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011888451306249618,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.001243120619041284,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005055556021881704,
            "feature_preprocessor:select_rates_classification:alpha": 0.039792816486503235,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10262322425842285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 957,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004328469594896885,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.810494600581269,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 1.34651850027923e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0021102537478859453,
            "feature_preprocessor:select_rates_classification:alpha": 0.35286426911391605,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09633517265319824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 958,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09863762435139087,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022912039012822703,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.0043173001590787255,
            "feature_preprocessor:select_rates_classification:alpha": 0.49678359598563504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12338781356811523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 959,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.243858551863852e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011388319788468266,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 282,
            "classifier:CustomMLPClassifier:tol": 0.00017265383737874974,
            "feature_preprocessor:select_rates_classification:alpha": 0.15407518495804176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12845683097839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 960,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003778110809028873,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03499700516875376,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 0.007232869310694295,
            "feature_preprocessor:select_rates_classification:alpha": 0.09290450833217498,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09610390663146973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 961,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.704278880947616e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05845707064559277,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.0036703516174785527,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28513520656583,
            "feature_preprocessor:select_rates_classification:alpha": 0.26562087010897106,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2258433872786052,
        "time": 0.42114925384521484,
        "additional_info": {
            "duration": 0.4105260372161865,
            "num_run": 962,
            "train_loss": 1.1773184904775074,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 962,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.8697275312087e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3263957292936438,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.00013978009273000336,
            "feature_preprocessor:select_rates_classification:alpha": 0.16601466798403702,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09739398956298828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 963,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009519928426399973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22678689219620893,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 4.283296240951506e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.885421365047652,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09306023751549067,
            "feature_preprocessor:select_percentile_classification:percentile": 67.12244591324605,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2578811604431046,
        "time": 1.9251959323883057,
        "additional_info": {
            "duration": 1.9036669731140137,
            "num_run": 964,
            "train_loss": 1.0536244801573034,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 964,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.1005953745619034e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019251352114187114,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.002189643912660841,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002091699202231517,
            "feature_preprocessor:select_rates_classification:alpha": 0.48075882653925817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12805414199829102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 965,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07289821319040671,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020545077884308455,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 6.621469519004941e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00045863574761966565,
            "feature_preprocessor:select_rates_classification:alpha": 0.4519174185976586,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.6604197025299072,
        "additional_info": {
            "duration": 0.6474099159240723,
            "num_run": 966,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 966,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003592746231746435,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01726657595530254,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 9.404137390612858e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7364525052130184,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06610254389266201,
            "feature_preprocessor:select_percentile_classification:percentile": 16.27486051698176,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2250226750536042,
        "time": 1.54365873336792,
        "additional_info": {
            "duration": 1.5323660373687744,
            "num_run": 967,
            "train_loss": 1.2137693120072401,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 967,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015825457441401762,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014086153858576293,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.0003255901537118682,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003238690773140914,
            "feature_preprocessor:select_rates_classification:alpha": 0.03332497991215084,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.222895931967203,
        "time": 7.560023069381714,
        "additional_info": {
            "duration": 7.546555757522583,
            "num_run": 968,
            "train_loss": 1.1130616853936868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 968,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00013628127448440814,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03929783743597084,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 0.0034165413822928167,
            "feature_preprocessor:select_rates_classification:alpha": 0.4285808026805916,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2315655707994377,
        "time": 0.9863400459289551,
        "additional_info": {
            "duration": 0.9696688652038574,
            "num_run": 969,
            "train_loss": 1.00976683883417,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 969,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.085047648347818e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011344438387261204,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 0.0005481174630995354,
            "feature_preprocessor:select_percentile_classification:percentile": 11.5786232397578,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.6402699947357178,
        "additional_info": {
            "duration": 0.6297180652618408,
            "num_run": 970,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 970,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.030807493689263186,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0049513454881722945,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 6.221774666258729e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008303700644023112,
            "feature_preprocessor:select_percentile_classification:percentile": 82.91857703614798,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.47154903411865234,
        "additional_info": {
            "duration": 0.45766687393188477,
            "num_run": 971,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 971,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.849545570143722e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013715709495269266,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 0.0008826071395988996,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3006952870254377,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2457850735247231,
        "time": 0.4797048568725586,
        "additional_info": {
            "duration": 0.46800923347473145,
            "num_run": 972,
            "train_loss": 1.1839984996086024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 972,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03821952637911881,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02408862314675338,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 0.009448175379548179,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2931755162141271,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2004396920648785,
        "time": 0.36736416816711426,
        "additional_info": {
            "duration": 0.3541738986968994,
            "num_run": 973,
            "train_loss": 1.1846737892758215,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 973,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008019083659201015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007640303703506798,
            "classifier:CustomMLPClassifier:max_iter": 426,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 0.00013579333575835766,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002684364246486583,
            "feature_preprocessor:select_rates_classification:alpha": 0.4285312123361535,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12404203414916992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 974,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.2753195463095546e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19048166303890887,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 1.0866334355133074e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005122746650551903,
            "feature_preprocessor:select_rates_classification:alpha": 0.0645103012002124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09648489952087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 975,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004358979809321363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029775014335527084,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.005703629619531029,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.274220561447293,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.4644179344177246,
        "additional_info": {
            "duration": 0.38164567947387695,
            "num_run": 976,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 976,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0007210412288806706,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016141231918719412,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.0005644333488693914,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 613,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8350552177285275,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.253080771391802,
        "time": 0.7896549701690674,
        "additional_info": {
            "duration": 0.7773158550262451,
            "num_run": 977,
            "train_loss": 1.1675631515054374,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 977,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0007819594136152778,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0368085517441867,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 0.00011339704948001499,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008804346733256318,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9071990950388279,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.014239910238686298,
            "feature_preprocessor:select_percentile_classification:percentile": 69.31264632545592,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2242341711254912,
        "time": 1.263920783996582,
        "additional_info": {
            "duration": 1.2516350746154785,
            "num_run": 978,
            "train_loss": 1.001606734960511,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 978,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009053441195963964,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000307345437951209,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 2.7199301952546288e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018199849498360614,
            "feature_preprocessor:select_rates_classification:alpha": 0.3503534754115141,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.227753916822805,
        "time": 1.2081480026245117,
        "additional_info": {
            "duration": 1.196481704711914,
            "num_run": 979,
            "train_loss": 1.1673197819419778,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 979,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00031677540043906655,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012775835089254254,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.0017890713976792781,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0066717047747377155,
            "feature_preprocessor:select_rates_classification:alpha": 0.331927817898962,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10196781158447266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 980,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.002831454197813831,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0875431015883534,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.0037143685231340135,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4143946316801512,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.213813822181713,
        "time": 0.79380202293396,
        "additional_info": {
            "duration": 0.779839277267456,
            "num_run": 981,
            "train_loss": 1.1631217155475426,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 981,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.586530712243413e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0092247842004113,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 0.0017097863137610788,
            "feature_preprocessor:select_percentile_classification:percentile": 33.603348470504706,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.33855104446411133,
        "additional_info": {
            "duration": 0.32551002502441406,
            "num_run": 982,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 982,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006878172333053236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1569353346351369,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.0005859397313181187,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012236031261661014,
            "feature_preprocessor:select_rates_classification:alpha": 0.30372842947079287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09639191627502441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 983,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05913815762731885,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016717576662691498,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.000294592088935115,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034448015918113694,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9094994501796401,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07548108382077037,
            "feature_preprocessor:select_percentile_classification:percentile": 70.66893252822753,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1978926967846983,
        "time": 7.258437156677246,
        "additional_info": {
            "duration": 7.241832971572876,
            "num_run": 984,
            "train_loss": 1.1816914197847972,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 984,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00020840465976612482,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007620317876925744,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 0.002643593816682957,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14259112351046066,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.3390028476715088,
        "additional_info": {
            "duration": 0.3169729709625244,
            "num_run": 985,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 985,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021635209276107237,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006611773670646657,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 5.874018985971399e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3462187714456536,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2513500309827583,
        "time": 3.1278042793273926,
        "additional_info": {
            "duration": 3.1119539737701416,
            "num_run": 986,
            "train_loss": 1.1366126050164072,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 986,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02352362780419446,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019042821915328138,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.003189782905941136,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002259979748915616,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7390226510417078,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2439958281236911,
        "time": 0.54640793800354,
        "additional_info": {
            "duration": 0.5317292213439941,
            "num_run": 987,
            "train_loss": 1.1733094039917882,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 987,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2579881434166444e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004078413982569203,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 350,
            "classifier:CustomMLPClassifier:tol": 0.00017995920189023122,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02068411665526415,
            "feature_preprocessor:select_rates_classification:alpha": 0.34457826808716624,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.23410266830192,
        "time": 0.574944019317627,
        "additional_info": {
            "duration": 0.5622599124908447,
            "num_run": 988,
            "train_loss": 1.1737757583514281,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 988,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 9.904478622348259e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035355233516307545,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 123,
            "classifier:CustomMLPClassifier:tol": 0.003512606221625946,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01631203046870595,
            "feature_preprocessor:select_rates_classification:alpha": 0.449087912483457,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09650206565856934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 989,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.035955457932712924,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6910342057009036,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 1.9745900341512263e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28464443287252805,
            "feature_preprocessor:select_rates_classification:alpha": 0.37320265693757343,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10273885726928711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 990,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0014416964254991597,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06834676340844024,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 0.00016557250122803654,
            "feature_preprocessor:select_rates_classification:alpha": 0.3194703647824889,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09863018989562988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 991,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00046593635042868094,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01480187756362517,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 4.271803644050727e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010236366025977062,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 279,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9312214864403159,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226819219207744,
        "time": 2.8791608810424805,
        "additional_info": {
            "duration": 2.863077163696289,
            "num_run": 992,
            "train_loss": 1.0281609257706859,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 992,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09813377366942663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036283420148478375,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 1.0738639655752739e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.13304925073008794,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10081815719604492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 993,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00018883828396443797,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008732186441641596,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 178,
            "classifier:CustomMLPClassifier:tol": 0.0035106155911984256,
            "feature_preprocessor:select_rates_classification:alpha": 0.11126715613677052,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12360095977783203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 994,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3258922894952863e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018390934200337257,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.009585905374569284,
            "feature_preprocessor:select_rates_classification:alpha": 0.16876518023499484,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12276887893676758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 995,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01132769158676531,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23495842511542553,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 96,
            "classifier:CustomMLPClassifier:tol": 5.506059506317256e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02667357029846603,
            "feature_preprocessor:select_rates_classification:alpha": 0.20398775633400992,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1292726993560791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 996,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.900675018631305e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25152195189364845,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 5.242100464707458e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4246827419828504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09688305854797363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 997,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0016713391384294573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00480204821650257,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.004581044912150959,
            "feature_preprocessor:select_percentile_classification:percentile": 26.147732183822367,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1951255164887062,
        "time": 0.24140214920043945,
        "additional_info": {
            "duration": 0.22356700897216797,
            "num_run": 998,
            "train_loss": 1.196100170810312,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 998,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006305671893010586,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004219097281341845,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 409,
            "classifier:CustomMLPClassifier:tol": 0.0008831568428084357,
            "feature_preprocessor:select_rates_classification:alpha": 0.4336847258957286,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12353992462158203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 999,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004656009605018477,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8984184040308258,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.005623591811721959,
            "feature_preprocessor:select_rates_classification:alpha": 0.04840289611478014,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09652471542358398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1000,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.0585639831791525e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016653636991069146,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 327,
            "classifier:CustomMLPClassifier:tol": 0.0012687204119959002,
            "feature_preprocessor:select_rates_classification:alpha": 0.4282871663787606,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13356494903564453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1001,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012329568558243772,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018443201602917835,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 166,
            "classifier:CustomMLPClassifier:tol": 0.005808944537815072,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 32,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8222917960880137,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2334878587125024,
        "time": 0.33726072311401367,
        "additional_info": {
            "duration": 0.3125429153442383,
            "num_run": 1002,
            "train_loss": 1.1933504630665346,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1002,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.2411213715904793e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25544590154056823,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 0.0014710629836102885,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7620110463974483,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23852471752384471,
            "feature_preprocessor:select_percentile_classification:percentile": 48.04077922337573,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2956399723517706,
        "time": 0.39246702194213867,
        "additional_info": {
            "duration": 0.37779998779296875,
            "num_run": 1003,
            "train_loss": 1.2420732388359261,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1003,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1244454187215677e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001686303864421123,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 0.0021158355816487066,
            "feature_preprocessor:select_rates_classification:alpha": 0.4648575993104396,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09619593620300293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1004,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.39335417373907e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005667598507256373,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0017822211374669053,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020596019267234426,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1991,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20547418227912062,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2564346051218904,
        "time": 0.42081689834594727,
        "additional_info": {
            "duration": 0.40884923934936523,
            "num_run": 1005,
            "train_loss": 1.1021534364540253,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1005,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.041733623475267e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01622788253234079,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.00029682218424945795,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013458811951723326,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 18,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6175576886879344,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2727211408539958,
        "time": 0.428081750869751,
        "additional_info": {
            "duration": 0.41136598587036133,
            "num_run": 1006,
            "train_loss": 1.1920924344950004,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1006,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007267003330274299,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010555486053806908,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 0.00015857476306201324,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014533979945613012,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1916,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 94.75825812982893,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2228595019054278,
        "time": 0.3888051509857178,
        "additional_info": {
            "duration": 0.37216806411743164,
            "num_run": 1007,
            "train_loss": 1.1622650924021647,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1007,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002456742532486165,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.0003039754664771372,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007843311174742481,
            "feature_preprocessor:select_rates_classification:alpha": 0.101159676995707,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12852883338928223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1008,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0013326488513466404,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031987803356523695,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 75,
            "classifier:CustomMLPClassifier:tol": 0.0005504335611985123,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008174563270282537,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1164,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24907328981230115,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1975216059130132,
        "time": 0.3346571922302246,
        "additional_info": {
            "duration": 0.31499314308166504,
            "num_run": 1009,
            "train_loss": 1.180255826599068,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1009,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00036981956339089667,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015665474935055386,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.0002510898501801137,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001385143462503767,
            "feature_preprocessor:select_rates_classification:alpha": 0.17921172710076147,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12351512908935547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1010,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.209540604226711e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001772300174285019,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 0.004193380694933895,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1554,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.35112370778375546,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2757717938161548,
        "time": 0.2942929267883301,
        "additional_info": {
            "duration": 0.2740437984466553,
            "num_run": 1011,
            "train_loss": 1.2303099110078177,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1011,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00017707940305644628,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28376623031869935,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 133,
            "classifier:CustomMLPClassifier:tol": 0.001089260060463693,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 412,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 90.15809069262379,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.34259700775146484,
        "additional_info": {
            "duration": 0.32755422592163086,
            "num_run": 1012,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1012,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00047945542221514034,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1039921356845397,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 0.00026170613795837606,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 739,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 95.73062941463219,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.188801672291479,
        "time": 0.3303830623626709,
        "additional_info": {
            "duration": 0.31813716888427734,
            "num_run": 1013,
            "train_loss": 1.1624867270279378,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1013,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011912315618943467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006496963204085138,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 3.842756659810882e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035749049004069805,
            "feature_preprocessor:select_rates_classification:alpha": 0.07164744593225428,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12373590469360352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1014,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5516833808873288e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026839583573879952,
            "classifier:CustomMLPClassifier:max_iter": 461,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.0001703266950580844,
            "feature_preprocessor:select_rates_classification:alpha": 0.492662908352812,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0967857837677002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1015,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.6939446242481436e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001832452678116628,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 2.9404274272129837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012521694538980031,
            "feature_preprocessor:select_percentile_classification:percentile": 89.67554651381906,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2079372483425963,
        "time": 1.251556158065796,
        "additional_info": {
            "duration": 1.2344591617584229,
            "num_run": 1016,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1016,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01652730939873866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011011128033004493,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 1.0086392595511664e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.012372722386578609,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1284651756286621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1017,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002029424691412557,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003399600493326627,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 175,
            "classifier:CustomMLPClassifier:tol": 0.0004119434518466747,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1908,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 35.86551095180591,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2050920076119827,
        "time": 0.34444117546081543,
        "additional_info": {
            "duration": 0.3339822292327881,
            "num_run": 1018,
            "train_loss": 1.178913425507816,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1018,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.43058395230615e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014371126782639976,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.008907654480271364,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2624358322773921,
            "feature_preprocessor:select_rates_classification:alpha": 0.10536550554500522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09677600860595703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1019,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.563716396135262e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004952373783231748,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.00015494801560323154,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03424098108977094,
            "feature_preprocessor:select_rates_classification:alpha": 0.30814107971569116,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13004326820373535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1020,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.473833419959387e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005129143925023876,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.004262459206712443,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017303701191440993,
            "feature_preprocessor:select_percentile_classification:percentile": 89.99362014782328,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.23807501792907715,
        "additional_info": {
            "duration": 0.2271580696105957,
            "num_run": 1021,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1021,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09141556641831604,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005237742687708759,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.0001414408934757559,
            "feature_preprocessor:select_rates_classification:alpha": 0.35788901289474817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0964968204498291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1022,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.1036932125817474e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04565910004705932,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.00783568453523636,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04075534704646224,
            "feature_preprocessor:select_percentile_classification:percentile": 87.60765970222504,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.26770997047424316,
        "additional_info": {
            "duration": 0.257343053817749,
            "num_run": 1023,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1023,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.019635919442024932,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006154431829870857,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.0036442582185268082,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 388,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.47142510112946134,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2190866312476678,
        "time": 0.49570727348327637,
        "additional_info": {
            "duration": 0.4834461212158203,
            "num_run": 1024,
            "train_loss": 1.1807311320106222,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1024,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01123040947539508,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6541500812423824,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 0.009533704521874955,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 872,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7976596812500223,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2872753850571472,
        "time": 0.4491581916809082,
        "additional_info": {
            "duration": 0.42943596839904785,
            "num_run": 1025,
            "train_loss": 1.1995060013309666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1025,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001204921045083015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.052170615821400534,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 0.0004349049851817827,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9980650873904184,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.036545143258256016,
            "feature_preprocessor:select_rates_classification:alpha": 0.16215155329718572,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2716946601867676,
        "additional_info": {
            "duration": 0.2589859962463379,
            "num_run": 1026,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1026,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.3560052438102528e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016942206192066117,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.0013295668694462905,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030836748007964996,
            "feature_preprocessor:select_rates_classification:alpha": 0.019370188911884963,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12372374534606934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1027,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.417616754739729e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09336330865832654,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 2.6800949800073194e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025002486981993014,
            "feature_preprocessor:select_rates_classification:alpha": 0.4936600899351812,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.225088961286116,
        "time": 0.33187198638916016,
        "additional_info": {
            "duration": 0.3210141658782959,
            "num_run": 1028,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1028,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.676520444058954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005298768244460117,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.0008938035321558828,
            "feature_preprocessor:select_percentile_classification:percentile": 64.70525007725922,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2137118375351719,
        "time": 0.9189109802246094,
        "additional_info": {
            "duration": 0.9035179615020752,
            "num_run": 1029,
            "train_loss": 1.0305065307406476,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1029,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012506511368874777,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03084720462314753,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 0.003730921940621873,
            "feature_preprocessor:select_rates_classification:alpha": 0.45821429548512604,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10155701637268066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1030,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003447055335733938,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006788164541046636,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.007550247107474023,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38039182165466917,
            "feature_preprocessor:select_rates_classification:alpha": 0.13893690501490222,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.101409912109375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1031,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.030278089355966698,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11811635184966232,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.00013383013964295362,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01016970848128308,
            "feature_preprocessor:select_rates_classification:alpha": 0.01670256481428398,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09570002555847168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1032,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.461941820537446e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002816504358416524,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.008197767676890573,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47167635884634185,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9783230089659793,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11472831025328942,
            "feature_preprocessor:select_rates_classification:alpha": 0.17343654932706817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2296073353120134,
        "time": 0.260037899017334,
        "additional_info": {
            "duration": 0.2450709342956543,
            "num_run": 1033,
            "train_loss": 1.2301442287145634,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1033,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.1128212719134757e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002901995227022091,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 1.2626812701237773e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008666913029360863,
            "feature_preprocessor:select_rates_classification:alpha": 0.14609611181142226,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0955510139465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1034,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01679350431116616,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6432182611830484,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 0.00019557540907423352,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8306110526058884,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.082127630061108,
            "feature_preprocessor:select_percentile_classification:percentile": 11.054385154211836,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2765495088740182,
        "time": 0.27329516410827637,
        "additional_info": {
            "duration": 0.2627861499786377,
            "num_run": 1035,
            "train_loss": 1.2667148588520982,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1035,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.013564541447379527,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004365306043298251,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 0.0006468621655968067,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001536248129561206,
            "feature_preprocessor:select_rates_classification:alpha": 0.09711761490855263,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09621310234069824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1036,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.435352873901452e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005577679766932055,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.0036468408010142525,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001990098321519399,
            "feature_preprocessor:select_rates_classification:alpha": 0.04372501142308567,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10191011428833008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1037,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004426405387374821,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012621344102222714,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 163,
            "classifier:CustomMLPClassifier:tol": 1.0333690770741804e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003159338441677844,
            "feature_preprocessor:select_rates_classification:alpha": 0.29910440113999787,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12356305122375488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1038,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03037311375321334,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007220651335176227,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 0.002365742395442558,
            "feature_preprocessor:select_rates_classification:alpha": 0.26395843644920597,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12384414672851562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1039,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.0754191560772144e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004880670958811174,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.0017243639191778834,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49486517323263923,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2005193627993909,
        "time": 0.3305370807647705,
        "additional_info": {
            "duration": 0.3183631896972656,
            "num_run": 1040,
            "train_loss": 1.1863228822163472,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1040,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.041895089226872864,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2932736774751907,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.005420674644357079,
            "feature_preprocessor:select_rates_classification:alpha": 0.36828540387457875,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09697103500366211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1041,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.606446077496635e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 2.0972260478274677e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.30653229250742753,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09590888023376465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1042,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.8840601546303546e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000660482511856934,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.004838819034301527,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017714802806130823,
            "feature_preprocessor:select_rates_classification:alpha": 0.19383044594281088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09633994102478027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1043,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011237286210440173,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008201789482954701,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.00013949304823055253,
            "feature_preprocessor:select_rates_classification:alpha": 0.45092688060064795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09574508666992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1044,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003809105680518301,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07090447204374196,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 310,
            "classifier:CustomMLPClassifier:tol": 0.00032397703781283205,
            "feature_preprocessor:select_rates_classification:alpha": 0.2887471793579053,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09674191474914551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1045,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003083107337646449,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15945770690389305,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.0059175245907260735,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0043562339595847755,
            "feature_preprocessor:select_rates_classification:alpha": 0.10323701741081003,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12323617935180664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1046,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4708585107450235e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001138506888797259,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 7.131828641462513e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7289151613465162,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15542461652571832,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09555609073489146,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2186356261358702,
        "time": 0.6270818710327148,
        "additional_info": {
            "duration": 0.6032116413116455,
            "num_run": 1047,
            "train_loss": 1.184337184245675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1047,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.694460390606244e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002844161725657959,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.008795193860412559,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007625085072515093,
            "feature_preprocessor:select_rates_classification:alpha": 0.035156242357753296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12872815132141113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1048,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008271364482779081,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06561213246650603,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 8.220691937590586e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011548740276035726,
            "feature_preprocessor:select_rates_classification:alpha": 0.4998576309813993,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12873387336730957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1049,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010044647109072073,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.039202550695889675,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.0002833994899690776,
            "feature_preprocessor:select_rates_classification:alpha": 0.2739731443762935,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09646797180175781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1050,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.044054318706740266,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027477162080383048,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0007230487773396726,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8369170756290237,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2179559174652606,
        "time": 0.553361177444458,
        "additional_info": {
            "duration": 0.538989782333374,
            "num_run": 1051,
            "train_loss": 1.1758500257136726,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1051,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008689756922727637,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012409973083720221,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.0006027129763772159,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0033156353011027213,
            "feature_preprocessor:select_rates_classification:alpha": 0.08967260928558603,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10133767127990723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1052,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009918452331069017,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004591120946197562,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.000803759504343101,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008584757348898215,
            "feature_preprocessor:select_rates_classification:alpha": 0.20714581350196998,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12406086921691895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1053,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.030574189366972107,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015200674656058307,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0002052898933943246,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02917388256118222,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9951968824713832,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2142925703199117,
        "time": 0.524163007736206,
        "additional_info": {
            "duration": 0.5079150199890137,
            "num_run": 1054,
            "train_loss": 1.1647266539089114,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1054,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6166077377161235e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.040252378847862806,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 2.2936026280183344e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.32468357302680395,
            "feature_preprocessor:select_rates_classification:alpha": 0.24103560514792818,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12874579429626465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1055,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.997584769224254e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014877082420264355,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.003024670313701852,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28497451434081017,
            "feature_preprocessor:select_rates_classification:alpha": 0.10051948835557259,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12344813346862793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1056,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.098882794373585e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011096604372173032,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00019572431158804593,
            "feature_preprocessor:select_rates_classification:alpha": 0.1345610040521298,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12339615821838379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1057,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004777265901503911,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013009555014024028,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 0.00550191915430346,
            "feature_preprocessor:select_rates_classification:alpha": 0.2618041274663687,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13105511665344238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1058,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.25737313936539e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005180438574748268,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.0013527381959118443,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018618731085962358,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2936962999459476,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.202639294143884,
        "time": 0.33411097526550293,
        "additional_info": {
            "duration": 0.31345701217651367,
            "num_run": 1059,
            "train_loss": 1.1991364835273453,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1059,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014835427112133665,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002984981613908686,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 4.5475181626199826e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000550170963572913,
            "feature_preprocessor:select_rates_classification:alpha": 0.47307198977348053,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2768712043762207,
        "additional_info": {
            "duration": 0.2633180618286133,
            "num_run": 1060,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1060,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.98301844697291e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003170462916427691,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 0.007183876683355522,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1590009611515279,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9808162672708385,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13145295083538083,
            "feature_preprocessor:select_rates_classification:alpha": 0.025296687222078736,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.214773671715208,
        "time": 0.2488703727722168,
        "additional_info": {
            "duration": 0.23708081245422363,
            "num_run": 1061,
            "train_loss": 1.1631311607540826,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1061,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.849912081632105e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03878160070787362,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 0.0022162534026484684,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30230181861066296,
            "feature_preprocessor:select_percentile_classification:percentile": 51.024907520469334,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2465493984258558,
        "time": 0.35938215255737305,
        "additional_info": {
            "duration": 0.34258365631103516,
            "num_run": 1062,
            "train_loss": 1.0564668240478785,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1062,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1635549990814516e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012450671657615936,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.00012748170769328102,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027015875638100147,
            "feature_preprocessor:select_rates_classification:alpha": 0.17000607624044453,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0976419448852539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1063,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.648974418033378e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18069782470850151,
            "classifier:CustomMLPClassifier:max_iter": 297,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.0006797350968566089,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007340502770861927,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06502759559052518,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.52846973519349,
        "time": 0.45230889320373535,
        "additional_info": {
            "duration": 0.4370276927947998,
            "num_run": 1064,
            "train_loss": 1.5286158020080816,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1064,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.444861395877244e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6063870334819289,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 6.261093605829878e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.25698423007482896,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1017920970916748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1065,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008001497673226351,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010722360475421262,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 9.05560642012445e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1735750053665771,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10127472877502441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1066,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001242379177031536,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001166310901338172,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 1.1183839870477569e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49713020859076357,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10148096084594727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1067,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7583316125201518e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004243889736249239,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 1.8318692418201223e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.37778097256136667,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2653314921340677,
        "time": 0.8286731243133545,
        "additional_info": {
            "duration": 0.8066401481628418,
            "num_run": 1068,
            "train_loss": 1.013414777669137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1068,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.4610291195091436e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47112384992359274,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 357,
            "classifier:CustomMLPClassifier:tol": 1.7079343053158682e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12340465136335772,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10311388969421387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1069,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0052684416218124345,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03180782676244512,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 3.875887438962922e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4124283106959493,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1961995915250228,
        "time": 0.3060779571533203,
        "additional_info": {
            "duration": 0.28626394271850586,
            "num_run": 1070,
            "train_loss": 1.193797267260677,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1070,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1654020403023748e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019216628652881501,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.002384190348110512,
            "feature_preprocessor:select_rates_classification:alpha": 0.09762826908585859,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12362217903137207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1071,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006509547826763439,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14459316950402362,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 1.4629257208692169e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010255932713803578,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1482,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11263526359546883,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.197970742517021,
        "time": 0.8658301830291748,
        "additional_info": {
            "duration": 0.8479762077331543,
            "num_run": 1072,
            "train_loss": 1.1147409048387682,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1072,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.0899290987592415e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006282942313747313,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 9.654070516397606e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2699357515761892,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5764068758610014,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.198657021685831,
        "time": 0.33089303970336914,
        "additional_info": {
            "duration": 0.31856608390808105,
            "num_run": 1073,
            "train_loss": 1.1809527872340795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1073,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0013517119380005963,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018702690502854494,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.008652405090299409,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7668240008348585,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.30774784088134766,
        "additional_info": {
            "duration": 0.2890157699584961,
            "num_run": 1074,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1074,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.016524072636864624,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7662181735741079,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 0.005438011138695359,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14630290751018157,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.22192258125854747,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2622745189649849,
        "time": 0.38609933853149414,
        "additional_info": {
            "duration": 0.3688938617706299,
            "num_run": 1075,
            "train_loss": 1.1563587699952416,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1075,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06412359059593052,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001041983481891813,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.0019476348708417845,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0043491477407397935,
            "feature_preprocessor:select_percentile_classification:percentile": 67.9015340563368,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2203292161448533,
        "time": 0.3517789840698242,
        "additional_info": {
            "duration": 0.3376119136810303,
            "num_run": 1076,
            "train_loss": 1.190054189017777,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1076,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012746980249764383,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002551976970856567,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.0034339845424213155,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8195184796926107,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.013874879223658421,
            "feature_preprocessor:select_rates_classification:alpha": 0.0646150085606695,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2191073145027767,
        "time": 0.2679908275604248,
        "additional_info": {
            "duration": 0.25160717964172363,
            "num_run": 1077,
            "train_loss": 1.1442839974983252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1077,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.282440335181263e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09111210525297625,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 0.0037504540466475338,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0075294410579129015,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9737566288630031,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22214746250715944,
            "feature_preprocessor:select_percentile_classification:percentile": 54.354371079043176,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2414749587843448,
        "time": 0.3829069137573242,
        "additional_info": {
            "duration": 0.37073516845703125,
            "num_run": 1078,
            "train_loss": 1.0410768209423893,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1078,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001417087225696644,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013461962669069285,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 2.082252788010195e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014559518026560935,
            "feature_preprocessor:select_rates_classification:alpha": 0.49352523432333456,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12291526794433594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1079,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001349547299378502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003053054831291111,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 166,
            "classifier:CustomMLPClassifier:tol": 1.875382338921443e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014241401216428021,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7939018274517272,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.4834427833557129,
        "additional_info": {
            "duration": 0.46532416343688965,
            "num_run": 1080,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1080,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010032016890525837,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01499689260352689,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 2.4622384513536512e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4838547176851653,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0963289737701416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1081,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0294955915337174e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8803691206613188,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 3.288867901365202e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.33739472065289905,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0960838794708252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1082,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.047536550018995496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.29789471011266594,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 3.434765923579558e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.38297386603052525,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2357828636303883,
        "time": 0.2506418228149414,
        "additional_info": {
            "duration": 0.23796796798706055,
            "num_run": 1083,
            "train_loss": 1.1469590964178713,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1083,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00016212316562209188,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.050998077140093405,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.00023642584692461956,
            "feature_preprocessor:select_rates_classification:alpha": 0.4877515233644058,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09706902503967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1084,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004085587063459405,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0463674162399167,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 1.5141783556295264e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9215980388438859,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.30839967727661133,
        "additional_info": {
            "duration": 0.29441213607788086,
            "num_run": 1085,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1085,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4674828608439927e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07512970271670567,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.00015856177670521736,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002391999801337095,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8304171728562194,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.39137792587280273,
        "additional_info": {
            "duration": 0.3742551803588867,
            "num_run": 1086,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1086,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09862221971256288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002864400278848776,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.0006171825401177704,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.11861909364133066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1009819507598877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1087,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02757538858437599,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15067640918037417,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.0009652662089212049,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006681659091261942,
            "feature_preprocessor:select_rates_classification:alpha": 0.33329587550678125,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12386894226074219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1088,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.020869056004973498,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09634481762492898,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.0006734500464405774,
            "feature_preprocessor:select_rates_classification:alpha": 0.49709135727860504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12822389602661133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1089,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.560751154512959e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005701074648977233,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0019642661367284147,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09113162684720937,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1313,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.07037659277816506,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2834700705135216,
        "time": 1.348555564880371,
        "additional_info": {
            "duration": 1.3339991569519043,
            "num_run": 1090,
            "train_loss": 1.0547753126948098,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1090,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4691439355143362e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17044445593351804,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 0.00011931212940213081,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7063876753132048,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23805596878261367,
            "feature_preprocessor:select_rates_classification:alpha": 0.3542812674704239,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.221466499294515,
        "time": 0.48345184326171875,
        "additional_info": {
            "duration": 0.46605992317199707,
            "num_run": 1091,
            "train_loss": 1.1724420104208289,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1091,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.891004432216288e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14040806780771364,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 0.0013936124204325182,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0208183327714338,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09948220903504268,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2116687490973006,
        "time": 0.7240521907806396,
        "additional_info": {
            "duration": 0.7027308940887451,
            "num_run": 1092,
            "train_loss": 1.016109236205023,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1092,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002884157017035977,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06926207953178977,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 123,
            "classifier:CustomMLPClassifier:tol": 0.0012107631637240553,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.40280432922971166,
            "feature_preprocessor:select_rates_classification:alpha": 0.4997069893875828,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13067007064819336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1093,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3621022086335215e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003955783502920198,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 0.007174466808356844,
            "feature_preprocessor:select_rates_classification:alpha": 0.17442004501244504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12335205078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1094,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.020154407979951633,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9377458222745875,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 0.0016000958459885725,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03161340286131934,
            "feature_preprocessor:select_percentile_classification:percentile": 26.15663122656044,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2867707669241213,
        "time": 0.27695798873901367,
        "additional_info": {
            "duration": 0.26094484329223633,
            "num_run": 1095,
            "train_loss": 1.2133045815742187,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1095,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.280486422227764e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01157067635387605,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 5.757545339534136e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1007,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9494918002597363,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2358604302681335,
        "time": 0.6301581859588623,
        "additional_info": {
            "duration": 0.6122510433197021,
            "num_run": 1096,
            "train_loss": 1.2060586009727527,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1096,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.839863701642485e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04188836111310976,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 0.0016087260367673463,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1389,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.40100386988356984,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2301013353290562,
        "time": 0.40625,
        "additional_info": {
            "duration": 0.38500404357910156,
            "num_run": 1097,
            "train_loss": 1.1896125222788498,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1097,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0029857434955523985,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019438867610805703,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 2.3169434993622334e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005073213940995567,
            "feature_preprocessor:select_rates_classification:alpha": 0.01111084622283134,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2582207712728095,
        "time": 0.34524989128112793,
        "additional_info": {
            "duration": 0.3334949016571045,
            "num_run": 1098,
            "train_loss": 1.1970343576397877,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1098,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00031123430438244267,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2284262112146816,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 299,
            "classifier:CustomMLPClassifier:tol": 0.0012450104013657939,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1424,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 11.49947248554303,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2333202501226999,
        "time": 0.4760777950286865,
        "additional_info": {
            "duration": 0.4596731662750244,
            "num_run": 1099,
            "train_loss": 1.2278991231830054,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1099,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00024124687643621248,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006725395970713339,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 0.00109500676057064,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8012432689329781,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21681474379985152,
            "feature_preprocessor:select_percentile_classification:percentile": 88.1234088809639,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.217085149432776,
        "time": 2.462122917175293,
        "additional_info": {
            "duration": 2.4502110481262207,
            "num_run": 1100,
            "train_loss": 1.0326100046217719,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.968738266587492e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07694509996928992,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 4.419884905213255e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 6.649204745238972,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.4031398296356201,
        "additional_info": {
            "duration": 0.3815329074859619,
            "num_run": 1101,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1101,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005578149560607118,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1417434860541804,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 5.008435826593391e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 249,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.30577100314262495,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.212658450277748,
        "time": 0.36185598373413086,
        "additional_info": {
            "duration": 0.3469810485839844,
            "num_run": 1102,
            "train_loss": 1.1605562576674722,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.008167231903324378,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004605264911365,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 0.0017052670247331766,
            "feature_preprocessor:select_rates_classification:alpha": 0.2990955575991094,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09700202941894531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4699988598579455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004391316444403644,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 2.458294485635768e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.48849822267473897,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09648680686950684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.199110164776346e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000523582126181904,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 0.0006826910728506721,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006667095294363909,
            "feature_preprocessor:select_rates_classification:alpha": 0.013222909090866285,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0964350700378418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1105,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0387591601871898,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028418061136819835,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.00019173054953600658,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11148343855294342,
            "feature_preprocessor:select_rates_classification:alpha": 0.4177620202205859,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.255369215990002,
        "time": 0.5966999530792236,
        "additional_info": {
            "duration": 0.586035966873169,
            "num_run": 1106,
            "train_loss": 1.3050751428806027,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00029229492330309844,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015079878084621018,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 138,
            "classifier:CustomMLPClassifier:tol": 0.0003332104038370467,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02828719420543675,
            "feature_preprocessor:select_rates_classification:alpha": 0.11116811501574073,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1010129451751709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09872032092610215,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010949737344251023,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 3.0271004083479884e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06845002610707507,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09694170951843262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.3571302717439466e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6476223624345121,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 5.809459968897059e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019214909652065246,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6635913823872819,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.3061838848135343,
        "time": 0.5792388916015625,
        "additional_info": {
            "duration": 0.5589089393615723,
            "num_run": 1109,
            "train_loss": 1.0701459355862744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04168420680886154,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0080539126519848,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 0.0026784894359443328,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06749891849876141,
            "feature_preprocessor:select_rates_classification:alpha": 0.16224842310203536,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2366261389277482,
        "time": 0.5735468864440918,
        "additional_info": {
            "duration": 0.5625042915344238,
            "num_run": 1110,
            "train_loss": 1.0308554070810971,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1110,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.540204035239526e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004781639543309764,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 185,
            "classifier:CustomMLPClassifier:tol": 0.00045170238998817045,
            "feature_preprocessor:select_rates_classification:alpha": 0.4470951811864031,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09555196762084961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1111,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001065032578385631,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07725261335959821,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 2.505504377426764e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.17521118205904304,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12310075759887695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1112,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006989690468501928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4056286509732281,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 0.00022376047946533385,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000598747112155366,
            "feature_preprocessor:select_percentile_classification:percentile": 86.68465493755268,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2408869272464966,
        "time": 1.0562241077423096,
        "additional_info": {
            "duration": 1.0454528331756592,
            "num_run": 1113,
            "train_loss": 1.1366060726580494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1113,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.010685470949841467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004981196311470434,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 141,
            "classifier:CustomMLPClassifier:tol": 0.0004958780766702131,
            "feature_preprocessor:select_rates_classification:alpha": 0.19412600773629435,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09674191474914551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1114,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.216621798298409e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018958427039479204,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.00011540774955410788,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06650058566895393,
            "feature_preprocessor:select_percentile_classification:percentile": 34.753991265532235,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2351691976866905,
        "time": 0.635282039642334,
        "additional_info": {
            "duration": 0.6248579025268555,
            "num_run": 1115,
            "train_loss": 1.174652510384508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1115,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00028111913069677255,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14074159987287257,
            "classifier:CustomMLPClassifier:max_iter": 133,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 3.0224667253183595e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 64.67468614035079,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 1.2859079837799072,
        "additional_info": {
            "duration": 1.2677979469299316,
            "num_run": 1116,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.004748332127048e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.055923992100475724,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.0011919097595532427,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011854224201889503,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8842602354120084,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19291704625456838,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8470242065687668,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2239495638611726,
        "time": 1.2497773170471191,
        "additional_info": {
            "duration": 1.236372947692871,
            "num_run": 1117,
            "train_loss": 1.0985464458124525,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.236855933664684e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014469777521645463,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 470,
            "classifier:CustomMLPClassifier:tol": 1.8118145912726785e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06232829831973406,
            "feature_preprocessor:select_percentile_classification:percentile": 27.42295641527681,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2567389295355402,
        "time": 0.7347729206085205,
        "additional_info": {
            "duration": 0.7226829528808594,
            "num_run": 1118,
            "train_loss": 1.1965690327847687,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.4048615734717624e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001462165138734258,
            "classifier:CustomMLPClassifier:max_iter": 243,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 5.418796370576547e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4304802867330444,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1999379074144736,
        "time": 2.4469268321990967,
        "additional_info": {
            "duration": 2.4268527030944824,
            "num_run": 1119,
            "train_loss": 1.1075805772433265,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.041462999297716546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012741339500889438,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.0001699089719378971,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014515212109190434,
            "feature_preprocessor:select_rates_classification:alpha": 0.13044640968608334,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10098695755004883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1120,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001775069298731973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004863983002360595,
            "classifier:CustomMLPClassifier:max_iter": 375,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 1.549817059387181e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09210476440267806,
            "feature_preprocessor:select_rates_classification:alpha": 0.2830779703047141,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2094390507347967,
        "time": 0.838529109954834,
        "additional_info": {
            "duration": 0.8211803436279297,
            "num_run": 1121,
            "train_loss": 1.1332530712912041,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.3241397939317645e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012789655311090256,
            "classifier:CustomMLPClassifier:max_iter": 339,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.0001441010980414133,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015772781511350885,
            "feature_preprocessor:select_rates_classification:alpha": 0.05650286020533807,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10500097274780273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1122,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0047038475072942645,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03544179711409925,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.0007868452570696831,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018559270217105312,
            "feature_preprocessor:select_rates_classification:alpha": 0.1251035884618155,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09682297706604004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.363844674328869e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004418105582908145,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 0.0003292115593736854,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4583082043151093,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.2709519863128662,
        "additional_info": {
            "duration": 0.25438928604125977,
            "num_run": 1124,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00013750717045851081,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02586627537365786,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.007004132856800015,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00048479757040465285,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5855533009457101,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2124438628686827,
        "time": 0.28630709648132324,
        "additional_info": {
            "duration": 0.27330780029296875,
            "num_run": 1125,
            "train_loss": 1.2055508313932992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0014500552623695395,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031356960032563774,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.006348251920604656,
            "feature_preprocessor:select_rates_classification:alpha": 0.4019536142578752,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12387418746948242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1126,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.387346600249965e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013542928681854658,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 2.0121811742751605e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006784588284140837,
            "feature_preprocessor:select_rates_classification:alpha": 0.20054925492194184,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2347661522022317,
        "time": 0.46150970458984375,
        "additional_info": {
            "duration": 0.44817376136779785,
            "num_run": 1127,
            "train_loss": 1.2248364265134892,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1127,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.6348997163985343e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3120371789729893,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 0.0020867447416041463,
            "feature_preprocessor:select_rates_classification:alpha": 0.486964576585879,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12897491455078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3401355706377184e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 1.0183779972021383e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.3333322702747062,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13965702056884766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1129,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.769469013496225e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01160449962510168,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 0.00028035377042896466,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10015652373088887,
            "feature_preprocessor:select_rates_classification:alpha": 0.3450914258706764,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12323904037475586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1130,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00014606372847013362,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024680205508243694,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 465,
            "classifier:CustomMLPClassifier:tol": 1.4816350801362529e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0714478418256956,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9426632272915828,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19819043856880614,
            "feature_preprocessor:select_percentile_classification:percentile": 60.931740504510344,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2317683941849078,
        "time": 0.7885217666625977,
        "additional_info": {
            "duration": 0.7717981338500977,
            "num_run": 1131,
            "train_loss": 1.018773608071197,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.944266564107287e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0072422035513771965,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.002402377536726492,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4728776656091614,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3133528232574463,
        "additional_info": {
            "duration": 0.29770588874816895,
            "num_run": 1132,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1132,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1892815361230033e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8813452767572123,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.0009934648815232592,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006055929632860403,
            "feature_preprocessor:select_percentile_classification:percentile": 85.62329007668836,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2156465562848666,
        "time": 0.23729681968688965,
        "additional_info": {
            "duration": 0.22121691703796387,
            "num_run": 1133,
            "train_loss": 1.0335396511390809,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.4667405107153765e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00033978246756311974,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.004267617557838684,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009010606783658928,
            "feature_preprocessor:select_percentile_classification:percentile": 8.525458716286295,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2387303325131431,
        "time": 0.2572770118713379,
        "additional_info": {
            "duration": 0.2444758415222168,
            "num_run": 1134,
            "train_loss": 1.2329132491651051,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.740480101198915e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024768857697408508,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 3.105657365994676e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1625618541435054,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9865126823168736,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2336302494182139,
        "time": 0.3652801513671875,
        "additional_info": {
            "duration": 0.3518509864807129,
            "num_run": 1135,
            "train_loss": 1.169230657764736,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.935989227478189e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008650398297655392,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.002027924510966504,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007093809184538892,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1760,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.31406996017401523,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.3607819080352783,
        "additional_info": {
            "duration": 0.3493649959564209,
            "num_run": 1136,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07490896040991978,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00903313398626765,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 5.585098521913724e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.38969973907705285,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12354874610900879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011195062211911562,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4642299306394294,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 8.148390913557985e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030980138606996614,
            "feature_preprocessor:select_rates_classification:alpha": 0.3520624579845338,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12436985969543457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0056691711061667765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000758013415286963,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 2.50729744478484e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.03953516889671962,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.6919631958007812,
        "additional_info": {
            "duration": 0.6813251972198486,
            "num_run": 1139,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.855149766768617e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06714280586333186,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 0.00011313877607378025,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011024033843079926,
            "feature_preprocessor:select_rates_classification:alpha": 0.25426464627184703,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1234748363494873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1140,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3875468392556207e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011961525239847174,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 1.4142898734195266e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4828265828303717,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10110330581665039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0032851897983198,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025030392008706354,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.006510654238998153,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004810246170378298,
            "feature_preprocessor:select_rates_classification:alpha": 0.12308588160470654,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13662385940551758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04494306485702962,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008150192851797867,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 0.0007243425105743814,
            "feature_preprocessor:select_rates_classification:alpha": 0.24229020993931888,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12336206436157227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1143,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.2544079297009596e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012478122064816223,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 359,
            "classifier:CustomMLPClassifier:tol": 0.009391470073500897,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19860642157258152,
            "feature_preprocessor:select_rates_classification:alpha": 0.43133454259625176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12334179878234863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006787188841658355,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020768995941730875,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 0.0044272011504885985,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08354813417129389,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8990402831361248,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.261594319890337,
        "time": 0.5557501316070557,
        "additional_info": {
            "duration": 0.5346701145172119,
            "num_run": 1145,
            "train_loss": 1.1995382543520239,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0075113353991325274,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6990223890569471,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 1.1935158065233826e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4584119300905883,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12821388244628906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00798669241753964,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041696667522270707,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.002802640954686564,
            "feature_preprocessor:select_rates_classification:alpha": 0.3002895382643842,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12340307235717773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4065215939997856e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15185247817409248,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 1.6655012748253695e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005039712528224688,
            "feature_preprocessor:select_rates_classification:alpha": 0.38293889685599225,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12853503227233887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1148,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0013200813713950613,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002242048715261945,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 0.0002655830561840985,
            "feature_preprocessor:select_rates_classification:alpha": 0.4490774919856333,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12827014923095703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014325258839852743,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08370032111541943,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 240,
            "classifier:CustomMLPClassifier:tol": 1.0739289519721797e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23779897832646874,
            "feature_preprocessor:select_rates_classification:alpha": 0.0780992130177616,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10117983818054199,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.290142930668693e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005934865034701842,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 1.9677222030013337e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007014063778421981,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4262862471626736,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.550084114074707,
        "additional_info": {
            "duration": 0.531113862991333,
            "num_run": 1151,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01186864909145552,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.854036128723308,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 0.0007603056921374661,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004247102719276508,
            "feature_preprocessor:select_rates_classification:alpha": 0.425011664195787,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09916186332702637,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1152,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.3024211315222415e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.260299489921169,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 2.972102567088017e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.32144281882920217,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12337708473205566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.034190328926799435,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006594930505096145,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.00023996040969443848,
            "feature_preprocessor:select_percentile_classification:percentile": 24.30148718263651,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.4637758731842041,
        "additional_info": {
            "duration": 0.4413759708404541,
            "num_run": 1154,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01084425596926284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07667558938331258,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.0004521308994094772,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00297744889470475,
            "feature_preprocessor:select_rates_classification:alpha": 0.14331193185811486,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1233820915222168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1155,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0038445357521211167,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004194090636301229,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.00024563103715894715,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7557311801733707,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24471967948110637,
            "feature_preprocessor:select_rates_classification:alpha": 0.030995314413555956,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.25692009925842285,
        "additional_info": {
            "duration": 0.2345271110534668,
            "num_run": 1156,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005383678436317424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11247439834810807,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 1.0538084605093947e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.23287045449401178,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.259732216627647,
        "time": 0.3625309467315674,
        "additional_info": {
            "duration": 0.3486599922180176,
            "num_run": 1157,
            "train_loss": 1.1957324723803582,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1157,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.818737205390951e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4553711073261927,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 0.005058343873875462,
            "feature_preprocessor:select_percentile_classification:percentile": 41.027016887677625,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2248400501739347,
        "time": 0.4400198459625244,
        "additional_info": {
            "duration": 0.42925000190734863,
            "num_run": 1158,
            "train_loss": 1.2045008167831428,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5795300354670877e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004920878175901042,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 0.00502133291867196,
            "feature_preprocessor:select_rates_classification:alpha": 0.07772761095421922,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10027003288269043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.2523187969337834e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04064959005561067,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.004725767543337192,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.41552993419022455,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2928024570745378,
        "time": 0.8064718246459961,
        "additional_info": {
            "duration": 0.789330005645752,
            "num_run": 1160,
            "train_loss": 1.1464382450613837,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1160,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.367185153996799e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12746831651671015,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.0009670966531233766,
            "feature_preprocessor:select_percentile_classification:percentile": 52.86251340980181,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2044581488172144,
        "time": 0.32440876960754395,
        "additional_info": {
            "duration": 0.30801916122436523,
            "num_run": 1161,
            "train_loss": 1.0838988169934385,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3235364299595398e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021146789806685725,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.0006988601897347832,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15280986726272033,
            "feature_preprocessor:select_rates_classification:alpha": 0.46202789635314007,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.227435233884755,
        "time": 0.688054084777832,
        "additional_info": {
            "duration": 0.6740410327911377,
            "num_run": 1162,
            "train_loss": 1.1997382158331635,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001787953049980242,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23691682783500406,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.0011844835581101307,
            "feature_preprocessor:select_rates_classification:alpha": 0.04641658112355056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09681916236877441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008898352692967244,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.39636739222216266,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 0.0013522058770895082,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006670725973367547,
            "feature_preprocessor:select_rates_classification:alpha": 0.02138141284101954,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12600302696228027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.338168430487255e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.237117998613033,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0009576674367356206,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22505184785447727,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9889296385140651,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.33792805671691895,
        "additional_info": {
            "duration": 0.32378697395324707,
            "num_run": 1165,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1165,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006377317928600285,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06776985021396884,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 0.009124177294394126,
            "feature_preprocessor:select_rates_classification:alpha": 0.38454831639543646,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12793684005737305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1166,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0015733335000070337,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00045996358078143756,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 5.382569061704075e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30169816454914056,
            "feature_preprocessor:select_rates_classification:alpha": 0.17359562014970117,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.128007173538208,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.6967001634682846e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001267587021853188,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0031359808003774965,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031272007386800625,
            "feature_preprocessor:select_rates_classification:alpha": 0.49198376174263964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12852692604064941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00011559661326370899,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014841878606964255,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 1.0441571250160348e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017258176227000887,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1923,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 6.328157843328176,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 1.8117918968200684,
        "additional_info": {
            "duration": 1.8012549877166748,
            "num_run": 1169,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00014630969051559074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0688863885817499,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 8.123064064537039e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00195259140310333,
            "feature_preprocessor:select_rates_classification:alpha": 0.30855178049108895,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1225900650024414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001934503281508535,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041225357700681593,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 0.00862851716658873,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08399138890658879,
            "feature_preprocessor:select_rates_classification:alpha": 0.40039107143822583,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12356209754943848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1171,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.744107461931606e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03334891687503585,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 0.00481528586324972,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03921038959552146,
            "feature_preprocessor:select_percentile_classification:percentile": 33.939744218634516,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2434691361913983,
        "time": 0.20378422737121582,
        "additional_info": {
            "duration": 0.1856987476348877,
            "num_run": 1172,
            "train_loss": 1.2040635033445908,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1172,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011729533330984547,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5916052589441395,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 6.170714105599704e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4995863776747877,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10116004943847656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010148987103726357,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02884469779172503,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.006789961839434583,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 454,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 39.35294311755229,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1940131372280944,
        "time": 0.6560750007629395,
        "additional_info": {
            "duration": 0.6360368728637695,
            "num_run": 1174,
            "train_loss": 1.1345844850958258,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005190158933225469,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008823523022362398,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 8.938606486190704e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030911035422265247,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6230409127316507,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2232651532001524,
        "time": 0.3573338985443115,
        "additional_info": {
            "duration": 0.34494471549987793,
            "num_run": 1175,
            "train_loss": 1.1979084776556286,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1175,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.7600905039332696e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017973820959810093,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.0003332031232368375,
            "feature_preprocessor:select_rates_classification:alpha": 0.2547947195697689,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09662103652954102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.9398869185375383e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005404900844478888,
            "classifier:CustomMLPClassifier:max_iter": 419,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 1.5720806434827023e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006704232314702512,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8402159582618981,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2333820722156708,
        "time": 2.7903120517730713,
        "additional_info": {
            "duration": 2.7745048999786377,
            "num_run": 1177,
            "train_loss": 1.1706884800427777,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1177,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004536737107131496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19704391113102643,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.0009070644172645043,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6951071445108319,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.227370333672617,
        "time": 0.46129393577575684,
        "additional_info": {
            "duration": 0.4287681579589844,
            "num_run": 1178,
            "train_loss": 1.1762391598295263,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09813377366942663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023162424812892446,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 1.0003351763343804e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.14322703250965452,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13049793243408203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.003913410613775986,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4220295448836812,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 0.003967596614477453,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009225998251244133,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1487,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 22.02427437917948,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2357492772297485,
        "time": 0.29655885696411133,
        "additional_info": {
            "duration": 0.2807450294494629,
            "num_run": 1180,
            "train_loss": 1.2101915015726559,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1180,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.8539051085305256e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001275986321648873,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 0.00010981578646282612,
            "feature_preprocessor:select_percentile_classification:percentile": 94.33487020397348,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5241751670837402,
        "additional_info": {
            "duration": 0.5127348899841309,
            "num_run": 1181,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.041961146667549444,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2338542821119928,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.00014116168513680154,
            "feature_preprocessor:select_percentile_classification:percentile": 23.232562039825787,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.253302177328452,
        "time": 1.4458589553833008,
        "additional_info": {
            "duration": 1.436046838760376,
            "num_run": 1182,
            "train_loss": 1.1718638985730996,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1182,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.5493631180658534e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 1.0390233271952065e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013238700814219587,
            "feature_preprocessor:select_rates_classification:alpha": 0.299872736693698,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.123046875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1183,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6071788515592589e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11650270174243532,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 163,
            "classifier:CustomMLPClassifier:tol": 2.792909076851839e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.013829491402843508,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2241227768433984,
        "time": 0.4944489002227783,
        "additional_info": {
            "duration": 0.47782397270202637,
            "num_run": 1184,
            "train_loss": 1.0564791821026007,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1184,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02184901973996049,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03347008984546167,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0005845010202270825,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007070057839561922,
            "feature_preprocessor:select_rates_classification:alpha": 0.4238525869907601,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10246491432189941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.054559632869603095,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024298802267219925,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 3.618847867097759e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010251219555590246,
            "feature_preprocessor:select_rates_classification:alpha": 0.2518402715313858,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12356185913085938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011888593255456423,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.32159318450500424,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 288,
            "classifier:CustomMLPClassifier:tol": 0.005244929113810178,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.99369696493083,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2691182399597585,
        "time": 0.3997321128845215,
        "additional_info": {
            "duration": 0.3859429359436035,
            "num_run": 1187,
            "train_loss": 1.2283336105177947,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005482551608450426,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013940079999402276,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 2.0246915137375376e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005105800083483282,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 603,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6962977659289373,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.211107976967492,
        "time": 0.7503421306610107,
        "additional_info": {
            "duration": 0.7313699722290039,
            "num_run": 1188,
            "train_loss": 1.1684703542462258,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018564977197564717,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5024662956735482,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0001550659260725529,
            "feature_preprocessor:select_rates_classification:alpha": 0.20367360612553478,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1234278678894043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1189,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0034468228233475668,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03368688803524699,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 0.0009767183567302225,
            "feature_preprocessor:select_rates_classification:alpha": 0.3835902928765063,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1009378433227539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.984954378664238e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3649563063241984,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 86,
            "classifier:CustomMLPClassifier:tol": 0.0016040763507204308,
            "feature_preprocessor:select_rates_classification:alpha": 0.24457178136411958,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10222697257995605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2899794530194055e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001133368221618905,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 1.1559581242127207e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 44.29090704971189,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.213886670995803,
        "time": 1.4435739517211914,
        "additional_info": {
            "duration": 1.4308528900146484,
            "num_run": 1192,
            "train_loss": 1.180351633650466,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1192,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00040358359250299556,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02502880788897303,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.000393723213665854,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6242355573573863,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.235609169291693,
        "time": 0.3738119602203369,
        "additional_info": {
            "duration": 0.35448503494262695,
            "num_run": 1193,
            "train_loss": 1.1866522311658243,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1193,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002428020453855692,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004209297419597544,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.00894345181793854,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1736398853335778,
            "feature_preprocessor:select_rates_classification:alpha": 0.2819001506347052,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09624028205871582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5202399471000725e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01387217635476699,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.00042540855768109076,
            "feature_preprocessor:select_rates_classification:alpha": 0.3012782734719964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09612011909484863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1195,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.8302709407139594e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.044247596105316485,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.004096461316919511,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034659870606811227,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7203704613424133,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2399547222642419,
            "feature_preprocessor:select_percentile_classification:percentile": 98.91985315617138,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2317681461555237,
        "time": 1.7171778678894043,
        "additional_info": {
            "duration": 1.7056808471679688,
            "num_run": 1196,
            "train_loss": 1.0043336576642963,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1196,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.592252215614933e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19351941613004844,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 0.0002670409062186368,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020707027922423323,
            "feature_preprocessor:select_rates_classification:alpha": 0.30630328798579476,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10145998001098633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1197,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004629632478754882,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012661670989067965,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 3.04505172571931e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 5.281093535547636,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.291866375700995,
        "time": 0.36432409286499023,
        "additional_info": {
            "duration": 0.35375404357910156,
            "num_run": 1198,
            "train_loss": 1.2238883645005667,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007211627311872867,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00495045755895856,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 4.4091674430091996e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011054026807907952,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 988,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5969705122680656,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.224115231191852,
        "time": 4.399792909622192,
        "additional_info": {
            "duration": 4.3847596645355225,
            "num_run": 1199,
            "train_loss": 1.1758186344226036,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1199,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011413285524483675,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0448710182252922,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.0007596758303835303,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08881988529767991,
            "feature_preprocessor:select_percentile_classification:percentile": 26.217418368304266,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2310047907530066,
        "time": 0.6168830394744873,
        "additional_info": {
            "duration": 0.6007709503173828,
            "num_run": 1200,
            "train_loss": 1.2253080519823396,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1200,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.787231248166481e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012779742877271058,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 310,
            "classifier:CustomMLPClassifier:tol": 0.00021801568904845475,
            "feature_preprocessor:select_rates_classification:alpha": 0.306238172707389,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09602904319763184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.034575662177159495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008347796923342334,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 4.282692162571607e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07262981198757931,
            "feature_preprocessor:select_percentile_classification:percentile": 67.57323416193341,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2116687490973006,
        "time": 0.5053451061248779,
        "additional_info": {
            "duration": 0.4929311275482178,
            "num_run": 1202,
            "train_loss": 1.1745065539224309,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.938277223929615e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03718316278984505,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.008687814422419168,
            "feature_preprocessor:select_percentile_classification:percentile": 82.10644097168142,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2115665164213754,
        "time": 1.204481840133667,
        "additional_info": {
            "duration": 1.1888651847839355,
            "num_run": 1203,
            "train_loss": 1.001606734960511,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08836769685722538,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8330015675797979,
            "classifier:CustomMLPClassifier:max_iter": 321,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 0.0024664625397851467,
            "feature_preprocessor:select_percentile_classification:percentile": 11.82406074714677,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2640917463742336,
        "time": 0.2904052734375,
        "additional_info": {
            "duration": 0.27936315536499023,
            "num_run": 1204,
            "train_loss": 1.240112269681336,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1204,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0068491952884442995,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005202900169404242,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.00400131568839832,
            "feature_preprocessor:select_percentile_classification:percentile": 64.85533247119571,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2147988236336418,
        "time": 0.35091423988342285,
        "additional_info": {
            "duration": 0.3386859893798828,
            "num_run": 1205,
            "train_loss": 1.149814224194219,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1205,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0038364547591142593,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005138087548328274,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 2.0985245342853635e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003775543870568209,
            "feature_preprocessor:select_rates_classification:alpha": 0.2528329304609406,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12849783897399902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.668721677160298e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001731117198687139,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 270,
            "classifier:CustomMLPClassifier:tol": 2.3974131669722357e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06273065620471928,
            "feature_preprocessor:select_rates_classification:alpha": 0.0841118817570847,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10100698471069336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012778568911246391,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041985222341395364,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 66,
            "classifier:CustomMLPClassifier:tol": 0.0001456165953150346,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00094775380908148,
            "feature_preprocessor:select_rates_classification:alpha": 0.0690486643216227,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09679007530212402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1208,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2020234302978176e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015249207700331675,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 0.00011899962898288965,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020636147589998917,
            "feature_preprocessor:select_rates_classification:alpha": 0.20109430801175845,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0966179370880127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02734835860222724,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2441212505121027,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 1.6269678328034147e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017194738258130432,
            "feature_preprocessor:select_rates_classification:alpha": 0.2942143907323857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12476325035095215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07946289035449554,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019491583494497377,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0007005000273881685,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9914871119453881,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17226650693301954,
            "feature_preprocessor:select_percentile_classification:percentile": 59.81484760436535,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2170964309689554,
        "time": 1.278475046157837,
        "additional_info": {
            "duration": 1.2663259506225586,
            "num_run": 1211,
            "train_loss": 1.1699174266963706,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1211,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03646289308797463,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010592267990489734,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 0.00048800701644542813,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0052562156312483425,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1066,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 24.32028323363142,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2151675567244453,
        "time": 1.5250580310821533,
        "additional_info": {
            "duration": 1.506662130355835,
            "num_run": 1212,
            "train_loss": 1.1876022610898873,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.917266296416108e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.055406497400846744,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 88,
            "classifier:CustomMLPClassifier:tol": 0.00892052602236132,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032171020528394317,
            "feature_preprocessor:select_percentile_classification:percentile": 95.42002342646867,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3570539951324463,
        "additional_info": {
            "duration": 0.3373098373413086,
            "num_run": 1213,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000648489058148513,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016853184826056522,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 1.6153365780090427e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3621983357223654,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.42696908268714784,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2198756165322504,
        "time": 0.8546979427337646,
        "additional_info": {
            "duration": 0.837982177734375,
            "num_run": 1214,
            "train_loss": 1.1801809404812595,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1214,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.696348372424698e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6148588598390624,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 0.005605449910004108,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025959886573110734,
            "feature_preprocessor:select_percentile_classification:percentile": 69.97120964684073,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.225088961286116,
        "time": 0.3131389617919922,
        "additional_info": {
            "duration": 0.2927107810974121,
            "num_run": 1215,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1215,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.3803837940219198e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019553880600350865,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.0015351755872265744,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00168008898932743,
            "feature_preprocessor:select_rates_classification:alpha": 0.2714388481912036,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1007990837097168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1216,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00025280325135844487,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007901104604316729,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 1.0577596393771774e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22485697361748808,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09650397300720215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1217,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00032897288999041407,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018717658771681166,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 0.001085489503534911,
            "feature_preprocessor:select_rates_classification:alpha": 0.2523296413664148,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12833714485168457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02422237538647994,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017692657901173907,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 228,
            "classifier:CustomMLPClassifier:tol": 1.0194298698486414e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.499426773206205,
            "feature_preprocessor:select_rates_classification:alpha": 0.3779633459317124,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.5333259105682373,
        "additional_info": {
            "duration": 0.5221798419952393,
            "num_run": 1219,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00014580748688509623,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6037791465316327,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.0008174175307933393,
            "feature_preprocessor:select_rates_classification:alpha": 0.23622046639334637,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09719204902648926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1220,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06918512030212459,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8983130803441526,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.00797841026154899,
            "feature_preprocessor:select_rates_classification:alpha": 0.44263067427771724,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09702920913696289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1221,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8493498587001784e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06577044057874562,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 300,
            "classifier:CustomMLPClassifier:tol": 0.0023431920553856323,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.48165621189908964,
            "feature_preprocessor:select_rates_classification:alpha": 0.010440690985741156,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12880516052246094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1222,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.947612683492679e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4884524746132373,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 1.1426661045002507e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.29139493026082314,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12856602668762207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1223,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09837809478521108,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01563567234050602,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.00941844241272371,
            "feature_preprocessor:select_rates_classification:alpha": 0.10670944747045359,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12816596031188965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1224,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07851186793632077,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023311672563298704,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.00020582878604760612,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01092821032510795,
            "feature_preprocessor:select_rates_classification:alpha": 0.43146193338146477,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09651803970336914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1225,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0012083899564171504,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018530136736591976,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.003285364221356806,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13035174709312258,
            "feature_preprocessor:select_rates_classification:alpha": 0.13328143078334212,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10120797157287598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1226,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.753466699920101e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02314990477588992,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 0.002316514742151774,
            "feature_preprocessor:select_rates_classification:alpha": 0.3963370414985123,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2352514697076848,
        "time": 0.44305872917175293,
        "additional_info": {
            "duration": 0.43207621574401855,
            "num_run": 1227,
            "train_loss": 1.1727008848085603,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1227,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004994662420954193,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002652627751334043,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.001235787424950705,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014556186864631509,
            "feature_preprocessor:select_rates_classification:alpha": 0.19179568967030922,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12867283821105957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008926531123252087,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013278423429616402,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.0003755672830992609,
            "feature_preprocessor:select_rates_classification:alpha": 0.475074061669691,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12365484237670898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007528146290190135,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005732372440490159,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 4.688723669744309e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006221506498869126,
            "feature_preprocessor:select_rates_classification:alpha": 0.48918969962057895,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09567785263061523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0032436318582268688,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0025172994174480373,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.004841306524270637,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.411075809277118,
            "feature_preprocessor:select_rates_classification:alpha": 0.04270612959084167,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.32244873046875,
        "additional_info": {
            "duration": 0.3116130828857422,
            "num_run": 1231,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1231,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.3300865470264195e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10912896628609947,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.0022130839818009364,
            "feature_preprocessor:select_rates_classification:alpha": 0.05572860389140148,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12468791007995605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08837432560932403,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02638823620662415,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 3.709615675765481e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024099480623284895,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.992191944836327,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29261824084726745,
            "feature_preprocessor:select_rates_classification:alpha": 0.35924582225950924,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2234498844384811,
        "time": 0.5276648998260498,
        "additional_info": {
            "duration": 0.5116417407989502,
            "num_run": 1233,
            "train_loss": 1.1616635953782393,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1233,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00029459110073963595,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014004080474849462,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 0.0013274331682546576,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 968,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.031043054729180952,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.4746890068054199,
        "additional_info": {
            "duration": 0.464069128036499,
            "num_run": 1234,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1234,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.023445923544491754,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05147852051731027,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.0003691314222397225,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002525968121619586,
            "feature_preprocessor:select_percentile_classification:percentile": 40.05802171264676,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.225088961286116,
        "time": 0.4866619110107422,
        "additional_info": {
            "duration": 0.46779918670654297,
            "num_run": 1235,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0013548463280001878,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017375714513636102,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 0.001352563249730758,
            "feature_preprocessor:select_rates_classification:alpha": 0.02040531842701101,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12388205528259277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1236,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6363130431078955e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005424175028701932,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 412,
            "classifier:CustomMLPClassifier:tol": 0.00026567108593066036,
            "feature_preprocessor:select_rates_classification:alpha": 0.39532222919962934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.208625398281088,
        "time": 2.0401530265808105,
        "additional_info": {
            "duration": 2.0293209552764893,
            "num_run": 1237,
            "train_loss": 1.0673781969825644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006146745103707321,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12421321797196476,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 0.0007791260720292416,
            "feature_preprocessor:select_rates_classification:alpha": 0.4712909986511735,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12292003631591797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.899074494254108e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00358184865572879,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 5.49454169975955e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19225178932212184,
            "feature_preprocessor:select_rates_classification:alpha": 0.39770104859727645,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12976479530334473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1239,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0027155557482804005,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10146793916918845,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 396,
            "classifier:CustomMLPClassifier:tol": 0.00033180795421921465,
            "feature_preprocessor:select_rates_classification:alpha": 0.015490894622865334,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09691023826599121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1240,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0007986514765167723,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03960855440386433,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0006901737822697235,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1870,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 45.803743822051565,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.257261403095784,
        "time": 1.5488929748535156,
        "additional_info": {
            "duration": 1.5369629859924316,
            "num_run": 1241,
            "train_loss": 1.0669973940010513,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00611331339666745,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024536776433388995,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 7.025509289315596e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0056398838283552985,
            "feature_preprocessor:select_rates_classification:alpha": 0.3708297664818568,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09699892997741699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1242,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.232689874586996e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12461747499711993,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 0.0003151211583448308,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022629581989296627,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5840117896651296,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225088961286116,
        "time": 0.39990901947021484,
        "additional_info": {
            "duration": 0.3807098865509033,
            "num_run": 1243,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3874800937973021e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9970774578646483,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 1.8970780017657408e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006623859652180109,
            "feature_preprocessor:select_rates_classification:alpha": 0.3312250598162186,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12851405143737793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006486158006707527,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001008181341884283,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.00016447836898203296,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4502464228615602,
            "feature_preprocessor:select_rates_classification:alpha": 0.3767174813762239,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2289758150720438,
        "time": 1.6401090621948242,
        "additional_info": {
            "duration": 1.6285009384155273,
            "num_run": 1245,
            "train_loss": 1.1710488356476427,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1245,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08121318410346388,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007744849842791773,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 0.0032540973883558874,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011245226062332178,
            "feature_preprocessor:select_rates_classification:alpha": 0.11433278016320056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09629988670349121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014691026118749074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1257609606438253,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 0.003969938810505637,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014748202849226087,
            "feature_preprocessor:select_rates_classification:alpha": 0.42692713281284794,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.225088961286116,
        "time": 0.887786865234375,
        "additional_info": {
            "duration": 0.8704171180725098,
            "num_run": 1247,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1247,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.020869056004973498,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.039714946545694976,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.0006734500464405774,
            "feature_preprocessor:select_rates_classification:alpha": 0.4815256560413736,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12392497062683105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1248,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00014876917092251145,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017005957195724303,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.001211454233716039,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07811501144835396,
            "feature_preprocessor:select_percentile_classification:percentile": 18.788615748568727,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.280452587430244,
        "time": 0.278181791305542,
        "additional_info": {
            "duration": 0.26467037200927734,
            "num_run": 1249,
            "train_loss": 1.2168814706626014,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7002061145324766e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010951090216862601,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 4.936221892392565e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007253371102682746,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6252124258448863,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2381763676014583,
        "time": 0.431140661239624,
        "additional_info": {
            "duration": 0.417172908782959,
            "num_run": 1250,
            "train_loss": 1.1989354697670598,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1250,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.625963730064409e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010082159245930642,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.005074682536204767,
            "feature_preprocessor:select_rates_classification:alpha": 0.09256715087192963,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.28516411781311035,
        "additional_info": {
            "duration": 0.27152395248413086,
            "num_run": 1251,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1251,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011101692782719377,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005707078629234364,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.00010759454971566581,
            "feature_preprocessor:select_rates_classification:alpha": 0.36580506193952966,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10178494453430176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03426121029379022,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06114638036528384,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.000406128467859399,
            "feature_preprocessor:select_rates_classification:alpha": 0.09303722257441294,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0968630313873291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.795735729440417e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005854092682299488,
            "classifier:CustomMLPClassifier:max_iter": 478,
            "classifier:CustomMLPClassifier:num_units": 374,
            "classifier:CustomMLPClassifier:tol": 0.0004584056426580607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0050324584988074685,
            "feature_preprocessor:select_rates_classification:alpha": 0.42890017516182444,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16402292251586914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1254,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0017788870142830477,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15058233409640784,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 392,
            "classifier:CustomMLPClassifier:tol": 3.181841716077095e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.08128718519069576,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12450480461120605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1255,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.030723729238620573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5680914740467224,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 1.292838179462611e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.06374697811399234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2460046154773676,
        "time": 0.38769102096557617,
        "additional_info": {
            "duration": 0.3766047954559326,
            "num_run": 1256,
            "train_loss": 1.1950921295444892,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1256,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.43364373925715e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031243017660284594,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 7.002883534878009e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008195627492101586,
            "feature_preprocessor:select_rates_classification:alpha": 0.15930737191324823,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12405872344970703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01791095031827866,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00028358302899244377,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.0017515140481545158,
            "feature_preprocessor:select_rates_classification:alpha": 0.2400333091855771,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12329816818237305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1258,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01888422145536444,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6889818732798718,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.00011959005880412669,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.036520759240963055,
            "feature_preprocessor:select_rates_classification:alpha": 0.2967633354433072,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12323522567749023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1259,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0007425832002159066,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7696654469042521,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 0.0011565501525414692,
            "feature_preprocessor:select_rates_classification:alpha": 0.34630058906772154,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09771275520324707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.329989291450834e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10620502648971715,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 9.000751878219599e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01199084411673739,
            "feature_preprocessor:select_rates_classification:alpha": 0.1792710711779062,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12479496002197266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1261,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.036958558301778514,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000800754899334527,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.001229483006915512,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007358990250854798,
            "feature_preprocessor:select_rates_classification:alpha": 0.3801982943875092,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13413214683532715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1262,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.051543006642213e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8424971305889695,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.0013155771170348762,
            "feature_preprocessor:select_rates_classification:alpha": 0.2820502662581616,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10191178321838379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1263,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001221269288368257,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017245693118989724,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.0047135772758823925,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14821563696754453,
            "feature_preprocessor:select_rates_classification:alpha": 0.2790063894587988,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.23285913467407227,
        "additional_info": {
            "duration": 0.21498990058898926,
            "num_run": 1264,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1264,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.9745173819685255e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21197186098937346,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 8.982293237885934e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.0955785349028243,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.225088961286116,
        "time": 0.24179697036743164,
        "additional_info": {
            "duration": 0.23097801208496094,
            "num_run": 1265,
            "train_loss": 1.2249428944715242,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1265,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.9180983170789614e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14959182792081266,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 0.004822707261973424,
            "feature_preprocessor:select_rates_classification:alpha": 0.12838539322255588,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12346076965332031,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1266,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000343595025337228,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06625771574409038,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 1.2884022649400404e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00339925028007063,
            "feature_preprocessor:select_rates_classification:alpha": 0.04644483193578162,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12446904182434082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0016641704754836635,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006332047400251149,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 0.0021753714557110125,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00803134964213296,
            "feature_preprocessor:select_rates_classification:alpha": 0.4033748396776551,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09784507751464844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1268,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2635276608049901e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013369228052951326,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 0.00039962287971095185,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017476994769232077,
            "feature_preprocessor:select_percentile_classification:percentile": 60.554669990569714,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.213749651355429,
        "time": 0.5533082485198975,
        "additional_info": {
            "duration": 0.5379900932312012,
            "num_run": 1269,
            "train_loss": 1.1939830968624774,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1269,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08425879830095341,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010093895677344502,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 200,
            "classifier:CustomMLPClassifier:tol": 0.008496833169038839,
            "feature_preprocessor:select_rates_classification:alpha": 0.46778287152157016,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]