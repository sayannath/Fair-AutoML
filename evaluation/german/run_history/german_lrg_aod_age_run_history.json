[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01
        },
        "cost": 1.254353454941569,
        "time": 0.9356029033660889,
        "additional_info": {
            "duration": 0.9269008636474609,
            "num_run": 2,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06943546983792238,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 193,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 318,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2179400636494486,
        "time": 0.31693291664123535,
        "additional_info": {
            "duration": 0.30332112312316895,
            "num_run": 3,
            "train_loss": 1.1654140464407279,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19744241073972732,
            "feature_preprocessor:kitchen_sinks:gamma": 0.008038493427960746,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.1350409984588623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005914257872015065,
            "feature_preprocessor:select_percentile_classification:percentile": 57.378373122989764,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.21669912338256836,
        "additional_info": {
            "duration": 0.2031080722808838,
            "num_run": 5,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2686627988772035,
        "time": 0.37366795539855957,
        "additional_info": {
            "duration": 0.3632619380950928,
            "num_run": 6,
            "train_loss": 1.164093173488045,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002836249135958794,
            "feature_preprocessor:pca:keep_variance": 0.5554331431994848,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2667805279276547,
        "time": 0.1957550048828125,
        "additional_info": {
            "duration": 0.18227910995483398,
            "num_run": 7,
            "train_loss": 1.2044087544891955,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002119388709440359,
            "feature_preprocessor:pca:keep_variance": 0.8778885047995537,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2282389019609836,
        "time": 0.18742775917053223,
        "additional_info": {
            "duration": 0.17173314094543457,
            "num_run": 8,
            "train_loss": 1.2324125277581306,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01885721793297807,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 495.1165435342211,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.02874497201376828
        },
        "cost": 1.251532387527716,
        "time": 0.21518492698669434,
        "additional_info": {
            "duration": 0.20579814910888672,
            "num_run": 9,
            "train_loss": 1.177713406855041,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29499356307409363,
            "feature_preprocessor:kitchen_sinks:gamma": 1.6375323826658983,
            "feature_preprocessor:kitchen_sinks:n_components": 450
        },
        "cost": 0.0,
        "time": 0.1639101505279541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11174888520652537,
            "feature_preprocessor:select_rates_classification:alpha": 0.07352425872611004,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2289630805192235,
        "time": 0.19172191619873047,
        "additional_info": {
            "duration": 0.17757701873779297,
            "num_run": 11,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01967020937722101,
            "feature_preprocessor:kitchen_sinks:gamma": 3.354380609422546e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1645
        },
        "cost": 0.0,
        "time": 0.13175082206726074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0024227120080171556,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00023274564293345338,
            "feature_preprocessor:kitchen_sinks:n_components": 2345
        },
        "cost": 0.0,
        "time": 0.1646881103515625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8005770534164137,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2327646847196704,
            "feature_preprocessor:kitchen_sinks:gamma": 1.488482693200368,
            "feature_preprocessor:kitchen_sinks:n_components": 451
        },
        "cost": 0.0,
        "time": 0.1402292251586914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14990161829089407,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4113621926001692,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2347338865781123,
        "time": 0.2755911350250244,
        "additional_info": {
            "duration": 0.26549291610717773,
            "num_run": 15,
            "train_loss": 1.1658460867262024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 201,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1690,
            "feature_preprocessor:kernel_pca:gamma": 0.00046215230042002443
        },
        "cost": 0.0,
        "time": 0.21191906929016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005214149406070777,
            "feature_preprocessor:pca:keep_variance": 0.5453196529300937,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.18451309204101562,
        "additional_info": {
            "duration": 0.16773223876953125,
            "num_run": 17,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1053,
            "feature_preprocessor:kernel_pca:coef0": 0.19317371361426328,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.13661994763219315
        },
        "cost": 0.0,
        "time": 0.18697810173034668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05351193334055079,
            "feature_preprocessor:select_percentile_classification:percentile": 74.0745869536482,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2488913145076914,
        "time": 0.23581910133361816,
        "additional_info": {
            "duration": 0.2234787940979004,
            "num_run": 19,
            "train_loss": 1.2015793987924974,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 868
        },
        "cost": 0.0,
        "time": 0.16473126411437988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1504
        },
        "cost": 0.0,
        "time": 0.15652775764465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6040768206146383,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2030572124259478,
        "time": 0.2529470920562744,
        "additional_info": {
            "duration": 0.24277400970458984,
            "num_run": 22,
            "train_loss": 1.1800101700589938,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.05909866280626571,
            "feature_preprocessor:kitchen_sinks:n_components": 91
        },
        "cost": 0.0,
        "time": 0.10465192794799805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.46675453290301905,
            "feature_preprocessor:pca:keep_variance": 0.842188017202119,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.1973710060119629,
        "additional_info": {
            "duration": 0.18336009979248047,
            "num_run": 24,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.059041032949524924,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1706,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1958
        },
        "cost": 0.0,
        "time": 0.1352710723876953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1577,
            "feature_preprocessor:kernel_pca:gamma": 0.0022032643258045677
        },
        "cost": 0.0,
        "time": 0.14619064331054688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00042353763356673286,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7414654110374286,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26760471073849196,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 104
        },
        "cost": 0.0,
        "time": 0.10732293128967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003330989269307355,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2587202048841468,
        "time": 1.423804759979248,
        "additional_info": {
            "duration": 1.4088692665100098,
            "num_run": 28,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.22055387496948242,
        "additional_info": {
            "duration": 0.2048189640045166,
            "num_run": 29,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005526680165526196,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 942
        },
        "cost": 1.2289630805192235,
        "time": 0.5458700656890869,
        "additional_info": {
            "duration": 0.5226819515228271,
            "num_run": 30,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.40281838415692,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 452
        },
        "cost": 0.0,
        "time": 0.15584802627563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.27660006226223,
        "time": 0.3119170665740967,
        "additional_info": {
            "duration": 0.30188798904418945,
            "num_run": 32,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017059902596018325,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 4594,
            "feature_preprocessor:nystroem_sampler:gamma": 9.331898886239968e-05
        },
        "cost": 1.2289630805192235,
        "time": 0.6215169429779053,
        "additional_info": {
            "duration": 0.6047530174255371,
            "num_run": 33,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1970,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0009708412475659165,
            "feature_preprocessor:kitchen_sinks:n_components": 595
        },
        "cost": 0.0,
        "time": 0.14153790473937988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029156593137031027,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1475,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1530
        },
        "cost": 0.0,
        "time": 0.16272521018981934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003908424604700762,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2719435143703615,
        "time": 0.2433011531829834,
        "additional_info": {
            "duration": 0.22876596450805664,
            "num_run": 36,
            "train_loss": 1.203101900518366,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1732
        },
        "cost": 0.0,
        "time": 0.24674296379089355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.6308088302612305,
        "additional_info": {
            "duration": 1.6190710067749023,
            "num_run": 38,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.15203001505420766,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.215337047426918,
        "time": 0.24086308479309082,
        "additional_info": {
            "duration": 0.22938990592956543,
            "num_run": 39,
            "train_loss": 1.1903611797897447,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1482509933236025,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 516,
            "feature_preprocessor:kernel_pca:gamma": 5.7653438673930275e-05
        },
        "cost": 0.0,
        "time": 0.20986318588256836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1698,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.33094120025634766,
        "additional_info": {
            "duration": 0.3161289691925049,
            "num_run": 41,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.2898380756378174,
        "additional_info": {
            "duration": 0.2779829502105713,
            "num_run": 42,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013029181510469909
        },
        "cost": 1.2289630805192235,
        "time": 0.1982421875,
        "additional_info": {
            "duration": 0.17817902565002441,
            "num_run": 43,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008566823389003826,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.42642688751220703,
        "additional_info": {
            "duration": 0.4050748348236084,
            "num_run": 44,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005534704313596168,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1236,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8636265573776065,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2622339725494385,
        "additional_info": {
            "duration": 0.252047061920166,
            "num_run": 45,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1999
        },
        "cost": 0.0,
        "time": 0.10483670234680176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 239,
            "feature_preprocessor:kernel_pca:gamma": 6.848415698018119e-05
        },
        "cost": 0.0,
        "time": 0.20334196090698242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2381618400563856,
        "time": 3.858595132827759,
        "additional_info": {
            "duration": 3.844496965408325,
            "num_run": 48,
            "train_loss": 1.1668318199529673,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04786565010411066,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.10480809211730957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010194895067494217,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2388130271209756,
        "time": 0.4727160930633545,
        "additional_info": {
            "duration": 0.4511570930480957,
            "num_run": 50,
            "train_loss": 1.152327452871783,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1702
        },
        "cost": 0.0,
        "time": 0.17835497856140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.802188770000402,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2689787209589913,
            "feature_preprocessor:select_percentile_classification:percentile": 14.417964428316209,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2745875538997633,
        "time": 0.23066377639770508,
        "additional_info": {
            "duration": 0.22157883644104004,
            "num_run": 52,
            "train_loss": 1.2371095118336397,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 379,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 589
        },
        "cost": 1.2289630805192235,
        "time": 0.598768949508667,
        "additional_info": {
            "duration": 0.5883879661560059,
            "num_run": 53,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9043011657681537,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2348382341528334,
        "time": 0.21554994583129883,
        "additional_info": {
            "duration": 0.19838690757751465,
            "num_run": 54,
            "train_loss": 1.1723618765130461,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1573
        },
        "cost": 0.0,
        "time": 0.1314852237701416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2534053024353846,
        "time": 1.1558520793914795,
        "additional_info": {
            "duration": 1.1432440280914307,
            "num_run": 56,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004276041363533823,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1843
        },
        "cost": 0.0,
        "time": 0.10471510887145996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010596130994398902,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7466378011560234,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19242790725903752
        },
        "cost": 1.2444108609485123,
        "time": 0.22261905670166016,
        "additional_info": {
            "duration": 0.20950913429260254,
            "num_run": 58,
            "train_loss": 1.182512592678977,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 946
        },
        "cost": 0.0,
        "time": 0.13402104377746582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034107734471354677,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1863
        },
        "cost": 0.0,
        "time": 0.11238312721252441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1116,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 439
        },
        "cost": 0.0,
        "time": 0.1376190185546875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8029554165846826,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06476100854975805,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5376248602658832,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.21703410148620605,
        "additional_info": {
            "duration": 0.20624899864196777,
            "num_run": 62,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 851,
            "feature_preprocessor:kernel_pca:gamma": 0.00026814152319211713
        },
        "cost": 0.0,
        "time": 0.1808609962463379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.2350339618421574e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 2423
        },
        "cost": 0.0,
        "time": 0.10950803756713867,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1582,
            "feature_preprocessor:kernel_pca:coef0": -0.5772421353766624
        },
        "cost": 0.0,
        "time": 0.3446059226989746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.133272 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.133272 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003002985675289805,
            "feature_preprocessor:kitchen_sinks:gamma": 5.887553546708904,
            "feature_preprocessor:kitchen_sinks:n_components": 949
        },
        "cost": 0.0,
        "time": 0.13089203834533691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05900553282752963,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.9542052975740046,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.001463493831384166
        },
        "cost": 1.240646319049415,
        "time": 0.18865299224853516,
        "additional_info": {
            "duration": 0.1792593002319336,
            "num_run": 67,
            "train_loss": 1.1854580119395601,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004100842211406813,
            "feature_preprocessor:kitchen_sinks:gamma": 0.019981451665965582,
            "feature_preprocessor:kitchen_sinks:n_components": 2916
        },
        "cost": 0.0,
        "time": 0.1054389476776123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 2043,
            "feature_preprocessor:nystroem_sampler:coef0": -0.059708019793880185,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00010248652035981518
        },
        "cost": 1.2289630805192235,
        "time": 0.4284672737121582,
        "additional_info": {
            "duration": 0.41761183738708496,
            "num_run": 69,
            "train_loss": 1.2294690459417643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15821477182826593,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9134299459917081,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07963654601723374,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2407266438894622,
        "time": 4.842189073562622,
        "additional_info": {
            "duration": 4.829588174819946,
            "num_run": 70,
            "train_loss": 1.1752086017213856,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 27
        },
        "cost": 0.0,
        "time": 0.15695977210998535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1579
        },
        "cost": 0.0,
        "time": 0.13307690620422363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 187,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 238,
            "feature_preprocessor:kernel_pca:coef0": 0.17967769545846735,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.0005217121594388293
        },
        "cost": 0.0,
        "time": 0.2525959014892578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0038745323457136764,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.43954135984042086,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.24743294715881348,
        "additional_info": {
            "duration": 0.23692083358764648,
            "num_run": 74,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013932521207494167,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.13289627215531763,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222158175279269,
        "time": 0.22517704963684082,
        "additional_info": {
            "duration": 0.2139878273010254,
            "num_run": 75,
            "train_loss": 1.2227141268496489,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002643970543278544,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0029922358144020447,
            "feature_preprocessor:kitchen_sinks:n_components": 153
        },
        "cost": 0.0,
        "time": 0.1060631275177002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023346457795418038,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.781996485548666,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24314880874038597,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006628995543392695,
            "feature_preprocessor:kitchen_sinks:n_components": 58
        },
        "cost": 0.0,
        "time": 0.13460206985473633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013787958086072851,
            "feature_preprocessor:select_rates_classification:alpha": 0.047200652212663,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2172146403555266,
        "time": 0.15544509887695312,
        "additional_info": {
            "duration": 0.14589691162109375,
            "num_run": 78,
            "train_loss": 1.17726429817585,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21702516888463022,
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 380,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2587202048841468,
        "time": 0.2719402313232422,
        "additional_info": {
            "duration": 0.2494678497314453,
            "num_run": 79,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20866861951854002,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 9,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2289630805192235,
        "time": 0.2612879276275635,
        "additional_info": {
            "duration": 0.25176215171813965,
            "num_run": 80,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 204,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7032833401813936,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 1.9595023804554137
        },
        "cost": 1.2760218769534235,
        "time": 0.2802407741546631,
        "additional_info": {
            "duration": 0.26397013664245605,
            "num_run": 81,
            "train_loss": 1.0366103643137916,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020348127066485217,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 150,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1311
        },
        "cost": 0.0,
        "time": 0.4224889278411865,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010229529814043341,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2985904060021147,
        "time": 0.3401451110839844,
        "additional_info": {
            "duration": 0.3298771381378174,
            "num_run": 83,
            "train_loss": 1.001634389283395,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014079546826538045,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 947
        },
        "cost": 0.0,
        "time": 0.10468387603759766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1993,
            "feature_preprocessor:kernel_pca:coef0": -0.263530221375339,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 0.12869671410624303
        },
        "cost": 0.0,
        "time": 0.12967491149902344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 30
        },
        "cost": 0.0,
        "time": 0.1048128604888916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2656355058485091
        },
        "cost": 1.2339041157094692,
        "time": 0.20846295356750488,
        "additional_info": {
            "duration": 0.19385600090026855,
            "num_run": 87,
            "train_loss": 1.1826291013123174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1049922989877134,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7880765049679609,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15269727421574988,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1738
        },
        "cost": 0.0,
        "time": 0.14134597778320312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 313
        },
        "cost": 0.0,
        "time": 0.1054081916809082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00625335422275476,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1087,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007529497807205167,
            "feature_preprocessor:kitchen_sinks:n_components": 6831
        },
        "cost": 0.0,
        "time": 0.13624000549316406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1049,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 61.10729810867467,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.254353454941569,
        "time": 0.268218994140625,
        "additional_info": {
            "duration": 0.25579094886779785,
            "num_run": 91,
            "train_loss": 1.156792389108712,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.47842253088332826,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.22165727615356445,
        "additional_info": {
            "duration": 0.21199989318847656,
            "num_run": 92,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016645536797862313,
            "feature_preprocessor:kitchen_sinks:gamma": 1.0549680915160868,
            "feature_preprocessor:kitchen_sinks:n_components": 370
        },
        "cost": 0.0,
        "time": 0.13672399520874023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4731281398011056,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1513
        },
        "cost": 0.0,
        "time": 0.1383371353149414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05558393174943574,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1674
        },
        "cost": 0.0,
        "time": 0.13234782218933105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003823951419071609,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 270
        },
        "cost": 0.0,
        "time": 0.16024398803710938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023547320822183034,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 996
        },
        "cost": 0.0,
        "time": 0.10557794570922852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002328292592312588,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 80,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 260
        },
        "cost": 0.0,
        "time": 0.11950206756591797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004919666920923443,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8342831876773112,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21334077526363796,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0025976160934948374,
            "feature_preprocessor:kitchen_sinks:n_components": 3125
        },
        "cost": 0.0,
        "time": 0.11240315437316895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006167560809955496,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7097381071517251,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11584432017316064,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 552,
            "feature_preprocessor:kernel_pca:gamma": 0.001702869033481726
        },
        "cost": 0.0,
        "time": 0.2343919277191162,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.2709310054779053,
        "additional_info": {
            "duration": 0.20310497283935547,
            "num_run": 101,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1731,
            "feature_preprocessor:kernel_pca:coef0": 0.5632179883384048,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.00876798645262368
        },
        "cost": 0.0,
        "time": 0.2874279022216797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.4500401020050049,
        "additional_info": {
            "duration": 0.4333987236022949,
            "num_run": 103,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1183
        },
        "cost": 0.0,
        "time": 0.3247041702270508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.012810368463464982,
            "feature_preprocessor:kitchen_sinks:n_components": 2786
        },
        "cost": 0.0,
        "time": 0.13205575942993164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00041611851408469787,
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 233,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2587202048841468,
        "time": 0.30253124237060547,
        "additional_info": {
            "duration": 0.27121615409851074,
            "num_run": 106,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005279867485217947,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1209,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 729,
            "feature_preprocessor:kernel_pca:coef0": -0.8832019706791792
        },
        "cost": 0.0,
        "time": 0.1933438777923584,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.703667999201995,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1053199393073545,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1533
        },
        "cost": 0.0,
        "time": 0.10736703872680664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006341597252598048,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8469387878011698,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16932050724752348,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1860
        },
        "cost": 0.0,
        "time": 0.1680150032043457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7571515564753813,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0963467815903661
        },
        "cost": 1.2305087630479485,
        "time": 0.22063517570495605,
        "additional_info": {
            "duration": 0.1957399845123291,
            "num_run": 110,
            "train_loss": 1.2307781384747358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026398282635809036,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1936,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 928
        },
        "cost": 0.0,
        "time": 0.17403197288513184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001489386004603056,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 549
        },
        "cost": 0.0,
        "time": 0.15533709526062012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9015864027292486,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13311042492786487,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2263103073157824,
        "time": 0.5218818187713623,
        "additional_info": {
            "duration": 0.5098581314086914,
            "num_run": 113,
            "train_loss": 1.211382082845153,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.2222309112548828,
        "additional_info": {
            "duration": 0.20784306526184082,
            "num_run": 114,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003940458088741297,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1801,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 92.72993767330075,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2303624586145945,
        "time": 0.29927802085876465,
        "additional_info": {
            "duration": 0.2875189781188965,
            "num_run": 115,
            "train_loss": 1.1609488090858735,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.005427265078515953,
            "feature_preprocessor:kitchen_sinks:n_components": 54
        },
        "cost": 0.0,
        "time": 0.1318528652191162,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016436406231501376,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1348,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2925,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0009289651990721914
        },
        "cost": 1.2289630805192235,
        "time": 0.6178140640258789,
        "additional_info": {
            "duration": 0.5944602489471436,
            "num_run": 117,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26554125864020994,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 87
        },
        "cost": 0.0,
        "time": 0.1106119155883789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01739335803480105,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8432564347881201,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.007059965046601103,
            "feature_preprocessor:pca:keep_variance": 0.904474197124946,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2282389019609836,
        "time": 0.26396799087524414,
        "additional_info": {
            "duration": 0.24951887130737305,
            "num_run": 119,
            "train_loss": 1.2324125277581306,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0352247431345662,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.6286370754241943,
        "additional_info": {
            "duration": 1.60736083984375,
            "num_run": 120,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002888947763153471,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9604929398363586,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07317826814622236,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 380
        },
        "cost": 0.0,
        "time": 0.10711789131164551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 10
        },
        "cost": 0.0,
        "time": 0.13428664207458496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1213,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2388730736955273,
        "time": 1.948904275894165,
        "additional_info": {
            "duration": 1.9382679462432861,
            "num_run": 123,
            "train_loss": 1.1720365797626227,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.23806524276733398,
        "additional_info": {
            "duration": 0.2131948471069336,
            "num_run": 124,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1717,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 821,
            "feature_preprocessor:kernel_pca:coef0": 0.8196683023354734
        },
        "cost": 0.0,
        "time": 0.25470972061157227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.287434 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.287434 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 16.764373472214654,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2289630805192235,
        "time": 0.18193483352661133,
        "additional_info": {
            "duration": 0.17232513427734375,
            "num_run": 126,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 303
        },
        "cost": 0.0,
        "time": 0.2525818347930908,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.5764389038085938,
        "additional_info": {
            "duration": 0.5116291046142578,
            "num_run": 128,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9749004841385315,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12274252769375246,
            "feature_preprocessor:kitchen_sinks:gamma": 0.001536003078807389,
            "feature_preprocessor:kitchen_sinks:n_components": 525
        },
        "cost": 0.0,
        "time": 0.1077580451965332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 850
        },
        "cost": 0.0,
        "time": 0.16228699684143066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 298,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2289630805192235,
        "time": 0.3020031452178955,
        "additional_info": {
            "duration": 0.2887301445007324,
            "num_run": 131,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 79
        },
        "cost": 0.0,
        "time": 0.13678312301635742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016716989176308804,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1712,
            "feature_preprocessor:kernel_pca:gamma": 1.7963625630284887
        },
        "cost": 0.0,
        "time": 0.24785327911376953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00036775248444294496,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9793801003224204,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10410206394011377,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 391,
            "feature_preprocessor:kernel_pca:coef0": 0.5323992427209783,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.6693008731294613
        },
        "cost": 0.0,
        "time": 0.35753297805786133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1030,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 38.0642307405815,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.2867751121520996,
        "additional_info": {
            "duration": 0.2772500514984131,
            "num_run": 135,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.238389247289588,
        "time": 0.9362790584564209,
        "additional_info": {
            "duration": 0.9228322505950928,
            "num_run": 136,
            "train_loss": 1.1795659042843525,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 389
        },
        "cost": 0.0,
        "time": 0.13238096237182617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 5129
        },
        "cost": 1.2347338865781123,
        "time": 0.5282289981842041,
        "additional_info": {
            "duration": 0.5159280300140381,
            "num_run": 138,
            "train_loss": 1.1585274877657725,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010609494722432037,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7314488527064441,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18144870254330048,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.250323293419815,
        "time": 1.3878190517425537,
        "additional_info": {
            "duration": 1.3749208450317383,
            "num_run": 139,
            "train_loss": 1.1772801753127302,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 28,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2720907523554768,
        "time": 0.2799098491668701,
        "additional_info": {
            "duration": 0.2647089958190918,
            "num_run": 140,
            "train_loss": 1.190133974855714,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00038717236688282043,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 365.5797392062304,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0016121110609761157
        },
        "cost": 1.2289630805192235,
        "time": 0.1895310878753662,
        "additional_info": {
            "duration": 0.17930006980895996,
            "num_run": 141,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 4468,
            "feature_preprocessor:nystroem_sampler:coef0": -0.2501966094986343,
            "feature_preprocessor:nystroem_sampler:gamma": 0.01504947987212942
        },
        "cost": 1.2289630805192235,
        "time": 0.6478900909423828,
        "additional_info": {
            "duration": 0.6208398342132568,
            "num_run": 142,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2381618400563856,
        "time": 0.2292637825012207,
        "additional_info": {
            "duration": 0.21017885208129883,
            "num_run": 143,
            "train_loss": 1.1668318199529673,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8327090590254159,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2300281524658203,
        "additional_info": {
            "duration": 0.21925091743469238,
            "num_run": 144,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7159071962182112,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25131659269245743,
            "feature_preprocessor:kitchen_sinks:gamma": 0.573449496446256,
            "feature_preprocessor:kitchen_sinks:n_components": 723
        },
        "cost": 0.0,
        "time": 0.10815119743347168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1125
        },
        "cost": 0.0,
        "time": 0.1372978687286377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 59.65846695427048,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2413575526885567,
        "time": 0.211686372756958,
        "additional_info": {
            "duration": 0.20073604583740234,
            "num_run": 147,
            "train_loss": 1.1748844962277984,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006661861039817292,
            "feature_preprocessor:select_percentile_classification:percentile": 52.64180636209477,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2289630805192235,
        "time": 0.21253085136413574,
        "additional_info": {
            "duration": 0.1916048526763916,
            "num_run": 148,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005490345488604715,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1999,
            "feature_preprocessor:kernel_pca:coef0": 0.5089177626742676,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 2.1645452325796914
        },
        "cost": 0.0,
        "time": 0.3021352291107178,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1585,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.0857521353949518,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2439298454599903,
        "time": 0.18840312957763672,
        "additional_info": {
            "duration": 0.17856574058532715,
            "num_run": 150,
            "train_loss": 1.2030963114264357,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004347310633329719,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7335193054181852,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03605709226860861
        },
        "cost": 1.222158175279269,
        "time": 0.22513198852539062,
        "additional_info": {
            "duration": 0.21086907386779785,
            "num_run": 151,
            "train_loss": 1.2226061920577616,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 37.33311214344115,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0004071858560782216
        },
        "cost": 1.2488203457095242,
        "time": 0.17375421524047852,
        "additional_info": {
            "duration": 0.16369009017944336,
            "num_run": 152,
            "train_loss": 1.1700833729596456,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003227298210725791,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 860,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.6611668330716245,
            "feature_preprocessor:kitchen_sinks:n_components": 1928
        },
        "cost": 0.0,
        "time": 0.14275693893432617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034421296432703634,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1832,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.005138457910293178,
            "feature_preprocessor:kitchen_sinks:n_components": 153
        },
        "cost": 0.0,
        "time": 0.16749310493469238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.7803194973646932,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.230106195033818,
        "time": 0.2567570209503174,
        "additional_info": {
            "duration": 0.2430741786956787,
            "num_run": 155,
            "train_loss": 1.1850220188884464,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14677147695413426,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 276,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.2425285899989635,
        "time": 0.24626708030700684,
        "additional_info": {
            "duration": 0.23320698738098145,
            "num_run": 156,
            "train_loss": 1.1762891541119604,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014415776812428945,
            "feature_preprocessor:pca:keep_variance": 0.9196139217858808,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.24858617782592773,
        "additional_info": {
            "duration": 0.237562894821167,
            "num_run": 157,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002960110730089606,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3353508256810487,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2642960489346255,
        "time": 0.2534058094024658,
        "additional_info": {
            "duration": 0.24126315116882324,
            "num_run": 158,
            "train_loss": 1.1797810276807468,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014886203273993502,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1709
        },
        "cost": 0.0,
        "time": 0.10445499420166016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001494446678433974,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6361025689689994,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.23023104667663574,
        "additional_info": {
            "duration": 0.21862292289733887,
            "num_run": 160,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7038297422570388,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27756153818221757,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 100
        },
        "cost": 0.0,
        "time": 0.13741397857666016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00020050222531633452,
            "feature_preprocessor:kitchen_sinks:n_components": 694
        },
        "cost": 0.0,
        "time": 0.1101231575012207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 574,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.08473929684179558,
            "feature_preprocessor:kitchen_sinks:n_components": 3472
        },
        "cost": 0.0,
        "time": 0.13579797744750977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007134593980179106,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7814437937914764,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15798626587428807,
            "feature_preprocessor:select_rates_classification:alpha": 0.17276350805200888,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2289630805192235,
        "time": 0.21213173866271973,
        "additional_info": {
            "duration": 0.19559216499328613,
            "num_run": 164,
            "train_loss": 1.2307781384747358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014791790043107412
        },
        "cost": 1.2484410224702662,
        "time": 0.22042536735534668,
        "additional_info": {
            "duration": 0.2069098949432373,
            "num_run": 165,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8227275234826351,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20400845577219603,
            "feature_preprocessor:kitchen_sinks:gamma": 0.35020695189946766,
            "feature_preprocessor:kitchen_sinks:n_components": 8301
        },
        "cost": 0.0,
        "time": 0.11338996887207031,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015344622845722225,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1260
        },
        "cost": 0.0,
        "time": 0.151932954788208,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07076591564768386,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2139099021276947,
        "time": 0.3042922019958496,
        "additional_info": {
            "duration": 0.2935009002685547,
            "num_run": 168,
            "train_loss": 1.189678530897212,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 5680,
            "feature_preprocessor:nystroem_sampler:coef0": -0.6915067633582626,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0015308307078875543
        },
        "cost": 1.2289630805192235,
        "time": 0.5709609985351562,
        "additional_info": {
            "duration": 0.5555031299591064,
            "num_run": 169,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1954
        },
        "cost": 0.0,
        "time": 0.13804888725280762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 748,
            "feature_preprocessor:kernel_pca:gamma": 0.0012365144925194104
        },
        "cost": 0.0,
        "time": 0.19330620765686035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011215097553284418,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1260
        },
        "cost": 0.0,
        "time": 0.1052560806274414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1993
        },
        "cost": 0.0,
        "time": 0.10547828674316406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002926804021101788,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.737483978271484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.23797384667898897,
            "feature_preprocessor:kitchen_sinks:n_components": 1094
        },
        "cost": 0.0,
        "time": 0.11095285415649414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012827678357062002,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 500,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.22013478227948044,
            "feature_preprocessor:kitchen_sinks:n_components": 290
        },
        "cost": 0.0,
        "time": 0.16176700592041016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.051796437375469274,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1424
        },
        "cost": 0.0,
        "time": 0.16311883926391602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9883089298860548,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18077347020473444,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 982
        },
        "cost": 0.0,
        "time": 0.10799980163574219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9198575015288601,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23731039457590433,
            "feature_preprocessor:kitchen_sinks:gamma": 0.5622420024116079,
            "feature_preprocessor:kitchen_sinks:n_components": 4314
        },
        "cost": 0.0,
        "time": 0.10889554023742676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1086,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1715
        },
        "cost": 0.0,
        "time": 0.2692720890045166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 398,
            "feature_preprocessor:nystroem_sampler:coef0": -0.32051385710987224,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0017133703365459522
        },
        "cost": 1.2289630805192235,
        "time": 0.4934549331665039,
        "additional_info": {
            "duration": 0.48265695571899414,
            "num_run": 181,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016862187724914338,
            "feature_preprocessor:kitchen_sinks:gamma": 7.011655424608458e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 948
        },
        "cost": 0.0,
        "time": 0.10507798194885254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.65164589881897,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43658540874880397,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1399,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 124
        },
        "cost": 1.2289630805192235,
        "time": 0.2520279884338379,
        "additional_info": {
            "duration": 0.23935198783874512,
            "num_run": 184,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.21265888214111328,
        "additional_info": {
            "duration": 0.1976158618927002,
            "num_run": 185,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 113,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 248.8039043228252,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0008461575698925951
        },
        "cost": 1.2289630805192235,
        "time": 0.23061609268188477,
        "additional_info": {
            "duration": 0.22082090377807617,
            "num_run": 186,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.352400779724121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003085916422159552,
            "feature_preprocessor:select_percentile_classification:percentile": 19.76820242565834,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2657063492536116,
        "time": 0.22308826446533203,
        "additional_info": {
            "duration": 0.21360993385314941,
            "num_run": 188,
            "train_loss": 1.2424491178043933,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2357863866590177,
        "time": 6.823267936706543,
        "additional_info": {
            "duration": 6.80100679397583,
            "num_run": 189,
            "train_loss": 1.1922055484470586,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.245956543477237,
        "time": 0.26328015327453613,
        "additional_info": {
            "duration": 0.2513008117675781,
            "num_run": 190,
            "train_loss": 1.0604756100638675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023269904624513713,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 336,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2289630805192235,
        "time": 0.2828841209411621,
        "additional_info": {
            "duration": 0.26470303535461426,
            "num_run": 191,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1078677795926487,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 802
        },
        "cost": 0.0,
        "time": 0.1326580047607422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020419377403623753
        },
        "cost": 1.2289630805192235,
        "time": 0.22164392471313477,
        "additional_info": {
            "duration": 0.20273494720458984,
            "num_run": 193,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.27660006226223,
        "time": 0.38193678855895996,
        "additional_info": {
            "duration": 0.36872100830078125,
            "num_run": 194,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017633097757269924,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5375654933929597,
        "time": 1.5565886497497559,
        "additional_info": {
            "duration": 1.5428359508514404,
            "num_run": 195,
            "train_loss": 1.5377140742369049,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007701807132204263,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00015275393768251274,
            "feature_preprocessor:kitchen_sinks:n_components": 2444
        },
        "cost": 0.0,
        "time": 0.1079857349395752,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03196815946982492,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 701,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 320,
            "feature_preprocessor:kernel_pca:gamma": 0.1599777808824875
        },
        "cost": 0.0,
        "time": 0.33283495903015137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.22574877738952637,
        "additional_info": {
            "duration": 0.20081305503845215,
            "num_run": 198,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01498182446373966,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5375654933929597,
        "time": 1.5150408744812012,
        "additional_info": {
            "duration": 1.5013408660888672,
            "num_run": 199,
            "train_loss": 1.5377140742369049,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1004,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2538649505146897,
        "time": 1.0375239849090576,
        "additional_info": {
            "duration": 1.0242810249328613,
            "num_run": 200,
            "train_loss": 1.1841437753841135,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 802
        },
        "cost": 0.0,
        "time": 0.10639381408691406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018479688369605556,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.897165060043335,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006334579984084958
        },
        "cost": 1.226773544272306,
        "time": 0.2468123435974121,
        "additional_info": {
            "duration": 0.23050618171691895,
            "num_run": 203,
            "train_loss": 1.222822807828917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017083120052292949,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1331,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 696,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7608368167237645,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.8620526894493742
        },
        "cost": 1.2404282678580927,
        "time": 0.4713881015777588,
        "additional_info": {
            "duration": 0.4569430351257324,
            "num_run": 204,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1330
        },
        "cost": 0.0,
        "time": 0.10483479499816895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.1868658065795898,
        "additional_info": {
            "duration": 1.1651997566223145,
            "num_run": 206,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010404425982625947,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 635,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 51.75134336454854,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2329606412242249,
        "time": 0.2839038372039795,
        "additional_info": {
            "duration": 0.27143001556396484,
            "num_run": 207,
            "train_loss": 1.1786998862691864,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004717445592633187,
            "feature_preprocessor:kitchen_sinks:gamma": 0.12369622028642525,
            "feature_preprocessor:kitchen_sinks:n_components": 860
        },
        "cost": 0.0,
        "time": 0.1099083423614502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.2918660640716553,
        "additional_info": {
            "duration": 1.279695749282837,
            "num_run": 209,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1147,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 1327,
            "feature_preprocessor:nystroem_sampler:gamma": 0.02283772852125071
        },
        "cost": 1.236863376250478,
        "time": 0.8730738162994385,
        "additional_info": {
            "duration": 0.8572869300842285,
            "num_run": 210,
            "train_loss": 1.0032687785667898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006191062618367941,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8941223455459552,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13997757561635615,
            "feature_preprocessor:kitchen_sinks:gamma": 0.029273293383723614,
            "feature_preprocessor:kitchen_sinks:n_components": 401
        },
        "cost": 0.0,
        "time": 0.10755419731140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006529635924271086,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.876101732254028,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2339041157094692,
        "time": 3.912039041519165,
        "additional_info": {
            "duration": 3.897505760192871,
            "num_run": 213,
            "train_loss": 1.182412485541162,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035029727725904757,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.100290060043335,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 156,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2289630805192235,
        "time": 0.29552674293518066,
        "additional_info": {
            "duration": 0.28266215324401855,
            "num_run": 215,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13168889429643799,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 218,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2558991374702937,
        "time": 0.3009951114654541,
        "additional_info": {
            "duration": 0.2775890827178955,
            "num_run": 216,
            "train_loss": 1.1708571893682744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023582039141485458,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8017528156291314,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24815917365129994,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2528077724128441,
        "time": 5.2608020305633545,
        "additional_info": {
            "duration": 5.246692180633545,
            "num_run": 217,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00043293687287555697,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1624,
            "feature_preprocessor:kernel_pca:coef0": -0.49681396349387263
        },
        "cost": 0.0,
        "time": 0.15432095527648926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01502019233133408,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.24281907081604,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028848340801698322,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.641418933868408,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.8524248600006104,
        "additional_info": {
            "duration": 0.8365542888641357,
            "num_run": 221,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1155
        },
        "cost": 0.0,
        "time": 0.32317399978637695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.5495898723602295,
        "additional_info": {
            "duration": 0.5366637706756592,
            "num_run": 223,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024672372425308484,
            "feature_preprocessor:kitchen_sinks:gamma": 0.3720878339447823,
            "feature_preprocessor:kitchen_sinks:n_components": 1431
        },
        "cost": 0.0,
        "time": 0.13706612586975098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18441809220950695,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.008548736572266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002785573289934478,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9260384477969488,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1475678783091951,
            "feature_preprocessor:select_percentile_classification:percentile": 13.789352762727319,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.242725273781069,
        "time": 0.15609502792358398,
        "additional_info": {
            "duration": 0.14634299278259277,
            "num_run": 226,
            "train_loss": 1.2280537328204024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0068209223785478945,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.555256128311157,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1632,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 36.541863204131296,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.02121431086053525
        },
        "cost": 1.2348382341528334,
        "time": 0.2275691032409668,
        "additional_info": {
            "duration": 0.21806120872497559,
            "num_run": 228,
            "train_loss": 1.1871831104547308,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010985649403834927,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.681158065795898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02469553284604715,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.573170900344849,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1073
        },
        "cost": 0.0,
        "time": 0.21405601501464844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038376789308328794,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2323584331807442,
        "time": 6.662585020065308,
        "additional_info": {
            "duration": 6.648846864700317,
            "num_run": 232,
            "train_loss": 1.1882881138236387,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023162281927484934,
            "feature_preprocessor:pca:keep_variance": 0.6369638320527833,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.20626378059387207,
        "additional_info": {
            "duration": 0.1951920986175537,
            "num_run": 233,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011268275581470642,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.306824207305908,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02765428199458404,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.1777873039245605,
        "additional_info": {
            "duration": 1.1624820232391357,
            "num_run": 235,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2658414707779885,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2343706303592905,
        "time": 0.5075387954711914,
        "additional_info": {
            "duration": 0.49332189559936523,
            "num_run": 236,
            "train_loss": 1.1510183603388118,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0038187456033422513,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2193324298444759,
        "time": 3.959578275680542,
        "additional_info": {
            "duration": 3.9479031562805176,
            "num_run": 237,
            "train_loss": 1.2380722864568328,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016822166993657812,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.131731033325195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012578180278869637,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.254436016082764,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005557174955262238,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8308159907661603,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18804031427627219,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 247,
            "feature_preprocessor:kernel_pca:coef0": -0.49801051072841296,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.00040028799502737813
        },
        "cost": 0.0,
        "time": 0.20897698402404785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010683356673668537,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.4724462032318115,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012701919856445606,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.20524215698242188,
        "additional_info": {
            "duration": 0.18735218048095703,
            "num_run": 242,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018409381726982723,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.156674861907959,
        "additional_info": {
            "duration": 1.1399023532867432,
            "num_run": 243,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 710
        },
        "cost": 0.0,
        "time": 0.13333606719970703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0033218275735863913,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.52724814414978,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.076581001281738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01126534105224704,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.383729934692383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2587202048841468,
        "time": 0.1919858455657959,
        "additional_info": {
            "duration": 0.17670178413391113,
            "num_run": 248,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043737757123230435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1274,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 667,
            "feature_preprocessor:kernel_pca:coef0": -0.3570951370876547
        },
        "cost": 0.0,
        "time": 0.29274487495422363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.226403 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.226403 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8841087146463139,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.041855193928845645
        },
        "cost": 1.2289630805192235,
        "time": 0.22507095336914062,
        "additional_info": {
            "duration": 0.21394610404968262,
            "num_run": 250,
            "train_loss": 1.2294690459417643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025580323125282,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9616564030014886,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13348620234800454,
            "feature_preprocessor:pca:keep_variance": 0.986424235390271,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.23346877098083496,
        "additional_info": {
            "duration": 0.2185051441192627,
            "num_run": 251,
            "train_loss": 1.2294690459417643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004653726692791327,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7520091632674009,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.050086724726482026,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2407266438894622,
        "time": 1.4165198802947998,
        "additional_info": {
            "duration": 1.4008848667144775,
            "num_run": 252,
            "train_loss": 1.1752086017213856,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006374289868203358,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.80208683013916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006765280137909245,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.7079758644104,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.041316466405783556,
            "feature_preprocessor:pca:keep_variance": 0.9335762303005832,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2478434924477257,
        "time": 0.21483373641967773,
        "additional_info": {
            "duration": 0.20176911354064941,
            "num_run": 255,
            "train_loss": 1.1942778682257837,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.05370487552424486,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.242725273781069,
        "time": 0.18056011199951172,
        "additional_info": {
            "duration": 0.1708228588104248,
            "num_run": 256,
            "train_loss": 1.2280537328204024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02311369625644905,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.412214994430542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02866325752242646,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.376185655593872,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03351500515752993,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9467781028530968,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09767920953399611,
            "feature_preprocessor:select_percentile_classification:percentile": 11.304748714446257,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.242725273781069,
        "time": 0.15713000297546387,
        "additional_info": {
            "duration": 0.14745712280273438,
            "num_run": 259,
            "train_loss": 1.2280537328204024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1156
        },
        "cost": 1.2289630805192235,
        "time": 0.46193623542785645,
        "additional_info": {
            "duration": 0.4486560821533203,
            "num_run": 260,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018558454713670108
        },
        "cost": 1.2484410224702662,
        "time": 0.2370738983154297,
        "additional_info": {
            "duration": 0.2258448600769043,
            "num_run": 261,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20358334392577923,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2614367691313184,
        "time": 2.7375030517578125,
        "additional_info": {
            "duration": 2.7206459045410156,
            "num_run": 262,
            "train_loss": 1.1719405693419767,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.054489131269390506,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.703406810760498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01625363174092671,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2339041157094692,
        "time": 4.890552282333374,
        "additional_info": {
            "duration": 4.877629041671753,
            "num_run": 264,
            "train_loss": 1.182412485541162,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26046830377793195,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 67,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.29679090211957165,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2362795691068371,
        "time": 0.2704319953918457,
        "additional_info": {
            "duration": 0.25729990005493164,
            "num_run": 265,
            "train_loss": 1.1642116974428076,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009682699903961004,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.173655033111572,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0066787889085210324,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.098615646362305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.339371204376221,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020306407667687466,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2524711839920202,
        "time": 6.7543909549713135,
        "additional_info": {
            "duration": 6.741798162460327,
            "num_run": 269,
            "train_loss": 1.1903557346493443,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.10992693901062,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004959304987981034,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.0811851024627686,
        "additional_info": {
            "duration": 1.0601260662078857,
            "num_run": 271,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012710389242321983,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.024861097335815,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0962961052842626,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 37,
            "feature_preprocessor:kernel_pca:gamma": 0.00022183280640795903
        },
        "cost": 0.0,
        "time": 0.18146324157714844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.35945089654332607,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.22225093841552734,
        "additional_info": {
            "duration": 0.2119128704071045,
            "num_run": 274,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009670609042939993,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.06211519241333,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03970834537935086,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.318857192993164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030967854958574388,
            "feature_preprocessor:select_percentile_classification:percentile": 31.43687142840286,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.1948091983795166,
        "additional_info": {
            "duration": 0.18549513816833496,
            "num_run": 277,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011357880777385728,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 673
        },
        "cost": 0.0,
        "time": 0.11134886741638184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014323298754419372,
            "feature_preprocessor:kitchen_sinks:gamma": 0.05342427795057593,
            "feature_preprocessor:kitchen_sinks:n_components": 55
        },
        "cost": 0.0,
        "time": 0.13225889205932617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002572755117636705,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 218
        },
        "cost": 0.0,
        "time": 0.10559511184692383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.136481046676636,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016725839299927225,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.0617330074310303,
        "additional_info": {
            "duration": 1.0485608577728271,
            "num_run": 282,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1064
        },
        "cost": 1.2537559249190284,
        "time": 0.38096165657043457,
        "additional_info": {
            "duration": 0.36943912506103516,
            "num_run": 283,
            "train_loss": 1.1747852131545693,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.827311038970947,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23673460694119394,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 234,
            "feature_preprocessor:kernel_pca:coef0": -0.9655849947751203,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.012946423230553027
        },
        "cost": 0.0,
        "time": 0.2581751346588135,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2587202048841468,
        "time": 3.685757875442505,
        "additional_info": {
            "duration": 3.6689453125,
            "num_run": 286,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4166502892472919,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.297505140304565,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08259387933329312,
            "feature_preprocessor:pca:keep_variance": 0.7791002589826137,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2282389019609836,
        "time": 0.1994318962097168,
        "additional_info": {
            "duration": 0.185943603515625,
            "num_run": 288,
            "train_loss": 1.2324125277581306,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010357891192789554,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.751652956008911,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.4506945868599205,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2432445016590452,
        "time": 0.18999218940734863,
        "additional_info": {
            "duration": 0.17752814292907715,
            "num_run": 290,
            "train_loss": 1.1859987332043027,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.254353454941569,
        "time": 0.2318427562713623,
        "additional_info": {
            "duration": 0.20862698554992676,
            "num_run": 291,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016730153180855703,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9333134787823391,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06201793934750124,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1800
        },
        "cost": 0.0,
        "time": 0.17675280570983887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006329931749437834,
            "feature_preprocessor:select_percentile_classification:percentile": 23.2777908116069,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.247189037951971,
        "time": 0.22356295585632324,
        "additional_info": {
            "duration": 0.21365880966186523,
            "num_run": 293,
            "train_loss": 1.198535809838316,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7419397229243423,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17116106815566334
        },
        "cost": 1.254353454941569,
        "time": 0.2595977783203125,
        "additional_info": {
            "duration": 0.2413318157196045,
            "num_run": 294,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.375200033187866,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4970524626293546,
            "feature_preprocessor:select_percentile_classification:percentile": 63.2249542144298,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.21244001388549805,
        "additional_info": {
            "duration": 0.18514108657836914,
            "num_run": 296,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013781392608112875,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8690450685238894,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.14734962433785287,
            "feature_preprocessor:select_percentile_classification:percentile": 13.476959628643833,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2454585274165175,
        "time": 0.16608786582946777,
        "additional_info": {
            "duration": 0.15566682815551758,
            "num_run": 297,
            "train_loss": 1.2404833976091891,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 13,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2289630805192235,
        "time": 0.28581690788269043,
        "additional_info": {
            "duration": 0.27571821212768555,
            "num_run": 298,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2985904060021147,
        "time": 0.3096902370452881,
        "additional_info": {
            "duration": 0.29880404472351074,
            "num_run": 299,
            "train_loss": 1.001634389283395,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 9080.367647117608,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0016138024992287203
        },
        "cost": 1.251532387527716,
        "time": 0.18743515014648438,
        "additional_info": {
            "duration": 0.17772507667541504,
            "num_run": 300,
            "train_loss": 1.1793477961384358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03121486485614551,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.439028263092041,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.646240838037693,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2360091158712803,
        "time": 0.28598880767822266,
        "additional_info": {
            "duration": 0.27545976638793945,
            "num_run": 302,
            "train_loss": 1.188506968156936,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09174772360647465,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2440695945067484,
        "time": 0.30150294303894043,
        "additional_info": {
            "duration": 0.2906608581542969,
            "num_run": 303,
            "train_loss": 1.1684603190265066,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00071875966312529,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006434865006010854,
            "feature_preprocessor:kitchen_sinks:n_components": 458
        },
        "cost": 0.0,
        "time": 0.1124119758605957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05035725343634511,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 871,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 644,
            "feature_preprocessor:kernel_pca:gamma": 0.30704166575418185
        },
        "cost": 0.0,
        "time": 0.17910504341125488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.587248115201957,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2386121320938108,
        "time": 0.2687087059020996,
        "additional_info": {
            "duration": 0.25185513496398926,
            "num_run": 306,
            "train_loss": 1.1887228377407109,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9302852362312914,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12457296569432148,
            "feature_preprocessor:pca:keep_variance": 0.6696850707091704,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.18382501602172852,
        "additional_info": {
            "duration": 0.17240118980407715,
            "num_run": 307,
            "train_loss": 1.23012359220825,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 2.4904887676239014,
        "additional_info": {
            "duration": 2.475719928741455,
            "num_run": 308,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013297286368883386,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9135555131613255,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19759749995807252,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 191
        },
        "cost": 0.0,
        "time": 0.3053460121154785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.5871570110321045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.36676812171936,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.061379022349616306,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.944182397341796,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16254147735550853,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 73
        },
        "cost": 0.0,
        "time": 0.11378622055053711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.097307920455933,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8759627344578143,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21198782777583108,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 515
        },
        "cost": 0.0,
        "time": 0.10851693153381348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 383,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2587202048841468,
        "time": 0.29953789710998535,
        "additional_info": {
            "duration": 0.28755831718444824,
            "num_run": 315,
            "train_loss": 1.173686099995517,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01605295734616329,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.832724332809448,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 20
        },
        "cost": 0.0,
        "time": 0.10448718070983887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007504619373484608,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.1413047313690186,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.609445095062256,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.245581742666959,
        "time": 0.24749112129211426,
        "additional_info": {
            "duration": 0.2313518524169922,
            "num_run": 320,
            "train_loss": 1.1768437371921612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2409829074702388,
        "time": 0.2125990390777588,
        "additional_info": {
            "duration": 0.20033526420593262,
            "num_run": 321,
            "train_loss": 1.1776094248287925,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001405239726610864,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.16597580909729,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.5336968113621755e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 6207
        },
        "cost": 0.0,
        "time": 0.16797184944152832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09540611426110916,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2461841063023997,
        "time": 1.1500396728515625,
        "additional_info": {
            "duration": 1.1339869499206543,
            "num_run": 324,
            "train_loss": 1.1297583279781314,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022184192891644864,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 100,
            "feature_preprocessor:nystroem_sampler:coef0": 0.37540488722290055,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.2574243329649251
        },
        "cost": 1.254083001706012,
        "time": 0.3707771301269531,
        "additional_info": {
            "duration": 0.3581960201263428,
            "num_run": 325,
            "train_loss": 1.2222892459080712,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015027342939919828,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.51433801651001,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000523745081559373,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.110105991363525,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.35762890558012805,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.790160611733058,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29180327825538643,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 26,
            "feature_preprocessor:kernel_pca:gamma": 0.22563065740787588
        },
        "cost": 0.0,
        "time": 0.27941131591796875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 39.03730987138165,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00029649699195499204
        },
        "cost": 1.2363932727234384,
        "time": 0.21962976455688477,
        "additional_info": {
            "duration": 0.2097611427307129,
            "num_run": 329,
            "train_loss": 1.1772754763597106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013181060523486592,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45589302265752074,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.21310091018676758,
        "additional_info": {
            "duration": 0.2021479606628418,
            "num_run": 330,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2557959311586738,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2472794967936995,
        "time": 1.1566872596740723,
        "additional_info": {
            "duration": 1.143672227859497,
            "num_run": 331,
            "train_loss": 1.001634389283395,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.371693134307861,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7792551492046914,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05392131554268158,
            "feature_preprocessor:select_rates_classification:alpha": 0.40149681293999623,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2442670562486549,
        "time": 0.18747520446777344,
        "additional_info": {
            "duration": 0.17774105072021484,
            "num_run": 333,
            "train_loss": 1.2120355818063329,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007003516695420206,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1005,
            "feature_preprocessor:kernel_pca:coef0": -0.4794120371128725
        },
        "cost": 0.0,
        "time": 0.31893396377563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.134502 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.134502 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 348
        },
        "cost": 0.0,
        "time": 0.13428664207458496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028938818856886046,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.905544996261597,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08300021156997477,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 274
        },
        "cost": 0.0,
        "time": 0.1338350772857666,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7417315631626036,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1041228514503795,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1480
        },
        "cost": 0.0,
        "time": 0.17554688453674316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011204827613102195,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1602,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2423105388076412,
        "time": 1.2274339199066162,
        "additional_info": {
            "duration": 1.21632719039917,
            "num_run": 339,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08916910848921504,
            "feature_preprocessor:kitchen_sinks:gamma": 2.982658755929896,
            "feature_preprocessor:kitchen_sinks:n_components": 4382
        },
        "cost": 0.0,
        "time": 0.17299413681030273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.567045119226789,
            "feature_preprocessor:kitchen_sinks:n_components": 4953
        },
        "cost": 0.0,
        "time": 0.13887810707092285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017097167379335736,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.962865114212036,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22161602077538936,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1484
        },
        "cost": 1.2450130689919927,
        "time": 0.35791492462158203,
        "additional_info": {
            "duration": 0.33087778091430664,
            "num_run": 343,
            "train_loss": 1.1683516380472385,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001493125229648243,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 376
        },
        "cost": 0.0,
        "time": 0.11094784736633301,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.256267070770264,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004321404437771601,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 511,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 226,
            "feature_preprocessor:kernel_pca:gamma": 0.09363917332590654
        },
        "cost": 0.0,
        "time": 0.2801940441131592,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02972339403341862,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.4594078063964844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004590573195957442,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1771,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1026,
            "feature_preprocessor:kernel_pca:gamma": 0.7152392085633623
        },
        "cost": 0.0,
        "time": 0.20758700370788574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2315381739459415,
        "time": 0.7724270820617676,
        "additional_info": {
            "duration": 0.759160041809082,
            "num_run": 349,
            "train_loss": 1.1113634376427382,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41735054840527996,
            "feature_preprocessor:select_percentile_classification:percentile": 82.42588139398923,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226773544272306,
        "time": 0.23581504821777344,
        "additional_info": {
            "duration": 0.22366809844970703,
            "num_run": 350,
            "train_loss": 1.2172650937122467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04837845758421208,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2432398236381053,
        "time": 4.4451751708984375,
        "additional_info": {
            "duration": 4.428263187408447,
            "num_run": 351,
            "train_loss": 1.1917676179517283,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 73.17915298745008,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.26758813858032227,
        "additional_info": {
            "duration": 0.2459249496459961,
            "num_run": 352,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.88347315788269,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007930884746573125,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.962963141632234,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15230672439982085,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 15
        },
        "cost": 0.0,
        "time": 0.11156511306762695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.9265968799591064,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0023188789182024727,
            "feature_preprocessor:kitchen_sinks:n_components": 9087
        },
        "cost": 0.0,
        "time": 0.13490629196166992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011367981333113229,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.74192214012146,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008763005695179356,
            "feature_preprocessor:pca:keep_variance": 0.8056390667329855,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.22066807746887207,
        "additional_info": {
            "duration": 0.2096390724182129,
            "num_run": 358,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 140,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2282192460633292,
        "time": 0.32346224784851074,
        "additional_info": {
            "duration": 0.3061990737915039,
            "num_run": 359,
            "train_loss": 1.1635393365952251,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.090950012207031,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 413
        },
        "cost": 0.0,
        "time": 0.13259077072143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008446828705822362,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1621
        },
        "cost": 0.0,
        "time": 0.13473010063171387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1213,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 7.7988512531321375,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.2560100555419922,
        "additional_info": {
            "duration": 0.2455298900604248,
            "num_run": 363,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7707392956907715,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07305458696603996,
            "feature_preprocessor:kitchen_sinks:gamma": 0.6686061157518653,
            "feature_preprocessor:kitchen_sinks:n_components": 76
        },
        "cost": 0.0,
        "time": 0.1128380298614502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004064588763576415,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.727271795272827,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1057,
            "feature_preprocessor:kernel_pca:coef0": 0.5997372703648205,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 2.7495209437735024
        },
        "cost": 0.0,
        "time": 0.20595192909240723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30926290418916375,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 709,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.4915523412513874,
            "feature_preprocessor:kitchen_sinks:n_components": 913
        },
        "cost": 0.0,
        "time": 0.14385390281677246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005948454804583008,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1355,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 358,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2425285899989635,
        "time": 0.32997822761535645,
        "additional_info": {
            "duration": 0.3161439895629883,
            "num_run": 368,
            "train_loss": 1.1779235433953552,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.13260913297356133,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.20115184783935547,
        "additional_info": {
            "duration": 0.19061493873596191,
            "num_run": 369,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3658071921562313,
            "feature_preprocessor:kitchen_sinks:gamma": 0.03250174134367578,
            "feature_preprocessor:kitchen_sinks:n_components": 3319
        },
        "cost": 0.0,
        "time": 0.11086273193359375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8521673241891004,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27019305001685434,
            "feature_preprocessor:kitchen_sinks:gamma": 0.1946469891842822,
            "feature_preprocessor:kitchen_sinks:n_components": 7179
        },
        "cost": 0.0,
        "time": 0.14464068412780762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028989872134650126,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1904,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 700,
            "feature_preprocessor:kernel_pca:coef0": 0.31850123283351817
        },
        "cost": 0.0,
        "time": 0.19936513900756836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.271139 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.271139 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01689216594054765,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.86004114151001,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.7810869216918945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08989718845946505,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 434
        },
        "cost": 1.2289630805192235,
        "time": 0.30069422721862793,
        "additional_info": {
            "duration": 0.287689208984375,
            "num_run": 375,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020987833812411506,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 163,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 465
        },
        "cost": 1.2289630805192235,
        "time": 0.43465113639831543,
        "additional_info": {
            "duration": 0.41751813888549805,
            "num_run": 376,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.586554765701294,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01596233150310133,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.3534598350524902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.515622138977051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.23538804054260254,
        "additional_info": {
            "duration": 0.22445917129516602,
            "num_run": 380,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.3590290546417236,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012979734115332402,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2707,
            "feature_preprocessor:nystroem_sampler:gamma": 1.2473414571694337
        },
        "cost": 1.2289630805192235,
        "time": 0.4426150321960449,
        "additional_info": {
            "duration": 0.42707300186157227,
            "num_run": 382,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11566843324608582,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.2007648944854736,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9045291016189695,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1313848340148999,
            "feature_preprocessor:select_rates_classification:alpha": 0.102024677688337,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2271190219591293,
        "time": 0.16197919845581055,
        "additional_info": {
            "duration": 0.15234684944152832,
            "num_run": 384,
            "train_loss": 1.198955323516699,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2719435143703615,
        "time": 0.4332282543182373,
        "additional_info": {
            "duration": 0.4144911766052246,
            "num_run": 385,
            "train_loss": 1.203101900518366,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00011801330195373473,
            "feature_preprocessor:kitchen_sinks:n_components": 1610
        },
        "cost": 0.0,
        "time": 0.10828089714050293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7860767841339111,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2097040564691258,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9010560512542725,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 214,
            "feature_preprocessor:kernel_pca:coef0": 0.8856871491927327,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.00124441466393293
        },
        "cost": 0.0,
        "time": 0.3022468090057373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05086261716354221,
            "feature_preprocessor:select_percentile_classification:percentile": 28.808832302693393,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2464648593937309,
        "time": 0.18804311752319336,
        "additional_info": {
            "duration": 0.17846298217773438,
            "num_run": 390,
            "train_loss": 1.1878563746560893,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.044148240465375625,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.3412196636199951,
        "additional_info": {
            "duration": 0.32973527908325195,
            "num_run": 391,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.0810599327087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012586332288952343,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1082,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2538649505146897,
        "time": 0.3679780960083008,
        "additional_info": {
            "duration": 0.35019707679748535,
            "num_run": 393,
            "train_loss": 1.1841437753841135,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2586160129013857,
        "time": 0.28798484802246094,
        "additional_info": {
            "duration": 0.2766909599304199,
            "num_run": 394,
            "train_loss": 1.0082798812088616,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03364849882024871,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0045931339263916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001071901371857236,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 60
        },
        "cost": 0.0,
        "time": 0.16870999336242676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.765657691452436,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10967752084277259,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9738145767803832,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.3319129943847656,
        "additional_info": {
            "duration": 0.32109689712524414,
            "num_run": 397,
            "train_loss": 1.2294690459417643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11289048816130601,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.2673828601837158,
        "additional_info": {
            "duration": 0.2518439292907715,
            "num_run": 398,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3209651099748059,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 399,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.254353454941569,
        "time": 0.33994483947753906,
        "additional_info": {
            "duration": 0.32428908348083496,
            "num_run": 399,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 72.87479619503108,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2289630805192235,
        "time": 0.18689990043640137,
        "additional_info": {
            "duration": 0.16837096214294434,
            "num_run": 400,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008031583098124429,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 929,
            "feature_preprocessor:kernel_pca:gamma": 0.000152973102632529
        },
        "cost": 0.0,
        "time": 0.13495612144470215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2484410224702662,
        "time": 0.22112584114074707,
        "additional_info": {
            "duration": 0.2027420997619629,
            "num_run": 402,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9094500405479468,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29304386992185344,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00029968090953436815,
            "feature_preprocessor:kitchen_sinks:n_components": 7618
        },
        "cost": 0.0,
        "time": 0.14124798774719238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.050085082098970335,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 817
        },
        "cost": 0.0,
        "time": 0.15694332122802734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026956698080733876,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2427561528241262,
        "time": 1.0120317935943604,
        "additional_info": {
            "duration": 0.9996461868286133,
            "num_run": 405,
            "train_loss": 1.1289899567099027,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13727040887082814,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1882
        },
        "cost": 0.0,
        "time": 0.2012622356414795,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9406185630580701,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2207431960847274,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1147,
            "feature_preprocessor:nystroem_sampler:coef0": -0.8986311893595835,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.5760917799653649
        },
        "cost": 1.216844050790308,
        "time": 1.0457170009613037,
        "additional_info": {
            "duration": 1.0298831462860107,
            "num_run": 407,
            "train_loss": 1.1817446664802038,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1397,
            "feature_preprocessor:kernel_pca:coef0": 0.5381690214290245,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 2.666170436546177
        },
        "cost": 0.0,
        "time": 0.2614140510559082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1874,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.18486673153430389,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.28788089752197266,
        "additional_info": {
            "duration": 0.27773332595825195,
            "num_run": 409,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.06409529727254984,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00027069016017314176
        },
        "cost": 1.2289630805192235,
        "time": 0.1610701084136963,
        "additional_info": {
            "duration": 0.15122079849243164,
            "num_run": 410,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9083526318259327,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.22456002235412598,
        "additional_info": {
            "duration": 0.20332789421081543,
            "num_run": 411,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.493669748306274,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 56.321175840807825,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2311920738912774,
        "time": 0.2611672878265381,
        "additional_info": {
            "duration": 0.24761700630187988,
            "num_run": 413,
            "train_loss": 1.1728168754020927,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.963890075683594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1253
        },
        "cost": 0.0,
        "time": 0.13524889945983887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04283425554753243,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 823,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1173
        },
        "cost": 0.0,
        "time": 0.13638901710510254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.4201395650139143,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2289630805192235,
        "time": 0.19077086448669434,
        "additional_info": {
            "duration": 0.17924118041992188,
            "num_run": 417,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012219003550508553,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.311525106430054,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2558991374702937,
        "time": 2.837000846862793,
        "additional_info": {
            "duration": 2.824444055557251,
            "num_run": 419,
            "train_loss": 1.1708571893682744,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03332011256151242,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.3164660930633545,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005201509635434796,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 578,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1372
        },
        "cost": 0.0,
        "time": 0.15259909629821777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005973611525213279,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 325,
            "feature_preprocessor:kernel_pca:coef0": -0.20040809214400257
        },
        "cost": 0.0,
        "time": 0.33434081077575684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.00371885 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.00371885 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.700939893722534,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025444224356296523
        },
        "cost": 1.2409829074702388,
        "time": 0.27310895919799805,
        "additional_info": {
            "duration": 0.24864602088928223,
            "num_run": 424,
            "train_loss": 1.1776094248287925,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.20721697807312012,
        "additional_info": {
            "duration": 0.18668913841247559,
            "num_run": 425,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09019167219134439,
            "feature_preprocessor:pca:keep_variance": 0.9705179481799686,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2282389019609836,
        "time": 0.2793450355529785,
        "additional_info": {
            "duration": 0.2677271366119385,
            "num_run": 426,
            "train_loss": 1.2324125277581306,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7675716217494567,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17490303197464493,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5822194294204623,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2846808433532715,
        "additional_info": {
            "duration": 0.27356886863708496,
            "num_run": 427,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015075128477757252,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1932,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 6128,
            "feature_preprocessor:nystroem_sampler:coef0": 0.8753111465571128,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00014335306009000682
        },
        "cost": 1.2289630805192235,
        "time": 0.43459415435791016,
        "additional_info": {
            "duration": 0.41417384147644043,
            "num_run": 428,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.254353454941569,
        "time": 0.25517797470092773,
        "additional_info": {
            "duration": 0.24117183685302734,
            "num_run": 429,
            "train_loss": 1.1716137802167919,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03036156165476027,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.930229187011719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018203037366973812,
            "feature_preprocessor:kitchen_sinks:gamma": 0.12948700960124965,
            "feature_preprocessor:kitchen_sinks:n_components": 1209
        },
        "cost": 0.0,
        "time": 0.10610008239746094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007866851806229036,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1566
        },
        "cost": 0.0,
        "time": 0.13296008110046387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005484085550352912,
            "feature_preprocessor:kitchen_sinks:gamma": 0.13423387218810012,
            "feature_preprocessor:kitchen_sinks:n_components": 101
        },
        "cost": 0.0,
        "time": 0.10622477531433105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004320910052490684,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8763358332143256,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03833947676196874,
            "feature_preprocessor:kitchen_sinks:gamma": 0.13916330895996737,
            "feature_preprocessor:kitchen_sinks:n_components": 246
        },
        "cost": 0.0,
        "time": 0.13582897186279297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014338462555524255,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 304,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2558991374702937,
        "time": 0.3054051399230957,
        "additional_info": {
            "duration": 0.2876858711242676,
            "num_run": 435,
            "train_loss": 1.1708571893682744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04153103414386715,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1291
        },
        "cost": 0.0,
        "time": 0.10545086860656738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014113855260482175,
            "feature_preprocessor:pca:keep_variance": 0.7561533112297856,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2434720644842079,
        "time": 0.3267819881439209,
        "additional_info": {
            "duration": 0.31396913528442383,
            "num_run": 437,
            "train_loss": 1.182191170816987,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.9934771060943604,
        "additional_info": {
            "duration": 0.9803032875061035,
            "num_run": 438,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11582325532772494,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.9567060470581055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 678
        },
        "cost": 0.0,
        "time": 0.13344502449035645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005915741310478798,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.515797853469849,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.252533912658691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9609141165625776,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2684305580311008,
        "time": 0.2692830562591553,
        "additional_info": {
            "duration": 0.25835704803466797,
            "num_run": 443,
            "train_loss": 1.2067043264363124,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2310951185356693,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.338939905166626,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.5477190017700195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007558634183231043,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.75509786605835,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.4451048374176025,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01795464012675429,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.296680927276611,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010071927351036844,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 166
        },
        "cost": 0.0,
        "time": 0.10528922080993652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1760,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 55,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7956817585721205,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.012616449344890292
        },
        "cost": 1.2289630805192235,
        "time": 0.2526240348815918,
        "additional_info": {
            "duration": 0.24114680290222168,
            "num_run": 450,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 41,
            "feature_preprocessor:kernel_pca:coef0": 0.7518549814498545,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.0010239770985691406
        },
        "cost": 0.0,
        "time": 0.19782805442810059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2348429121737734,
        "time": 0.24728131294250488,
        "additional_info": {
            "duration": 0.2244739532470703,
            "num_run": 452,
            "train_loss": 1.188173542634515,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003990892457474182,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.245956543477237,
        "time": 0.2565791606903076,
        "additional_info": {
            "duration": 0.24062108993530273,
            "num_run": 453,
            "train_loss": 1.0604756100638675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1807,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7050149859420402,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2413669087304366,
        "time": 0.3240528106689453,
        "additional_info": {
            "duration": 0.2795677185058594,
            "num_run": 454,
            "train_loss": 1.197439903257522,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.55875301361084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.32600508257343985,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 765
        },
        "cost": 0.0,
        "time": 0.1327378749847412,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005499498695877502,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 553,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1756
        },
        "cost": 0.0,
        "time": 0.18972206115722656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.40622091293335,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003076179916066825,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2460704026857985,
        "time": 0.2814762592315674,
        "additional_info": {
            "duration": 0.26631784439086914,
            "num_run": 459,
            "train_loss": 1.0556764242399315,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1012,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 989
        },
        "cost": 0.0,
        "time": 0.17349505424499512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.299129962921143,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 5806
        },
        "cost": 1.2289630805192235,
        "time": 0.34682202339172363,
        "additional_info": {
            "duration": 0.32503700256347656,
            "num_run": 462,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0356219144340524,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.140093088150024,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004476443965599329,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1792,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 6.0092136709544144e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 7477
        },
        "cost": 0.0,
        "time": 0.17560291290283203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02887742966864182
        },
        "cost": 1.2416988191303204,
        "time": 0.27587318420410156,
        "additional_info": {
            "duration": 0.263185977935791,
            "num_run": 465,
            "train_loss": 1.1833790557635986,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6171948410432853,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.23536992073059082,
        "additional_info": {
            "duration": 0.22402310371398926,
            "num_run": 466,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011335755071170183,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9977737208377497,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1762057667633324,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 45
        },
        "cost": 0.0,
        "time": 0.1369609832763672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.911747592863597,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2646598815917969,
        "additional_info": {
            "duration": 0.25345683097839355,
            "num_run": 468,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18481046680332835,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8421567424550815,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29532463193355096,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.03989272727075899,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2335247924702113,
        "time": 0.24985074996948242,
        "additional_info": {
            "duration": 0.23891997337341309,
            "num_run": 469,
            "train_loss": 1.1846967221380231,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02523644544326782,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8028719425201416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 121,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.238389247289588,
        "time": 0.32634997367858887,
        "additional_info": {
            "duration": 0.30901002883911133,
            "num_run": 471,
            "train_loss": 1.1795659042843525,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1285,
            "feature_preprocessor:kernel_pca:gamma": 0.17845168774495354
        },
        "cost": 0.0,
        "time": 0.17374801635742188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.045819021663198976,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.032449007034302,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.306376934051514,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0496037370318027,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.119510889053345,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 388
        },
        "cost": 0.0,
        "time": 0.14242291450500488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029709220002609515,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.819167852401733,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008864700805840005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 163
        },
        "cost": 0.0,
        "time": 0.13807415962219238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03525830119104316,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7948567346709111,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28798627751734585,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 73
        },
        "cost": 0.0,
        "time": 0.11321020126342773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016178251599624268,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.787076950073242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08498062762685507,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.986404180526733,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2910634106602076,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1765
        },
        "cost": 0.0,
        "time": 0.13311004638671875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024786522297740303,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.8037590980529785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0944701893835724,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 56
        },
        "cost": 0.0,
        "time": 0.10513997077941895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008419257627968775,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.576984167098999,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07927055334704199,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.651120185852051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008773399058294997,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 928,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1974,
            "feature_preprocessor:kernel_pca:coef0": -0.19502159495805027
        },
        "cost": 0.0,
        "time": 0.37630581855773926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.46808195815963205,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.2010190486907959,
        "additional_info": {
            "duration": 0.1911160945892334,
            "num_run": 488,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2488009935995178,
            "feature_preprocessor:select_rates_classification:alpha": 0.06674811587364979,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2479858968199409,
        "time": 0.21876907348632812,
        "additional_info": {
            "duration": 0.20704984664916992,
            "num_run": 489,
            "train_loss": 1.1924288006154502,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.36812901496887207,
        "additional_info": {
            "duration": 0.34804415702819824,
            "num_run": 490,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009170169168193921,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.924595832824707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2560083186579152,
        "time": 1.0891971588134766,
        "additional_info": {
            "duration": 1.0722291469573975,
            "num_run": 492,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7804382599319815,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22941471821178086,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 867
        },
        "cost": 0.0,
        "time": 0.17208504676818848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8880177500005297,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.23169898986816406,
        "additional_info": {
            "duration": 0.21408319473266602,
            "num_run": 494,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.35663373015302435,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.22211503982543945,
        "additional_info": {
            "duration": 0.21242594718933105,
            "num_run": 495,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01980834445690022,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.598285675048828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005778011536347207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1822,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 189
        },
        "cost": 0.0,
        "time": 0.16903233528137207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1814,
            "feature_preprocessor:kernel_pca:coef0": -0.7123588780514023
        },
        "cost": 0.0,
        "time": 0.295609712600708,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.133201 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.133201 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 77.9469664169773,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.2581930160522461,
        "additional_info": {
            "duration": 0.24030518531799316,
            "num_run": 499,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 17.59438265988528,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2011367290869448,
        "time": 0.18484902381896973,
        "additional_info": {
            "duration": 0.1746807098388672,
            "num_run": 500,
            "train_loss": 1.2011301329469115,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1371526009233543,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 14
        },
        "cost": 0.0,
        "time": 0.15709424018859863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1320
        },
        "cost": 0.0,
        "time": 0.10489511489868164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004271557588009711,
            "feature_preprocessor:select_percentile_classification:percentile": 44.06008074293991,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2563828082842727,
        "time": 0.1854877471923828,
        "additional_info": {
            "duration": 0.17383813858032227,
            "num_run": 503,
            "train_loss": 1.1840421758715374,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0664960261247186,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 120
        },
        "cost": 0.0,
        "time": 0.13692021369934082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015093805096400234,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 227,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 865,
            "feature_preprocessor:kernel_pca:coef0": -0.7032934091506482,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.027972774554905055
        },
        "cost": 0.0,
        "time": 0.1830592155456543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (10.6582 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (10.6582 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006221569600581201,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 691,
            "feature_preprocessor:nystroem_sampler:gamma": 0.008876560743509291
        },
        "cost": 1.2445293981780137,
        "time": 0.5852198600769043,
        "additional_info": {
            "duration": 0.5714719295501709,
            "num_run": 506,
            "train_loss": 1.080408133074629,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17441618603382145,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.209683895111084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015337701714100064,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.952651023864746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04051936109948734,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.516983985900879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025066506454390284,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1364
        },
        "cost": 0.0,
        "time": 0.11120891571044922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 867,
            "feature_preprocessor:nystroem_sampler:coef0": -0.3300348811597895,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0006659091848812109
        },
        "cost": 1.2289630805192235,
        "time": 0.8489241600036621,
        "additional_info": {
            "duration": 0.8307151794433594,
            "num_run": 511,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02052791993834854,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7550338380387497,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1743082521827924,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1624
        },
        "cost": 0.0,
        "time": 0.14082884788513184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014200382121565673,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2498252773590954,
        "time": 1.0949807167053223,
        "additional_info": {
            "duration": 1.0753870010375977,
            "num_run": 513,
            "train_loss": 1.21683626000503,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010134581650948905,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1496
        },
        "cost": 0.0,
        "time": 0.13257694244384766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006529635180586513,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 541,
            "feature_preprocessor:nystroem_sampler:coef0": -0.8328211514319086,
            "feature_preprocessor:nystroem_sampler:gamma": 0.12311719284384784
        },
        "cost": 1.2318700843458252,
        "time": 0.5265941619873047,
        "additional_info": {
            "duration": 0.5147318840026855,
            "num_run": 515,
            "train_loss": 1.1228061000707188,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020140389623730878,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.205118894577026,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26365814582360375,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.2760200500488281,
        "additional_info": {
            "duration": 0.26491212844848633,
            "num_run": 517,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.040608337620711275,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 71
        },
        "cost": 0.0,
        "time": 0.1061849594116211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.238389247289588,
        "time": 1.120779037475586,
        "additional_info": {
            "duration": 1.1073589324951172,
            "num_run": 519,
            "train_loss": 1.1795659042843525,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17339226399126476,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.961764933255083,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05047327766872458
        },
        "cost": 1.2407266438894622,
        "time": 0.21673989295959473,
        "additional_info": {
            "duration": 0.2032160758972168,
            "num_run": 520,
            "train_loss": 1.1752086017213856,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009781784666797326,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.000773191452026,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018180141503360337,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.34549955407555166,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2764720916748047,
        "additional_info": {
            "duration": 0.26561594009399414,
            "num_run": 522,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.951089859008789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1248
        },
        "cost": 0.0,
        "time": 0.13275599479675293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 241,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2558991374702937,
        "time": 0.32322001457214355,
        "additional_info": {
            "duration": 0.307873010635376,
            "num_run": 525,
            "train_loss": 1.1708571893682744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17692739957566933,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.739803075790405,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 970
        },
        "cost": 0.0,
        "time": 0.11039495468139648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03934661332067644,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.018294095993042,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.876436948776245,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03970834537935086,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.263360023498535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02145766304183976,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.804749011993408,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005699173791029075,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 454
        },
        "cost": 0.0,
        "time": 0.13653898239135742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0108250317265102,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 157,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2509255014632954,
        "time": 0.32567286491394043,
        "additional_info": {
            "duration": 0.3011012077331543,
            "num_run": 533,
            "train_loss": 1.1720405325282615,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011051101387208246,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 330,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 80
        },
        "cost": 0.0,
        "time": 0.1304492950439453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 2.743495347705064,
            "feature_preprocessor:kitchen_sinks:n_components": 190
        },
        "cost": 0.0,
        "time": 0.1409471035003662,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009445612250431713,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1603,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.2282192460633292,
        "time": 0.24231886863708496,
        "additional_info": {
            "duration": 0.23050618171691895,
            "num_run": 536,
            "train_loss": 1.1635393365952251,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020612581042205608,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.21760988235473633,
        "additional_info": {
            "duration": 0.19957399368286133,
            "num_run": 537,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 12
        },
        "cost": 0.0,
        "time": 0.13731980323791504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 118,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7643373941808218,
            "feature_preprocessor:nystroem_sampler:gamma": 0.4696656872363959
        },
        "cost": 1.2289630805192235,
        "time": 0.23867082595825195,
        "additional_info": {
            "duration": 0.22302603721618652,
            "num_run": 539,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.046651788560418496,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8224374085027395,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2245963305766456,
        "time": 0.2623178958892822,
        "additional_info": {
            "duration": 0.24963784217834473,
            "num_run": 540,
            "train_loss": 1.2380722864568328,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0021487112716886765,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1474,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1054
        },
        "cost": 0.0,
        "time": 0.15059304237365723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1214
        },
        "cost": 0.0,
        "time": 0.19109392166137695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005479330304277605,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.906030178070068,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013475904821364487,
            "feature_preprocessor:select_percentile_classification:percentile": 83.6307280089384,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.2710440158843994,
        "additional_info": {
            "duration": 0.25371289253234863,
            "num_run": 544,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 107
        },
        "cost": 0.0,
        "time": 0.1616358757019043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008360203412023079,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.93522310256958,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09675342182615229,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9474026695908266,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17390396807853498,
            "feature_preprocessor:kitchen_sinks:gamma": 0.03909088289351982,
            "feature_preprocessor:kitchen_sinks:n_components": 2528
        },
        "cost": 0.0,
        "time": 0.14255309104919434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.688421010971069,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019313651947361356,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 100
        },
        "cost": 0.0,
        "time": 0.1799333095550537,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.987008880655635,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.1798716530490219,
        "time": 0.2354259490966797,
        "additional_info": {
            "duration": 0.22185301780700684,
            "num_run": 550,
            "train_loss": 1.21399922060579,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001390778896075905,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7897546390772803,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24491098141968,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 901
        },
        "cost": 0.0,
        "time": 0.10887813568115234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04804218172444102,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.491262912750244,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.130271208180755,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.393213987350464,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02130075966978451,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8600980303596247,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20771624276880943,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 903
        },
        "cost": 0.0,
        "time": 0.1367323398590088,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003851187546421839,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 100,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.254353454941569,
        "time": 0.2816751003265381,
        "additional_info": {
            "duration": 0.2647571563720703,
            "num_run": 555,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010737618647153094,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.452657222747803,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1078,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.035591879887151956,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2308127506520194,
        "time": 0.3161280155181885,
        "additional_info": {
            "duration": 0.30545902252197266,
            "num_run": 557,
            "train_loss": 1.1905777955609,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06727096215461997,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.24149608612060547,
        "additional_info": {
            "duration": 0.231215238571167,
            "num_run": 558,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24662524593706206,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8413394117369333,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11195382280718336,
            "feature_preprocessor:select_percentile_classification:percentile": 35.97386245801435,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.222158175279269,
        "time": 0.21970415115356445,
        "additional_info": {
            "duration": 0.20938897132873535,
            "num_run": 559,
            "train_loss": 1.220317256507881,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1629,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.5534588275791358,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.2758667469024658,
        "additional_info": {
            "duration": 0.26269984245300293,
            "num_run": 560,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 89.57605477283109,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2329653192451648,
        "time": 0.2921769618988037,
        "additional_info": {
            "duration": 0.2670321464538574,
            "num_run": 561,
            "train_loss": 1.1621327412668463,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27829846286012405,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 253,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2289630805192235,
        "time": 0.29404425621032715,
        "additional_info": {
            "duration": 0.27886104583740234,
            "num_run": 562,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17980689787657314,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 843,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 778
        },
        "cost": 0.0,
        "time": 0.16278314590454102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 15
        },
        "cost": 0.0,
        "time": 0.1609790325164795,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1666
        },
        "cost": 0.0,
        "time": 0.4026641845703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28027624949348423,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.170949697494507,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0035715209481817856,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.4228150844573975,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02213869515529578,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1147,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2611004918944149,
        "time": 1.4048960208892822,
        "additional_info": {
            "duration": 1.3919658660888672,
            "num_run": 568,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3520824947478891,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2284526824951172,
        "additional_info": {
            "duration": 0.21697306632995605,
            "num_run": 569,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.112649823561957,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 805
        },
        "cost": 0.0,
        "time": 0.12973999977111816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 792
        },
        "cost": 0.0,
        "time": 0.136613130569458,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012914722550913008,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.084969997406006,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3121312575329496,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1221,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005957672130959106,
            "feature_preprocessor:kitchen_sinks:n_components": 55
        },
        "cost": 0.0,
        "time": 0.13786602020263672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05097013958739041,
            "feature_preprocessor:select_percentile_classification:percentile": 81.45695560218186,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2404234342451923,
        "time": 0.19154620170593262,
        "additional_info": {
            "duration": 0.17925691604614258,
            "num_run": 574,
            "train_loss": 1.1674738396123612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002583249639422065,
            "feature_preprocessor:kitchen_sinks:gamma": 0.573421476100441,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.10718584060668945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02974539499087139,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2381618400563856,
        "time": 1.641956090927124,
        "additional_info": {
            "duration": 1.6290359497070312,
            "num_run": 576,
            "train_loss": 1.1668318199529673,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020043684744373616,
            "feature_preprocessor:select_percentile_classification:percentile": 64.51972013265564,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2481044340494425,
        "time": 0.21483492851257324,
        "additional_info": {
            "duration": 0.20352602005004883,
            "num_run": 577,
            "train_loss": 1.1621393776640825,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004460280313455768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 738,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1246
        },
        "cost": 0.0,
        "time": 0.1415081024169922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.03851378453658701,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2289630805192235,
        "time": 0.1602950096130371,
        "additional_info": {
            "duration": 0.14993834495544434,
            "num_run": 579,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17401244829282056,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2509255014632954,
        "time": 3.2552599906921387,
        "additional_info": {
            "duration": 3.2427477836608887,
            "num_run": 580,
            "train_loss": 1.1720405325282615,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2602613649838919,
        "time": 1.1277203559875488,
        "additional_info": {
            "duration": 1.105349063873291,
            "num_run": 581,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 634
        },
        "cost": 0.0,
        "time": 0.11115908622741699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04583208480179183,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.33641791343689,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 118,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2509255014632954,
        "time": 0.3376641273498535,
        "additional_info": {
            "duration": 0.3156898021697998,
            "num_run": 584,
            "train_loss": 1.1720405325282615,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.43762049521999885,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 624,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.9737930846029552,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.24625682830810547,
        "additional_info": {
            "duration": 0.22342920303344727,
            "num_run": 585,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039236248413261464,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1187
        },
        "cost": 0.0,
        "time": 0.1389000415802002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 772,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0001145854233929049,
            "feature_preprocessor:kitchen_sinks:n_components": 9943
        },
        "cost": 0.0,
        "time": 0.1711139678955078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016236518602273011,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1833,
            "feature_preprocessor:kernel_pca:gamma": 3.648522125270259
        },
        "cost": 0.0,
        "time": 0.16499090194702148,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.21007323265075684,
        "additional_info": {
            "duration": 0.1879591941833496,
            "num_run": 589,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04051936109948734,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.028362035751343,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007612048615758538,
            "feature_preprocessor:select_percentile_classification:percentile": 65.46493579270945,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2289630805192235,
        "time": 0.25066208839416504,
        "additional_info": {
            "duration": 0.239332914352417,
            "num_run": 591,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007280158941338293,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 131
        },
        "cost": 1.247957196064327,
        "time": 0.2170429229736328,
        "additional_info": {
            "duration": 0.20414113998413086,
            "num_run": 592,
            "train_loss": 1.168671790775187,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.226104560914979,
            "feature_preprocessor:kitchen_sinks:gamma": 0.003871394070417755,
            "feature_preprocessor:kitchen_sinks:n_components": 86
        },
        "cost": 0.0,
        "time": 0.13404226303100586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6301518410487215,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.2037649154663086,
        "additional_info": {
            "duration": 0.190324068069458,
            "num_run": 594,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0001877602726154687,
            "feature_preprocessor:kitchen_sinks:n_components": 1551
        },
        "cost": 0.0,
        "time": 0.10525989532470703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1597907197802346,
            "feature_preprocessor:select_rates_classification:alpha": 0.10973758088137865,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2289630805192235,
        "time": 0.15472102165222168,
        "additional_info": {
            "duration": 0.14446115493774414,
            "num_run": 596,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.560444116592407,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.226773544272306,
        "time": 6.581087827682495,
        "additional_info": {
            "duration": 6.563492059707642,
            "num_run": 598,
            "train_loss": 1.2241319003618885,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.207257032394409,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01530551108755245,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.32682204246521,
        "additional_info": {
            "duration": 1.3155639171600342,
            "num_run": 600,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001149796873939367,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00011174522279809034,
            "feature_preprocessor:kitchen_sinks:n_components": 73
        },
        "cost": 0.0,
        "time": 0.10752105712890625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1191
        },
        "cost": 0.0,
        "time": 0.11239504814147949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2289630805192235,
        "time": 0.22311711311340332,
        "additional_info": {
            "duration": 0.20607209205627441,
            "num_run": 603,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015068968082866044,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.856157064437866,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23763669092850848,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1539,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.6586171740583586,
            "feature_preprocessor:kitchen_sinks:n_components": 5722
        },
        "cost": 0.0,
        "time": 0.174116849899292,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00027627963813369773,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2491524117013681,
        "time": 1.1467671394348145,
        "additional_info": {
            "duration": 1.134549856185913,
            "num_run": 606,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1056,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006276279381133355,
            "feature_preprocessor:kitchen_sinks:n_components": 579
        },
        "cost": 0.0,
        "time": 0.13661718368530273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004440794793846547,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 2806.578016940234,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 6.92851089128883e-05
        },
        "cost": 1.2289630805192235,
        "time": 0.18774795532226562,
        "additional_info": {
            "duration": 0.17790508270263672,
            "num_run": 608,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06834313942890723,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00016710321097638688,
            "feature_preprocessor:kitchen_sinks:n_components": 941
        },
        "cost": 0.0,
        "time": 0.1064450740814209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2323584331807442,
        "time": 1.249436855316162,
        "additional_info": {
            "duration": 1.2381930351257324,
            "num_run": 610,
            "train_loss": 1.1817454126675844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015442382351711852,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.1895527839660645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1422
        },
        "cost": 0.0,
        "time": 0.13201308250427246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.878379052573938,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2537512468980885,
        "time": 0.22972416877746582,
        "additional_info": {
            "duration": 0.21730923652648926,
            "num_run": 613,
            "train_loss": 1.1842346417822849,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012754714491891172,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.631571054458618,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 12
        },
        "cost": 0.0,
        "time": 0.13429522514343262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 707,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 312
        },
        "cost": 0.0,
        "time": 0.17446112632751465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017415281971170635,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.563676118850708,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 5.143238197674995e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 56
        },
        "cost": 0.0,
        "time": 0.10557103157043457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026653395775977744,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1260,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 158
        },
        "cost": 0.0,
        "time": 0.14800786972045898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 94,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.2425285899989635,
        "time": 0.24899506568908691,
        "additional_info": {
            "duration": 0.22707819938659668,
            "num_run": 620,
            "train_loss": 1.1762891541119604,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.047075534578316924,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.131422281265259,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 2662.772390089598,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.020614745153210528
        },
        "cost": 1.2512574118631792,
        "time": 0.18418478965759277,
        "additional_info": {
            "duration": 0.17420697212219238,
            "num_run": 622,
            "train_loss": 1.1833686237671186,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 478
        },
        "cost": 0.0,
        "time": 0.15636801719665527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018527883915341937,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8256345275182946,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25700018475867054,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1421
        },
        "cost": 0.0,
        "time": 0.14119863510131836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001607380373834782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1820,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.02051566611523502,
            "feature_preprocessor:kitchen_sinks:n_components": 101
        },
        "cost": 0.0,
        "time": 0.15542197227478027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7818283370441886,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29057327950210726,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 62
        },
        "cost": 0.0,
        "time": 0.11444211006164551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.3600850105285645,
        "additional_info": {
            "duration": 1.3449559211730957,
            "num_run": 627,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003125671770574181,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.0208715922649807,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2282389019609836,
        "time": 0.25880885124206543,
        "additional_info": {
            "duration": 0.21136879920959473,
            "num_run": 628,
            "train_loss": 1.2307781384747358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 398
        },
        "cost": 0.0,
        "time": 0.16352534294128418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15791946164657447,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002484914450257696,
            "feature_preprocessor:kitchen_sinks:n_components": 540
        },
        "cost": 0.0,
        "time": 0.13164997100830078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013935705610385404,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1805
        },
        "cost": 0.0,
        "time": 0.13301706314086914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8817526869734893,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2728917460705867,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1256
        },
        "cost": 0.0,
        "time": 0.11511015892028809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14079626831454167,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1266,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2538649505146897,
        "time": 0.8058071136474609,
        "additional_info": {
            "duration": 0.7934970855712891,
            "num_run": 633,
            "train_loss": 1.1841437753841135,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.049070235271867935,
            "feature_preprocessor:pca:keep_variance": 0.7503029482178578,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2434720644842079,
        "time": 0.25080299377441406,
        "additional_info": {
            "duration": 0.2361769676208496,
            "num_run": 634,
            "train_loss": 1.183825560100382,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.524492979049683,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.055799054600047436,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 922,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2643008825475257,
        "time": 0.3746788501739502,
        "additional_info": {
            "duration": 0.3567929267883301,
            "num_run": 636,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1046,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.936650290257613e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3854
        },
        "cost": 0.0,
        "time": 0.17929911613464355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00806127297577863,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8775737611684536,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27793986269775867,
            "feature_preprocessor:pca:keep_variance": 0.7903741151792566,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2282389019609836,
        "time": 0.22283506393432617,
        "additional_info": {
            "duration": 0.2032909393310547,
            "num_run": 638,
            "train_loss": 1.2324125277581306,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 0.23824501037597656,
        "additional_info": {
            "duration": 0.22236108779907227,
            "num_run": 639,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005944210962338532
        },
        "cost": 1.2289630805192235,
        "time": 0.20917701721191406,
        "additional_info": {
            "duration": 0.19492769241333008,
            "num_run": 640,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2102366478226058,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.013153076171875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016017810398064072,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 74,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2558991374702937,
        "time": 0.2952399253845215,
        "additional_info": {
            "duration": 0.2792630195617676,
            "num_run": 642,
            "train_loss": 1.1708571893682744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019593994766723675,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 462
        },
        "cost": 0.0,
        "time": 0.13009190559387207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007336713222231618,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 251,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.254353454941569,
        "time": 0.2689180374145508,
        "additional_info": {
            "duration": 0.25685715675354004,
            "num_run": 644,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1033,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.04305637970691476,
            "feature_preprocessor:kitchen_sinks:n_components": 4720
        },
        "cost": 0.0,
        "time": 0.1684551239013672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.614709138870239,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016182723376631056,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 7449,
            "feature_preprocessor:nystroem_sampler:coef0": 0.44511396948243687,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00010635146979633456
        },
        "cost": 1.2289630805192235,
        "time": 0.5639441013336182,
        "additional_info": {
            "duration": 0.5443642139434814,
            "num_run": 647,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003913772733805157,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2334204448954902,
        "time": 0.3170130252838135,
        "additional_info": {
            "duration": 0.3014383316040039,
            "num_run": 648,
            "train_loss": 1.1289030430773703,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9632084676635555,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06394369584788721,
            "feature_preprocessor:select_percentile_classification:percentile": 42.16208869446549,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2402715182391368,
        "time": 0.21424579620361328,
        "additional_info": {
            "duration": 0.1993699073791504,
            "num_run": 649,
            "train_loss": 1.172269818858039,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5970893107712422,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2298649093297556,
        "time": 0.2522251605987549,
        "additional_info": {
            "duration": 0.2410430908203125,
            "num_run": 650,
            "train_loss": 1.216610547445761,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039607096363204145,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1973,
            "feature_preprocessor:kernel_pca:coef0": -0.5524354303337118
        },
        "cost": 0.0,
        "time": 0.22481679916381836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.133392 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.133392 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.541646957397461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03218986890401035,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8176304559670513,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22506149326075736,
            "feature_preprocessor:select_percentile_classification:percentile": 54.96434420822273,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2399711195122842,
        "time": 0.240617036819458,
        "additional_info": {
            "duration": 0.22550010681152344,
            "num_run": 653,
            "train_loss": 1.2163939316746055,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01817381877015257
        },
        "cost": 1.2614367691313184,
        "time": 0.18522000312805176,
        "additional_info": {
            "duration": 0.17258810997009277,
            "num_run": 654,
            "train_loss": 1.1719405693419767,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.8820600509643555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.254353454941569,
        "time": 0.21164488792419434,
        "additional_info": {
            "duration": 0.19889044761657715,
            "num_run": 656,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 596,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 848
        },
        "cost": 0.0,
        "time": 0.19211483001708984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4146488211334246,
            "feature_preprocessor:select_rates_classification:alpha": 0.05674414631347344,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2289630805192235,
        "time": 0.15865302085876465,
        "additional_info": {
            "duration": 0.14909911155700684,
            "num_run": 658,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.21927905082702637,
        "additional_info": {
            "duration": 0.2061929702758789,
            "num_run": 659,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005706064591214268,
            "feature_preprocessor:select_percentile_classification:percentile": 68.33468249165708,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2289630805192235,
        "time": 0.19082427024841309,
        "additional_info": {
            "duration": 0.17322707176208496,
            "num_run": 660,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1522,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1740
        },
        "cost": 0.0,
        "time": 0.1377098560333252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1682,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1578
        },
        "cost": 0.0,
        "time": 0.15360116958618164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005564624027777684
        },
        "cost": 1.2339041157094692,
        "time": 0.23185276985168457,
        "additional_info": {
            "duration": 0.22054409980773926,
            "num_run": 663,
            "train_loss": 1.1826291013123174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002627168016896277,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.0970057439596322,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00019981720083993122
        },
        "cost": 1.2547281001598867,
        "time": 0.16356492042541504,
        "additional_info": {
            "duration": 0.15329504013061523,
            "num_run": 664,
            "train_loss": 1.1779366590234326,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 835,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 348
        },
        "cost": 0.0,
        "time": 0.20818400382995605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2084213074338285,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.505456924438477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011315286102303803,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1722,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 20,
            "feature_preprocessor:kernel_pca:coef0": -0.29086237759017464,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.0038470349258004125
        },
        "cost": 0.0,
        "time": 0.23966574668884277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01980834445690022,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.48884916305542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004267406343029158,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1165
        },
        "cost": 0.0,
        "time": 0.2657809257507324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001490797688523412,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1444,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8353011159331964,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2558944594493537,
        "time": 0.3019688129425049,
        "additional_info": {
            "duration": 0.29024505615234375,
            "num_run": 670,
            "train_loss": 1.191336323853634,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8167651236960413,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2810898235006653,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 913
        },
        "cost": 0.0,
        "time": 0.11252784729003906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1745
        },
        "cost": 0.0,
        "time": 0.13910603523254395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1451
        },
        "cost": 0.0,
        "time": 0.13720703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.9874587059021,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032104330094201218,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.217803001403809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.640389680862427,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49500887160872376,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9803007655794093,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2380479808478244,
        "time": 0.25583720207214355,
        "additional_info": {
            "duration": 0.24396204948425293,
            "num_run": 677,
            "train_loss": 1.204955365963794,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12259312420635339,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.886775016784668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 97,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.254353454941569,
        "time": 0.347012996673584,
        "additional_info": {
            "duration": 0.32499194145202637,
            "num_run": 679,
            "train_loss": 1.1732481695001868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 68.95521792548135,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2431354760633841,
        "time": 0.18846893310546875,
        "additional_info": {
            "duration": 0.1674518585205078,
            "num_run": 680,
            "train_loss": 1.1599524866962336,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7177567037482115,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2620005039451373,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 409,
            "feature_preprocessor:kernel_pca:gamma": 0.04969429506580674
        },
        "cost": 0.0,
        "time": 0.31932759284973145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 60.93946501590485,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.243130798042444,
        "time": 0.23139190673828125,
        "additional_info": {
            "duration": 0.21942496299743652,
            "num_run": 682,
            "train_loss": 1.179245751556404,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1901
        },
        "cost": 1.2289630805192235,
        "time": 0.716437816619873,
        "additional_info": {
            "duration": 0.6970551013946533,
            "num_run": 683,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.044486679334168944,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.592716932296753,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008185816917448087,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.113618850708008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.39546187269149063,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 924,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 8.032644476911827,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00021388476338733575
        },
        "cost": 1.2255025262241974,
        "time": 0.20360970497131348,
        "additional_info": {
            "duration": 0.1933002471923828,
            "num_run": 686,
            "train_loss": 1.2005933644478075,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 917,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 742
        },
        "cost": 0.0,
        "time": 0.15612292289733887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004242810968098432,
            "feature_preprocessor:select_rates_classification:alpha": 0.27226618417601894,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2289630805192235,
        "time": 0.2225630283355713,
        "additional_info": {
            "duration": 0.2126471996307373,
            "num_run": 688,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006147536154753471,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.8575499057769775,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1016,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 849,
            "feature_preprocessor:kernel_pca:coef0": 0.8574736534369138,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 0.0010225078675680547
        },
        "cost": 0.0,
        "time": 0.3666799068450928,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.1194093227386475,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019984343148763523,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 47
        },
        "cost": 0.0,
        "time": 0.11174988746643066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 20
        },
        "cost": 0.0,
        "time": 0.10616612434387207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 244,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004188243840615594,
            "feature_preprocessor:kitchen_sinks:n_components": 226
        },
        "cost": 0.0,
        "time": 0.13875293731689453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.060485508119207027,
            "feature_preprocessor:select_percentile_classification:percentile": 53.01585414486525,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2332972296450486,
        "time": 0.2598271369934082,
        "additional_info": {
            "duration": 0.2426900863647461,
            "num_run": 695,
            "train_loss": 1.1944964214411558,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 674,
            "feature_preprocessor:kernel_pca:coef0": 0.3100130009718949
        },
        "cost": 0.0,
        "time": 0.26740193367004395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7637167390731023,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2628417932342298
        },
        "cost": 1.2407266438894622,
        "time": 0.24785089492797852,
        "additional_info": {
            "duration": 0.2231590747833252,
            "num_run": 697,
            "train_loss": 1.1752086017213856,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1539008332797484,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1067,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1286
        },
        "cost": 0.0,
        "time": 0.13754630088806152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1959
        },
        "cost": 0.0,
        "time": 0.1111609935760498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003203618640667427,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1150,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1715
        },
        "cost": 0.0,
        "time": 0.15310287475585938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.449932098388672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003643987206520493,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7068206884710866,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19977354342789472,
            "feature_preprocessor:kitchen_sinks:gamma": 0.006075340176289879,
            "feature_preprocessor:kitchen_sinks:n_components": 246
        },
        "cost": 0.0,
        "time": 0.17283415794372559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.529120922088623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014420906061741228,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1233,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 65,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2289630805192235,
        "time": 0.41709089279174805,
        "additional_info": {
            "duration": 0.39371275901794434,
            "num_run": 704,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1197,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2611004918944149,
        "time": 0.32811498641967773,
        "additional_info": {
            "duration": 0.31554198265075684,
            "num_run": 705,
            "train_loss": 1.0057743298878257,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 479,
            "feature_preprocessor:kernel_pca:gamma": 0.5072474798014117
        },
        "cost": 0.0,
        "time": 0.2682478427886963,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007043803494750545,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 10
        },
        "cost": 0.0,
        "time": 0.13204026222229004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07291073072257974,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.581924915313721,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007238187500495225,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 12059.318111352424,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.014329608883822493
        },
        "cost": 1.251532387527716,
        "time": 0.22560405731201172,
        "additional_info": {
            "duration": 0.21566486358642578,
            "num_run": 709,
            "train_loss": 1.1793477961384358,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017632627270154477,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 371
        },
        "cost": 1.2289630805192235,
        "time": 0.5503029823303223,
        "additional_info": {
            "duration": 0.530991792678833,
            "num_run": 710,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.154983758926392,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0067399891306736985,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 621
        },
        "cost": 0.0,
        "time": 0.13244009017944336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14119081925623805,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7586201753956139,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1783678217030502,
            "feature_preprocessor:select_rates_classification:alpha": 0.12329304016805322,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2436902712674907,
        "time": 0.20307588577270508,
        "additional_info": {
            "duration": 0.19149184226989746,
            "num_run": 713,
            "train_loss": 1.1763919448813729,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5525243178228917,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2365731115253065,
        "time": 0.25566720962524414,
        "additional_info": {
            "duration": 0.24399375915527344,
            "num_run": 714,
            "train_loss": 1.1993947463867907,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01079453004895169,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 10
        },
        "cost": 0.0,
        "time": 0.15720605850219727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 424,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 80
        },
        "cost": 0.0,
        "time": 0.17319297790527344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022555923337038426,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9473185437801359,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2006188176529818,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 252
        },
        "cost": 0.0,
        "time": 0.10833621025085449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 701
        },
        "cost": 0.0,
        "time": 0.13526320457458496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9022375781042081,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2769985285942657,
            "feature_preprocessor:select_percentile_classification:percentile": 86.88312418757907,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2375596320129052,
        "time": 0.2437880039215088,
        "additional_info": {
            "duration": 0.224442720413208,
            "num_run": 719,
            "train_loss": 1.168568253818394,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1476911129497064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 589,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 820
        },
        "cost": 0.0,
        "time": 0.17489385604858398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.32017979570789984,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1800,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1652
        },
        "cost": 0.0,
        "time": 0.16885018348693848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1433
        },
        "cost": 0.0,
        "time": 0.13772225379943848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018413292045437207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1603,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1301
        },
        "cost": 0.0,
        "time": 0.3200240135192871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.328049898147583,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49989838637411504,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.420730113983154,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021583855386352224,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.189110040664673,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1287,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1116
        },
        "cost": 0.0,
        "time": 0.16498613357543945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008089391636290072,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.16516709327697754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 46, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 720, in fit\n    self._fit_transform(X, compute_sources=False)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 647, in _fit_transform\n    W, n_iter = _ica_par(X1, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 118, in _ica_par\n    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 61, in _sym_decorrelation\n    s, u = linalg.eigh(np.dot(W, W.T))\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/scipy/linalg/_decomp.py\", line 460, in eigh\n    a1 = _asarray_validated(a, check_finite=check_finite)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/scipy/_lib/_util.py\", line 240, in _asarray_validated\n    a = toarray(a)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/numpy/lib/function_base.py\", line 627, in asarray_chkfinite\n    raise ValueError(\nValueError: array must not contain infs or NaNs\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 49, in fit\n    raise ValueError(\nValueError: Bug in scikit-learn: https://github.com/scikit-learn/scikit-learn/pull/2738\n",
            "error": "ValueError('Bug in scikit-learn: https://github.com/scikit-learn/scikit-learn/pull/2738')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011107041509448674,
            "feature_preprocessor:kitchen_sinks:gamma": 0.14369302093988362,
            "feature_preprocessor:kitchen_sinks:n_components": 5269
        },
        "cost": 0.0,
        "time": 0.10723209381103516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.836251974105835,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 96
        },
        "cost": 0.0,
        "time": 0.10547256469726562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00044888181727302404,
            "feature_preprocessor:kitchen_sinks:gamma": 0.05845594843977222,
            "feature_preprocessor:kitchen_sinks:n_components": 395
        },
        "cost": 0.0,
        "time": 0.13280200958251953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20648898001793176,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.875498056411743,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 123
        },
        "cost": 0.0,
        "time": 0.10561394691467285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1582
        },
        "cost": 0.0,
        "time": 0.11140203475952148,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 10.62971121256709,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2629302052077689,
        "time": 0.18366003036499023,
        "additional_info": {
            "duration": 0.17304396629333496,
            "num_run": 736,
            "train_loss": 1.224347769945663,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00940452939598513,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.373697757720947,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4934050050548306,
            "feature_preprocessor:select_percentile_classification:percentile": 76.761964561466,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2574448199990185,
        "time": 0.25121426582336426,
        "additional_info": {
            "duration": 0.2389078140258789,
            "num_run": 738,
            "train_loss": 1.161916125495691,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022404068387700923,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.322530031204224,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21313548974689944,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289630805192235,
        "time": 0.2601478099822998,
        "additional_info": {
            "duration": 0.24422001838684082,
            "num_run": 740,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1260,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 158
        },
        "cost": 0.0,
        "time": 0.1823747158050537,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04039095333002001,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.156961679458618,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9540896415931659,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19226594510159073,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 525,
            "feature_preprocessor:nystroem_sampler:coef0": -0.3336562182269467,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0057920768756468165
        },
        "cost": 1.2221793870965258,
        "time": 0.7518918514251709,
        "additional_info": {
            "duration": 0.7241830825805664,
            "num_run": 743,
            "train_loss": 1.1645338654921782,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013398369577836839,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0012320547110692044,
            "feature_preprocessor:kitchen_sinks:n_components": 4662
        },
        "cost": 0.0,
        "time": 0.1306769847869873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1709,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 700
        },
        "cost": 0.0,
        "time": 0.17854595184326172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0072829150088939715,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1928,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 308
        },
        "cost": 0.0,
        "time": 0.16959881782531738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.5277603952965082,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2289630805192235,
        "time": 0.22310805320739746,
        "additional_info": {
            "duration": 0.19110393524169922,
            "num_run": 747,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3127907243420878,
        "time": 0.32182765007019043,
        "additional_info": {
            "duration": 0.30262184143066406,
            "num_run": 748,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.37436035706758086,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1066
        },
        "cost": 0.0,
        "time": 0.1055910587310791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000689704622502461,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 666,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1799,
            "feature_preprocessor:kernel_pca:gamma": 0.00013576644947999123
        },
        "cost": 0.0,
        "time": 0.35288190841674805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.901258945465088,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001902031331570788,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.242614984512329,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10253376549770837
        },
        "cost": 1.226773544272306,
        "time": 0.22373008728027344,
        "additional_info": {
            "duration": 0.20907807350158691,
            "num_run": 753,
            "train_loss": 1.222822807828917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9560637405369886,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1737220603085696,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2152453512793352,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2340131413051303,
        "time": 0.24591064453125,
        "additional_info": {
            "duration": 0.23409175872802734,
            "num_run": 754,
            "train_loss": 1.1915524945553342,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01750454152027453,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 823,
            "feature_preprocessor:nystroem_sampler:coef0": -0.23762839645070266,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 7.740164636659133e-05
        },
        "cost": 1.2358189874757706,
        "time": 0.3862462043762207,
        "additional_info": {
            "duration": 0.3671867847442627,
            "num_run": 755,
            "train_loss": 1.2247824938627352,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022657266125459385,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.751398576759703,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21841584663081628,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 1140,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0001127233620084239
        },
        "cost": 1.2289630805192235,
        "time": 0.32303476333618164,
        "additional_info": {
            "duration": 0.3058791160583496,
            "num_run": 756,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.052997794778718015,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2289630805192235,
        "time": 1.3602797985076904,
        "additional_info": {
            "duration": 1.3453502655029297,
            "num_run": 757,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006619051325252047,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.945697069168091,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08937487368581577,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 628,
            "feature_preprocessor:kernel_pca:gamma": 0.9477976760358698
        },
        "cost": 0.0,
        "time": 0.2102971076965332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02145954793309638,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.705487012863159,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06504647055479411,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1206,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 937
        },
        "cost": 0.0,
        "time": 0.20236897468566895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 21
        },
        "cost": 0.0,
        "time": 0.13919901847839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 913,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 68
        },
        "cost": 0.0,
        "time": 0.14185285568237305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.216059923171997,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 257.47050087870537,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.026613979704308895
        },
        "cost": 1.2430169388338825,
        "time": 0.1591339111328125,
        "additional_info": {
            "duration": 0.14845705032348633,
            "num_run": 765,
            "train_loss": 1.172702304212969,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 8225.894332051028,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00046763886603214024
        },
        "cost": 1.2289630805192235,
        "time": 0.15716290473937988,
        "additional_info": {
            "duration": 0.14676117897033691,
            "num_run": 766,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.40890592706044415,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00039285094528714536,
            "feature_preprocessor:kitchen_sinks:n_components": 121
        },
        "cost": 0.0,
        "time": 0.11375904083251953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2719435143703615,
        "time": 0.27940797805786133,
        "additional_info": {
            "duration": 0.26643824577331543,
            "num_run": 768,
            "train_loss": 1.203101900518366,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1946,
            "feature_preprocessor:kernel_pca:gamma": 0.014162132580617888
        },
        "cost": 0.0,
        "time": 0.2607760429382324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.053889929377719185,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.768552303314209,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002051775729930975,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.665303540645516,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2531870956521018,
        "time": 0.23001909255981445,
        "additional_info": {
            "duration": 0.21831703186035156,
            "num_run": 771,
            "train_loss": 1.190133974855714,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 26.927234641738877,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2432445016590452,
        "time": 0.18419289588928223,
        "additional_info": {
            "duration": 0.1738288402557373,
            "num_run": 772,
            "train_loss": 1.2055090589050839,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016885816006949873
        },
        "cost": 1.2323584331807442,
        "time": 0.1875457763671875,
        "additional_info": {
            "duration": 0.1687328815460205,
            "num_run": 773,
            "train_loss": 1.1817454126675844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005235401040835534,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 323
        },
        "cost": 0.0,
        "time": 0.11651611328125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23601075705244265,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1869,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1594
        },
        "cost": 0.0,
        "time": 0.16361618041992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11570070013637568,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2411395014972342,
        "time": 1.1731431484222412,
        "additional_info": {
            "duration": 1.150946855545044,
            "num_run": 776,
            "train_loss": 1.001634389283395,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2348429121737734,
        "time": 0.23390698432922363,
        "additional_info": {
            "duration": 0.21898508071899414,
            "num_run": 777,
            "train_loss": 1.188173542634515,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7250089599137397,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2684237072179486,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 697,
            "feature_preprocessor:kernel_pca:coef0": 0.3261526094793097
        },
        "cost": 0.0,
        "time": 0.26961207389831543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.134037 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.134037 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1757
        },
        "cost": 0.0,
        "time": 0.15700221061706543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14250238198975013,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1487
        },
        "cost": 0.0,
        "time": 0.11110115051269531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.305452108383179,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016657990338017309,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1058,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.258388450076223,
        "time": 0.35391902923583984,
        "additional_info": {
            "duration": 0.3401341438293457,
            "num_run": 782,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11566843324608582,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.390127897262573,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_AOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21326934866732686,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1366,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2499915386118914,
        "time": 1.4240341186523438,
        "additional_info": {
            "duration": 1.4091808795928955,
            "num_run": 784,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 146,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2289630805192235,
        "time": 0.3560161590576172,
        "additional_info": {
            "duration": 0.33937716484069824,
            "num_run": 785,
            "train_loss": 1.2288144996752786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 12.498564742540372,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2279487928277724,
        "time": 0.1931624412536621,
        "additional_info": {
            "duration": 0.18288588523864746,
            "num_run": 786,
            "train_loss": 1.2050608403648038,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004413593587583813,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 723,
            "feature_preprocessor:kernel_pca:gamma": 0.87213075106995
        },
        "cost": 0.0,
        "time": 0.22155404090881348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9939229678081076,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1110579614272986,
            "feature_preprocessor:select_rates_classification:alpha": 0.2832151973322619,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2531870956521018,
        "time": 0.22495484352111816,
        "additional_info": {
            "duration": 0.21186304092407227,
            "num_run": 788,
            "train_loss": 1.170738665413512,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 45.96205702676868,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 9.230326557937739e-05
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]